{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFCx6jZU3m11"
   },
   "source": [
    "<!-- Banner Image -->\n",
    "<img src=\"https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brev-xmas-3.png\" width=\"100%\">\n",
    "\n",
    "<!-- Links -->\n",
    "<center>\n",
    "  <a href=\"https://console.brev.dev\" style=\"color: #06b6d4;\">Console</a> •\n",
    "  <a href=\"https://brev.dev\" style=\"color: #06b6d4;\">Docs</a> •\n",
    "  <a href=\"/\" style=\"color: #06b6d4;\">Templates</a> •\n",
    "  <a href=\"https://discord.gg/NVDyv7TUgJ\" style=\"color: #06b6d4;\">Discord</a>\n",
    "</center>\n",
    "\n",
    "# Fine-tuning Microsoft's Phi-2 on your own data 🤙\n",
    "\n",
    "Welcome!\n",
    "\n",
    "In this notebook and tutorial, we will fine-tune [Microsoft's Phi-2](https://huggingface.co/microsoft/phi-2) relatively small 2.7B model - which has \"showcased a nearly state-of-the-art performance among models with less than 13 billion parameters\" - ***on your own data!***\n",
    "\n",
    "## Watch the accompanying video walk-through (but for Mistral 7B) [here](https://youtu.be/kmkcNVvEz-k?si=Ogt1wRFNqYI6zXfw&t=1)! \n",
    "If you'd like to see a notebook to fine-tune Phi-2 on a Hugging Face dataset instead, click [here](https://github.com/brevdev/notebooks/blob/main/phi2-finetune-own-data.ipynb).\n",
    "\n",
    "I did this for **just one dollar ($1)** on an 1x A10G 24GB from Brev.dev (instructions below).\n",
    "\n",
    "This tutorial will use QLoRA, a fine-tuning method that combines quantization and LoRA. For more information about what those are and how they work, see [this post](https://brev.dev/blog/how-qlora-works).\n",
    "\n",
    "Note that if you ever have trouble importing something from Huggingface, you may need to run `huggingface-cli login` in a shell. To open a shell in Jupyter Lab, click on 'Launcher' (or the '+' if it's not there) next to the notebook tab at the top of the screen. Under \"Other\", click \"Terminal\" and then run the command.\n",
    "\n",
    "### Help us make this tutorial better! Please provide feedback on the [Discord channel](https://discord.gg/RN2a436M73) or on [X](https://x.com/harperscarroll)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9TytWkb3m15"
   },
   "source": [
    "#### Before we begin: A note on OOM errors\n",
    "\n",
    "If you get an error like this: `OutOfMemoryError: CUDA out of memory`, tweak your parameters to make the model less computationally intensive. I will help guide you through that in this guide, and if you have any additional questions you can reach out on the [Discord channel](https://discord.gg/RN2a436M73) or on [X](https://x.com/harperscarroll).\n",
    "\n",
    "To re-try after you tweak your parameters, open a Terminal ('Launcher' or '+' in the nav bar above -> Other -> Terminal) and run the command `nvidia-smi`. Then find the process ID `PID` under `Processes` and run the command `kill [PID]`. You will need to re-start your notebook from the beginning. (There may be a better way to do this... if so please do let me know!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC-9m2yv3m18"
   },
   "source": [
    "## Let's begin!\n",
    "### 0. Preparing data\n",
    "\n",
    "Before you check out a GPU, prepare your dataset for loading and training.\n",
    "\n",
    "To prepare your dataset for loading, all you need are two `.jsonl` files structured something like this:\n",
    "```\n",
    "{\"input\": \"What color is the sky?\", \"output\": \"The sky is blue.\"}\n",
    "{\"input\": \"Where is the best place to get cloud GPUs?\", \"output\": \"Brev.dev\"}\n",
    "```\n",
    "If you choose to model your data as input/output pairs, you'll want to use something like the second `formatting_func` below, which will will combine all your features into one input string.\n",
    "\n",
    "As you can see below, I have `notes.jsonl` for my `train_dataset` and `notes_validation.jsonl` for my `eval_dataset`.\n",
    "\n",
    "I used Exporter, a free local-only app, to export my Apple Notes to `.txt` files, and then I wrote a script to process each note into one `.jsonl` file. Note that for this script, ChatGPT can help out a LOT if you tell it how your data is currently formatted, how you'd like it to be formatted, and ask it to write a script in a certain language you know well (for any debugging) to do so. I also broke up my journal entries so the training sample vector length was smaller (see the discussion on `max_length` and the data visualization below). I broke it into pieces so that contexts were encapsulated entirely, since I did want the model to understand context about my life. My data were ultimately formatted as:\n",
    "\n",
    "```json\n",
    "{\"note\": \"journal-entry-for-model-to-predict\"}\n",
    "{\"note\": \"journal-entry-for-model-to-predict-1\"}\n",
    "{\"note\": \"journal-entry-for-model-to-predict-2\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2CkxsA43m15"
   },
   "source": [
    "### 1. Set Up GPU\n",
    "\n",
    "I used a GPU and dev environment from [brev.dev](https://brev.dev). The whole thing cost me $1 using a 1xA10G 24GB. Click the badge below to get your preconfigured instance:\n",
    "\n",
    "[![click here to deploy](https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brevdeploynavy.svg)](https://console.brev.dev/environment/new?instance=A10G:g5.xlarge&diskStorage=256&name=phi2-finetune-own-data&file=https://github.com/brevdev/notebooks/raw/main/phi2-finetune-own-data.ipynb&python=3.10&cuda=12.0.1)\n",
    "\n",
    "A single A10G (as linked) with 24GB GPU Memory was enough for me. You may need more GPUs and/or Memory if your sequence max_length is larger than 512.\n",
    "\n",
    "Once you've checked out your machine and landed in your instance page, select the specs you'd like (I used **Python 3.10 and CUDA 12.0.1**; these should be preconfigured for you if you use the badge above) and click the \"Build\" button to build your verb container. Give this a few minutes.\n",
    "\n",
    "A few minutes after your model has started Running, click the 'Notebook' button on the top right of your screen once it illuminates (you may need to refresh the screen). You will be taken to a Jupyter Lab environment, where you can upload this Notebook.\n",
    "\n",
    "\n",
    "Note: You can connect your cloud credits (AWS or GCP) by clicking \"Org: \" on the top right, and in the panel that slides over, click \"Connect AWS\" or \"Connect GCP\" under \"Connect your cloud\" and follow the instructions linked to attach your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/jorge/.local/lib/python3.10/site-packages (from jsonlines) (23.2.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "phrases = \"\"\"the sun is playfully golden\n",
    "clouds are fluffy dreamers\n",
    "computers are tirelessly calculating\n",
    "coffee beans are irresistibly aromatic\n",
    "books are windows to other worlds\n",
    "bicycles are silently rolling\n",
    "raindrops are rhythmically tapping\n",
    "elephants are majestically gentle\n",
    "fireflies are enchanting the night\n",
    "roller coasters are thrillingly fast\n",
    "strawberries are temptingly sweet\n",
    "dolphins are gracefully swimming\n",
    "candles are softly flickering\n",
    "moonlight is romantically silver\n",
    "penguins are comically waddling\n",
    "diamonds are dazzlingly brilliant\n",
    "rivers are serenely flowing\n",
    "jellyfish are gracefully floating\n",
    "guitars are passionately strumming\n",
    "stars are twinkling diamonds\n",
    "wind is whimsically whispering\n",
    "ice cream is blissfully creamy\n",
    "deserts are expansively serene\n",
    "puzzles are intriguingly challenging\n",
    "owls are mysteriously hooting\n",
    "butterflies are delicately fluttering\n",
    "robots are efficiently buzzing\n",
    "rainbows are magically colorful\n",
    "rollerblades are smoothly gliding\n",
    "volcanoes are powerfully erupting\n",
    "forests are abundantly green\n",
    "laughter is contagiously joyful\n",
    "seashells are intricately patterned\n",
    "saxophones are soulfully playing\n",
    "feathers are softly floating\n",
    "marmalade is delightfully sticky\n",
    "snowflakes are uniquely delicate\n",
    "hammocks are lazily swinging\n",
    "fireworks are explosively vibrant\n",
    "marshmallows are perfectly fluffy\n",
    "comets are speedily streaking\n",
    "trampolines are bouncily springing\n",
    "cherry blossoms are gracefully falling\n",
    "hummingbirds are swiftly darting\n",
    "sunsets are breathtakingly colorful\n",
    "hot air balloons are peacefully drifting\n",
    "acrobats are daringly flipping\n",
    "canyons are grandly echoing\n",
    "bubbles are playfully floating\n",
    "kangaroos are energetically hopping\n",
    "auroras are ethereally dancing\n",
    "lightning is dramatically striking\n",
    "popcorn is irresistibly buttery\n",
    "giraffes are elegantly towering\n",
    "sandcastles are creatively sculpted\n",
    "peacocks are regally displaying\n",
    "tulips are gracefully nodding\n",
    "meteors are spectacularly streaking\n",
    "spiders are intricately weaving\n",
    "thunder is rumbling mysteriously\n",
    "seagulls are gracefully gliding\n",
    "marshes are peacefully teeming\n",
    "tornadoes are ominously swirling\n",
    "dolphins are joyfully leaping\n",
    "lighthouses are steadfastly shining\n",
    "avalanches are powerfully cascading\n",
    "strawberries are temptingly juicy\n",
    "zebras are strikingly patterned\"\"\".split(\"\\n\")\n",
    "\n",
    "\n",
    "with jsonlines.open('notes.jsonl', 'w') as writer:\n",
    "    for i, phrase in enumerate(phrases):\n",
    "        entry_format = {\"note\": f\"{phrase}\"}\n",
    "        writer.write(entry_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "phrases = \"\"\"kites are soaring gracefully\n",
    "eagles are majestically soaring\n",
    "bonsai trees are intricately pruned\n",
    "bumblebees are industriously buzzing\n",
    "rainforests are abundantly vibrant\n",
    "dragonflies are delicately hovering\n",
    "waterfalls are thunderously cascading\n",
    "sunflowers are cheerfully blooming\n",
    "snowmen are whimsically adorned\n",
    "sand dunes are expansively shifting\n",
    "crickets are chirping rhythmically\n",
    "cacti are resiliently standing\n",
    "symphonies are harmoniously playing\n",
    "polar bears are magnificently white\n",
    "caterpillars are industriously crawling\n",
    "comets are mysteriously glowing\n",
    "glaciers are slowly advancing\n",
    "igloos are cozily constructed\n",
    "metropolises are bustling with energy\n",
    "fireflies are romantically twinkling\n",
    "satellites are silently orbiting\n",
    "orchids are elegantly blooming\n",
    "robots are diligently computing\n",
    "hurricanes are powerfully swirling\n",
    "dolphins are gracefully flipping\n",
    "tigers are stealthily prowling\n",
    "strawberries are lusciously ripe\n",
    "snowflakes are intricately formed\n",
    "eagles are majestically soaring\n",
    "sandcastles are playfully sculpted\n",
    "moonlight is softly illuminating\n",
    "fireworks are explosively dazzling\"\"\".split(\"\\n\")\n",
    "\n",
    "\n",
    "with jsonlines.open('notes_validation.jsonl', 'w') as writer:\n",
    "    for i, phrase in enumerate(phrases):\n",
    "        entry_format = {\"note\": f\"{phrase}\"}\n",
    "        writer.write(entry_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FuXIFTFapAMI",
    "outputId": "c8ced1ad-c7b3-44ba-807b-26d7d13906bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anyio 3.7.1 requires sniffio>=1.1, which is not installed.\n",
      "chainlit 1.0.100 requires pydantic<3,>=1, which is not installed.\n",
      "chainlit 1.0.100 requires syncer<3.0.0,>=2.0.3, which is not installed.\n",
      "fastapi 0.100.1 requires pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4, which is not installed.\n",
      "httpcore 0.17.3 requires h11<0.15,>=0.13, which is not installed.\n",
      "httpcore 0.17.3 requires sniffio==1.*, which is not installed.\n",
      "httpx 0.24.1 requires sniffio, which is not installed.\n",
      "literalai 0.0.102 requires pydantic<3,>=1, which is not installed.\n",
      "ERROR: Could not find a version that satisfies the requirement torch<2.2.0,>=1.10.0 (from accelerate) (from versions: 2.2.0)\n",
      "ERROR: No matching distribution found for torch<2.2.0,>=1.10.0\n"
     ]
    }
   ],
   "source": [
    "# You only need to run this once per machine\n",
    "# !pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05H5MIfjyRgc"
   },
   "source": [
    "#### Accelerator\n",
    "\n",
    "Set up the Accelerator. I'm not sure if we really need this for a QLoRA given its [description](https://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/fsdp) (I have to read more about it) but it seems it can't hurt, and it's helpful to have the code for future reference. You can always comment out the accelerator if you want to try without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"inbox/yousefjoeguy_1044219450303485/message_1.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['participants', 'messages', 'title', 'is_still_participant', 'thread_path', 'magic_words'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3509"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['messages'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yousefjoeguy'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i['sender_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count(\"kek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Eduardo: what u cookingg\n",
      "Jorge Eduardo: what will it be\n",
      "Jorge Eduardo: so\n",
      "Jorge Eduardo: gtg helping my dad\n",
      "Jorge Eduardo: i gave them the firebase lango2lang website the one that looks good\n",
      "Jorge Eduardo: ?\n",
      "Jorge Eduardo: 3 daysv\n",
      "Jorge Eduardo: how long we got?\n",
      "Jorge Eduardo: the link part is stuck\n",
      "Jorge Eduardo: wym\n",
      "Jorge Eduardo: âif i see lego gif ill commit crimes in serbiaâ\n",
      "âlego gifâ\n",
      "âayo some guy committed crimes in serbiaâ\n",
      "Jorge Eduardo: ill reply later when i have time bro\n",
      "Jorge Eduardo: im trying to figure out how the scam works, do u know?\n",
      "Jorge Eduardo: nigga what if we played once a week\n",
      "Jorge Eduardo: commentsâ¦\n",
      "Jorge Eduardo: u rn\n",
      "Jorge Eduardo: check my comment\n",
      "Jorge Eduardo: the red pill of truth isnt always easy to accept\n",
      "Jorge Eduardo: ah yes, the final setup, we need this\n",
      "Jorge Eduardo: 888237\n",
      "Jorge Eduardo: the indian nigga\n",
      "Jorge Eduardo: oh cool information\n",
      "Jorge Eduardo: she looks so hot from where i sit\n",
      "Jorge Eduardo: who tf is she\n",
      "Jorge Eduardo: that girl in leather jacket looks like my ex...\n",
      "Jorge Eduardo: nigga\n",
      "Jorge Eduardo: btw i saw rahul and he said my work was excellent\n",
      "Jorge Eduardo: tf are they yapping abt\n",
      "Jorge Eduardo: does that mean u have a non mew time?\n",
      "Jorge Eduardo: 327872\n",
      "Jorge Eduardo: u fked\n",
      "Jorge Eduardo: damn\n",
      "Jorge Eduardo: Â£40 for u\n",
      "Jorge Eduardo: but now i have my doubts\n",
      "Jorge Eduardo: i thought u were a samurai\n",
      "Jorge Eduardo: a week ago i got them for Â£2.6\n",
      "Jorge Eduardo: is this normal?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: ðââï¸ð\n",
      "Jorge Eduardo: yeah i saw that comment too\n",
      "Jorge Eduardo: haram pigeon\n",
      "Jorge Eduardo: like nigga just use the existing toilets, you aint steve jobs for adding a douche in the toilet\n",
      "Jorge Eduardo: like new genders and now new toilets\n",
      "Jorge Eduardo: ppl be so bored today they do be creating new shit\n",
      "Jorge Eduardo: cant wait for update in abt 2 years\n",
      "Jorge Eduardo: damn\n",
      "Jorge Eduardo: crazier to think many ppl didnt even know what these were before the movie\n",
      "Jorge Eduardo: are we wide lower face practicers?\n",
      "Jorge Eduardo: every thursday bro on the premium toilets\n",
      "Jorge Eduardo: niggativities\n",
      "Jorge Eduardo: me without being drunk\n",
      "Jorge Eduardo: us cooking\n",
      "Jorge Eduardo: https://youtube.com/shorts/_1exm-RSu3Q?si=eX8zZCrHGKvQHp8b\n",
      "Jorge Eduardo: https://www.reddit.com/r/ClashRoyaleCirclejerk/comments/16hrth6/archer_queen_feet_appreciation_post/\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=aK2XiCq7dqY\n",
      "Jorge Eduardo: and hit the person off the bridge then again when going down\n",
      "Jorge Eduardo: then the explosion will throw the arrows up\n",
      "Jorge Eduardo: then a fireball\n",
      "Jorge Eduardo: throw many arrows up\n",
      "Jorge Eduardo: but still room for improvement\n",
      "Jorge Eduardo: impressive\n",
      "Jorge Eduardo: damn\n",
      "Jorge Eduardo: bro was sending message manually lmfao\n",
      "Jorge Eduardo: nvm\n",
      "Jorge Eduardo: get them to promote his app and split profit\n",
      "Jorge Eduardo: sending dms to influencers\n",
      "Jorge Eduardo: hes cooking\n",
      "Jorge Eduardo: shh\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=LdYfaaxhfvw\n",
      "Jorge Eduardo: ââââ\n",
      "Jorge Eduardo: blondes\n",
      "Jorge Eduardo: finally brooo\n",
      "Jorge Eduardo: my teamates on ranked\n",
      "Jorge Eduardo: mewing\n",
      "Jorge Eduardo: \"show the bola\" literal translation = \"ball show\" actual translation = \"cool\"\n",
      "Jorge Eduardo: also, i didnt read the captions that much, but one that i saw that was funny was \"ball show\" like who tf translated this shit lmfao\n",
      "Jorge Eduardo: he started the whole trend on tiktok of speaking a word in all languages and then german in a very angry and loud way\n",
      "Jorge Eduardo: i have a friend who did the same\n",
      "Jorge Eduardo: also it seems like he learn the most used phrases, like 50 of them and thats it\n",
      "Jorge Eduardo: brah, his portuguese is so from portugal\n",
      "Jorge Eduardo: yapa these nuts\n",
      "Jorge Eduardo: are u trying say u japanese? but all u do is yapanese nuts\n",
      "Jorge Eduardo: meme potential\n",
      "Jorge Eduardo: wanna video call? im in a pub\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: exactly, move on from palestine vs israel, we need a new war\n",
      "Jorge Eduardo: âthere is only two sexes, the one i have with your mom and the one i have with your dadâ\n",
      "Jorge Eduardo: roast my comment\n",
      "Jorge Eduardo: fax\n",
      "Jorge Eduardo: https://youtube.com/shorts/7F4i44dbKl4?si=J2gBVdDtKUeqBCBS\n",
      "Jorge Eduardo: wait for me\n",
      "Jorge Eduardo: damn\n",
      "Jorge Eduardo: milestone 3: 100% uncooked\n",
      "Jorge Eduardo: white rizz\n",
      "Jorge Eduardo: W\n",
      "Jorge Eduardo: https://youtube.com/shorts/IQzhfHSE540?si=CVxxQXqaeCSSDW1z\n",
      "Jorge Eduardo: https://youtube.com/shorts/8ccXkd40J0o?si=0_Ot-1HU0S9ENmgL\n",
      "Jorge Eduardo: u telling me im not the mc\n",
      "Jorge Eduardo: https://youtube.com/shorts/lIpajWKlMPo?si=M5VUqwbcMPF5UpSv\n",
      "Jorge Eduardo: what a fucking cunt of an advice\n",
      "Jorge Eduardo: check my comment\n",
      "Jorge Eduardo: im better than 99.999% of the population\n",
      "Jorge Eduardo: me with my  yoyo\n",
      "Jorge Eduardo: ping pong ninga\n",
      "Jorge Eduardo: shes a 10 but the next hittler and also ur dad: 10\n",
      "Jorge Eduardo: ?\n",
      "Jorge Eduardo: wanna play lol?\n",
      "Jorge Eduardo: an arab in between all them asians lmfao\n",
      "Jorge Eduardo: it wouldnt fit in\n",
      "Jorge Eduardo: also weird af\n",
      "Jorge Eduardo: that would be sick lol\n",
      "Jorge Eduardo: one day?\n",
      "Jorge Eduardo: we playing LoL in 2 hours\n",
      "Jorge Eduardo: just slept the whole day\n",
      "Jorge Eduardo: Merry Christmas\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/_2FAe_MkH3M\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/k-WXEsc0rbE\n",
      "Jorge Eduardo: sleep tight yemini person\n",
      "Jorge Eduardo: ait\n",
      "Jorge Eduardo: LoL?\n",
      "Jorge Eduardo: i can fking hear it\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: hold on, opening my game\n",
      "Jorge Eduardo: letsgo\n",
      "Jorge Eduardo: normal map?\n",
      "Jorge Eduardo: summoners rift?\n",
      "Jorge Eduardo: method\n",
      "Jorge Eduardo: bro using the big ed\n",
      "Jorge Eduardo: LoL time\n",
      "Jorge Eduardo: ayo\n",
      "Jorge Eduardo: everyone talking shit abt me Q_Q\n",
      "Jorge Eduardo: wasnt general\n",
      "Jorge Eduardo: deleting it all\n",
      "Jorge Eduardo: no one reading my chats\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: send to me\n",
      "Jorge Eduardo: bro said K\n",
      "Jorge Eduardo: ill join in 5\n",
      "Jorge Eduardo: hold on\n",
      "Jorge Eduardo: found it\n",
      "Jorge Eduardo: im looking for the server\n",
      "Jorge Eduardo: german?\n",
      "Jorge Eduardo: how does it look like?\n",
      "Jorge Eduardo: soop?\n",
      "Jorge Eduardo: i didnt ask but ok\n",
      "Jorge Eduardo: kek\n",
      "Jorge Eduardo: here where?\n",
      "Jorge Eduardo: download what\n",
      "Jorge Eduardo: wow\n",
      "Jorge Eduardo: im waiting zingey\n",
      "Jorge Eduardo: LoL when?\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: thats why i dont remember fighting u, cuz i won and u wiped my memory\n",
      "Jorge Eduardo: https://www.reddit.com/r/AsianPleasureSquad/comments/14j4ph1/sdvs_list_of_asiancentric_subreddits/\n",
      "Jorge Eduardo: there is a nigga peeing and singing at the same time\n",
      "Jorge Eduardo: help\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: help\n",
      "Jorge Eduardo: yup\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=svTkihwLUx4\n",
      "Jorge Eduardo: without getting banned thats insane\n",
      "Jorge Eduardo: how tho\n",
      "Jorge Eduardo: who\n",
      "Jorge Eduardo: nigativities\n",
      "Jorge Eduardo: thats racist\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=9wyvS0YVduQ\n",
      "Jorge Eduardo: btw asians are so fking smart\n",
      "Jorge Eduardo: i prefer this\n",
      "Jorge Eduardo: womp womp chiga?\n",
      "Jorge Eduardo: damn that free shipping be looking tempting\n",
      "Jorge Eduardo: bro forgot how biology works\n",
      "Jorge Eduardo: https://we-are-jammin.xyz/\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=9nTpK97o9JA&list=PLXq9ObUBLV1qq8CBXcs0F-aHrGF9iNqLa\n",
      "Jorge Eduardo: ngl i thought it was the start of a porno\n",
      "Jorge Eduardo: cant\n",
      "Jorge Eduardo: comments are insane\n",
      "Jorge Eduardo: the struggle is real\n",
      "Jorge Eduardo: boring\n",
      "Jorge Eduardo: abt how im 1 dimentional\n",
      "Jorge Eduardo: i thought he kept yapping more\n",
      "Jorge Eduardo: oh nvm\n",
      "Jorge Eduardo: check the last comment\n",
      "Jorge Eduardo: holy shit\n",
      "Jorge Eduardo: korean shit is the best\n",
      "Jorge Eduardo: u\n",
      "Jorge Eduardo: ê¹\n",
      "Jorge Eduardo: ayy\n",
      "Jorge Eduardo: yepp\n",
      "Jorge Eduardo: chatgpt tonight:\n",
      "Jorge Eduardo: hold on cuz im taking a shit\n",
      "Jorge Eduardo: same, not even research\n",
      "Jorge Eduardo: fr? u havent done it yet?\n",
      "Jorge Eduardo: nah u are the right person, cuz i read a comment saying its good for taking a shit\n",
      "Jorge Eduardo: macroeconomics of japan bitch\n",
      "Jorge Eduardo: so u can get a waifu\n",
      "Jorge Eduardo: learn this shit\n",
      "Jorge Eduardo: he is me\n",
      "Jorge Eduardo: i cant be bothered to go back months of talk to find the stuff she talked abt\n",
      "Jorge Eduardo: this was just her reminding me\n",
      "Jorge Eduardo: the ð\n",
      "Jorge Eduardo: it really traumatised her apparently and was the worst part of her british experience\n",
      "Jorge Eduardo: hm i dont remember, i guess its cuz i trust my friend who said he did these things and its not hard to believe he would actually do it\n",
      "Jorge Eduardo: thats why i said he can request to follow me on ig but i didnt say i would accept the request ð\n",
      "Jorge Eduardo: i guess i just dont respect him at all anymore so idc\n",
      "Jorge Eduardo: idk why im sharing this with u lol\n",
      "Jorge Eduardo: cuz i hate when others do that to me\n",
      "Jorge Eduardo: i thought i shouldnât share negative stuff abt others behind their backs\n",
      "Jorge Eduardo: ait\n",
      "Jorge Eduardo: did u really show?\n",
      "Jorge Eduardo: cuz just by saying Korean it narrows it down and might reveal who she is\n",
      "Jorge Eduardo: dont tell him that tho\n",
      "Jorge Eduardo: there is this Korean that i befriend a few years ago and she said he was stalking her and she reported him to the uni\n",
      "Jorge Eduardo: cuz u like to see him bend over and balls\n",
      "Jorge Eduardo: idk it he knows ik those things abt him\n",
      "Jorge Eduardo: its facts tho, ive seen reports from other students\n",
      "Jorge Eduardo: omg bro is actually friends with him\n",
      "Jorge Eduardo: bro is friends with a misogynist sex offender\n",
      "Jorge Eduardo: bro i swear why do u even bother asking if u reply like this anyways\n",
      "Jorge Eduardo: by tuesday\n",
      "Jorge Eduardo: gops\n",
      "Jorge Eduardo: oh\n",
      "Jorge Eduardo: gobi?\n",
      "Jorge Eduardo: i already figured out better ways to crack it\n",
      "Jorge Eduardo: why do u think i stopped asking\n",
      "Jorge Eduardo: family bitch\n",
      "Jorge Eduardo: english fanily\n",
      "Jorge Eduardo: diss my comment yo\n",
      "Jorge Eduardo: wanna make Â£300 real quick?\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/Ax2vjgqxuxk\n",
      "Jorge Eduardo: https://youtube.com/shorts/0R71vDhoMmc?si=dIrlTNYmyydE89iO\n",
      "Jorge Eduardo: or we say it was on purpose and call it art\n",
      "Jorge Eduardo: ill forever be hunted by my single mistake\n",
      "Jorge Eduardo: yo, check my comment\n",
      "Jorge Eduardo: woman have bulge\n",
      "Jorge Eduardo: to me there are a few that look like her but u wont agree cuz they dont use that type of make up\n",
      "Jorge Eduardo: just ask any of the girls there to use makeup\n",
      "Jorge Eduardo: so u like guys\n",
      "Jorge Eduardo: bro thats a guy\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=iWgiFDTP_MU\n",
      "Jorge Eduardo: ill hold ur hand dw\n",
      "Jorge Eduardo: in this case you have more experience on the technical side so yes\n",
      "Jorge Eduardo: u will be the technical guy and ill be the business guy\n",
      "Jorge Eduardo: u should drop uni and become a plumber\n",
      "Jorge Eduardo: what a fking nerd\n",
      "Jorge Eduardo: tf\n",
      "Jorge Eduardo: 2 what\n",
      "Jorge Eduardo: ur whalecum\n",
      "Jorge Eduardo: what\n",
      "Jorge Eduardo: at least u dont send pics of whatever u u want\n",
      "Jorge Eduardo: i dont wanna give ideas\n",
      "Jorge Eduardo: nvm\n",
      "Jorge Eduardo: im profusely disappointed\n",
      "Jorge Eduardo: plz dont be what i think it is\n",
      "Jorge Eduardo: nah, im natural baby\n",
      "Jorge Eduardo: i cant laugh too loud\n",
      "Jorge Eduardo: im in the lib\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: cuz ur brain doesnt function as it should\n",
      "Jorge Eduardo: cant relate, my body works as it should\n",
      "Jorge Eduardo: so u a cow?\n",
      "Jorge Eduardo: so u made out of protein?\n",
      "Jorge Eduardo: since cows are protein they fart\n",
      "Jorge Eduardo: or that protein itself farts?\n",
      "Jorge Eduardo: so u telling me grass has protein?\n",
      "Jorge Eduardo: its screaming for help in form of smell\n",
      "Jorge Eduardo: ur body says otherwise\n",
      "Jorge Eduardo: must have been a 10\n",
      "Jorge Eduardo: nice one\n",
      "Jorge Eduardo: cuz me not there\n",
      "Jorge Eduardo: Get help\n",
      "Jorge Eduardo: fr\n",
      "Jorge Eduardo: stfu i dont need ur approval dad\n",
      "Jorge Eduardo: i still gotta learn this language some day\n",
      "Jorge Eduardo: is that why they like Ruby?\n",
      "Jorge Eduardo: average asian\n",
      "Jorge Eduardo: kekw\n",
      "Jorge Eduardo: $1 if u do\n",
      "Jorge Eduardo: i dare u to push that woman\n",
      "Jorge Eduardo: nvm\n",
      "Jorge Eduardo: and my phone isnt loading..\n",
      "Jorge Eduardo: on pc it doesnt show\n",
      "Jorge Eduardo: send normal pic\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: bto\n",
      "Jorge Eduardo: fking nerd\n",
      "Jorge Eduardo: ah u have gym\n",
      "Jorge Eduardo: but u can chill if u free...\n",
      "Jorge Eduardo: u dont have to do it since its my job\n",
      "Jorge Eduardo: wanna join\n",
      "Jorge Eduardo: im doing redstone in my mc world\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: let it cook\n",
      "Jorge Eduardo: done\n",
      "Jorge Eduardo: technically everyone is everyones cousin\n",
      "Jorge Eduardo: https://youtu.be/_F_-fTJvEw0?si=G550z5wPgdx3CViy\n",
      "Jorge Eduardo: u gotta focus\n",
      "Jorge Eduardo: shorter ones have easier access tho\n",
      "Jorge Eduardo: hows shit going\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: bro doesnt get it\n",
      "Jorge Eduardo: im going to class\n",
      "Jorge Eduardo: where tf are u son\n",
      "Jorge Eduardo: ikr lmfa\n",
      "Jorge Eduardo: thats what they all say\n",
      "Jorge Eduardo: im in asda looking for food yo\n",
      "Jorge Eduardo: bro using statistics to find the criminal\n",
      "Jorge Eduardo: thats u\n",
      "Jorge Eduardo: where tf are u samurai\n",
      "Jorge Eduardo: and i still got it wrong which makes it even funnier ð\n",
      "Jorge Eduardo: inside joke\n",
      "Jorge Eduardo: i guess its too internal\n",
      "Jorge Eduardo: funny that no one got the joke lmfao\n",
      "Jorge Eduardo: i thought u would say ratioed\n",
      "Jorge Eduardo: i was just waiting for u to say something abt it\n",
      "Jorge Eduardo: like my comment plz\n",
      "Jorge Eduardo: like vr glasses or android phones have\n",
      "Jorge Eduardo: oc it could be custom res\n",
      "Jorge Eduardo: or im over analysing a dumb fking 0 effort meme and ruining someone trash\n",
      "Jorge Eduardo: either this meme is trash and not accurate\n",
      "Jorge Eduardo: its not a thing\n",
      "Jorge Eduardo: i looked it up\n",
      "Jorge Eduardo: android phones?\n",
      "Jorge Eduardo: what kind of resolution is that\n",
      "Jorge Eduardo: also 1980?\n",
      "Jorge Eduardo: X,Y\n",
      "Jorge Eduardo: see, im right\n",
      "Jorge Eduardo: but the first one is always the X\n",
      "Jorge Eduardo: 1980 is vertical....\n",
      "Jorge Eduardo: oh wait no\n",
      "Jorge Eduardo: let me guess, is it because they have their eyes almost shut?\n",
      "Jorge Eduardo: à² _à² \n",
      "Jorge Eduardo: the ones i have dont even know how to make a website\n",
      "Jorge Eduardo: only if i had friends like that Q_Q\n",
      "Jorge Eduardo: bro is practicing\n",
      "Jorge Eduardo: ayo its my whole generation\n",
      "Jorge Eduardo: ik a guy thereâ¦\n",
      "Jorge Eduardo: instead of lib lets hangout in MI\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: where u at\n",
      "Jorge Eduardo: what a fking nerd\n",
      "Jorge Eduardo: lmfao\n",
      "Jorge Eduardo: comments\n",
      "Jorge Eduardo: yes\n",
      "Jorge Eduardo: check whats\n",
      "Jorge Eduardo: its hilareous\n",
      "Jorge Eduardo: literally cooking while fighting\n",
      "Jorge Eduardo: where they are cooking something\n",
      "Jorge Eduardo: i like the first part more\n",
      "Jorge Eduardo: u havent even seen it\n",
      "Jorge Eduardo: its the same thing just on a different level\n",
      "Jorge Eduardo: uk all those âfunnyâ tiktoks u send me\n",
      "Jorge Eduardo: its not porn tho\n",
      "Jorge Eduardo: bro just ignored all my other messages\n",
      "Jorge Eduardo: u are missing out\n",
      "Jorge Eduardo: japanese women can deffo cook something\n",
      "Jorge Eduardo: https://crazyshit.com/cnt/medias/137891-what-the-fuck-is-wrong-with-japan-volume-38\n",
      "Jorge Eduardo: https://lizengland.com/blog/2014/04/the-door-problem/\n",
      "Jorge Eduardo: good thing i came back before she came back from france\n",
      "Jorge Eduardo: HALARIOS\n",
      "Jorge Eduardo: Hello,\n",
      "\n",
      "No problem at all! I completely understand, and I'll be here when you're ready to continue our conversation. If you have any questions or need assistance in the future, don't hesitate to reach out. Take your time, and I'll be here when you're ready.\n",
      "Jorge Eduardo: thx for worrying abt my time\n",
      "Jorge Eduardo: why\n",
      "Jorge Eduardo: u speak it?\n",
      "Jorge Eduardo: english?\n",
      "Jorge Eduardo: delete more\n",
      "Jorge Eduardo: how much did u buy it for\n",
      "Jorge Eduardo: Q-Q\n",
      "Jorge Eduardo: u could buy my 8gb so that i can buy a 16gb\n",
      "Jorge Eduardo: me\n",
      "Jorge Eduardo: it just hit ne\n",
      "Jorge Eduardo: yo did u buy ur ram\n",
      "Jorge Eduardo: suh\n",
      "Jorge Eduardo: i sent it to her\n",
      "Jorge Eduardo: but ive almost sent it in some situations\n",
      "Jorge Eduardo: the only thing in this story missing is the poop\n",
      "Jorge Eduardo: and i tried to uplift her mood\n",
      "Jorge Eduardo: and spoke to me\n",
      "Jorge Eduardo: has once been upset by him\n",
      "Jorge Eduardo: she has a bf\n",
      "Jorge Eduardo: i liked her in a romantic way\n",
      "Jorge Eduardo: i have a russian friend\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: lmfaoo\n",
      "Jorge Eduardo: thats some funny shit my friend\n",
      "Jorge Eduardo: n?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: come\n",
      "Jorge Eduardo: always\n",
      "Jorge Eduardo: i actually do tho :/\n",
      "Jorge Eduardo: stap wastin mu taim\n",
      "Jorge Eduardo: suh\n",
      "Jorge Eduardo: and\n",
      "Jorge Eduardo: lmfaoo\n",
      "Jorge Eduardo: i went to brazil and now idk how to get out\n",
      "Jorge Eduardo: im lost ð£ï¸ð£ï¸\n",
      "Jorge Eduardo: https://youtube.com/shorts/TxkGYFhdggw?si=XhgC1Mtukv7fHHWO\n",
      "Jorge Eduardo: bro got fried by the Atomic man\n",
      "Jorge Eduardo: and i wont take the 5 years in prison cuz i didnt point at anyone\n",
      "Jorge Eduardo: i was thinking abt something like that actually\n",
      "Jorge Eduardo: sadly i live in UK\n",
      "Jorge Eduardo: already done too\n",
      "Jorge Eduardo: late\n",
      "Jorge Eduardo: lame, ive already done that years ago\n",
      "Jorge Eduardo: wanna come party on Friday\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: https://youtu.be/7xXARKA3O_Q?si=Hq_42BDrQojC0UR4\n",
      "Jorge Eduardo: yousef last time he has to communicate with a woman\n",
      "Jorge Eduardo: (i thought the message was from the same person)\n",
      "Jorge Eduardo: and i was like tf is going on\n",
      "Jorge Eduardo: then u said this\n",
      "Jorge Eduardo: a friend of mine said emergency\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: average of rape per new woman you meet\n",
      "Jorge Eduardo: lost kids count\n",
      "Jorge Eduardo: body count\n",
      "Jorge Eduardo: cocaine per day intake\n",
      "Jorge Eduardo: americans be like\n",
      "Jorge Eduardo: a fking whiten humanoid\n",
      "Jorge Eduardo: lmfaooooo\n",
      "Jorge Eduardo: where u at\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: ì¤ì¼\n",
      "Jorge Eduardo: ìë\n",
      "Jorge Eduardo: we have class in the first main character room\n",
      "Jorge Eduardo: why do u look exactly like him\n",
      "Jorge Eduardo: YAPIDIYAPIDILA\n",
      "Jorge Eduardo: else u would be eating donuts\n",
      "Jorge Eduardo: cuz the hormones kicked in\n",
      "Jorge Eduardo: so the doctor recommended that she should take a fat shit\n",
      "Jorge Eduardo: urs said the abortion didnt work\n",
      "Jorge Eduardo: soon\n",
      "Jorge Eduardo: https://youtube.com/shorts/RqW8oXa0GkM?si=SeWS7Y1p_eb5k2-z\n",
      "Jorge Eduardo: https://youtu.be/Ggh3Mu40200?si=PvjPDLzmkBdEC924\n",
      "Jorge Eduardo: that was petra lmfao\n",
      "Jorge Eduardo: lmfao\n",
      "Jorge Eduardo: u need glasses mate\n",
      "Jorge Eduardo: omfg\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: U think that dude is gopinat?\n",
      "Jorge Eduardo: idk him\n",
      "Jorge Eduardo: fr?\n",
      "Jorge Eduardo: game?\n",
      "Jorge Eduardo: yap yap yap\n",
      "Jorge Eduardo: if u have a different name for fat\n",
      "Jorge Eduardo: u look so fat\n",
      "Jorge Eduardo: tf\n",
      "Jorge Eduardo: have u been doing gym every single day\n",
      "Jorge Eduardo: bro u so fking buffed\n",
      "Jorge Eduardo: u aint cool bruv\n",
      "Jorge Eduardo: ì¤ì¼ ìëí\n",
      "Jorge Eduardo: yapping?\n",
      "Jorge Eduardo: now bro is nervous\n",
      "Jorge Eduardo: of ignoring\n",
      "Jorge Eduardo: after months\n",
      "Jorge Eduardo: why bro talking to me now\n",
      "Jorge Eduardo: kmsf\n",
      "Jorge Eduardo: when i ask\n",
      "Jorge Eduardo: so the Ye Men\n",
      "Jorge Eduardo: whixh\n",
      "Jorge Eduardo: cuh?\n",
      "Jorge Eduardo: in da buz\n",
      "Jorge Eduardo: monke chan\n",
      "Jorge Eduardo: moke chan\n",
      "Jorge Eduardo: 5617.977528 bananas\n",
      "Jorge Eduardo: ããããã\n",
      "Jorge Eduardo: ãããããã\n",
      "Jorge Eduardo: that mustve been painful for u\n",
      "Jorge Eduardo: pfffffffff\n",
      "Jorge Eduardo: ?\n",
      "Jorge Eduardo: also probably cuz of He Chan ãããããããã\n",
      "Jorge Eduardo: for them wlv is really really good, and its that wlv is bad, its just that its not the best but we arent grateful for all we have\n",
      "Jorge Eduardo: in Korea education is really bad\n",
      "Jorge Eduardo: its weird\n",
      "Jorge Eduardo: ill help them tho\n",
      "Jorge Eduardo: nah\n",
      "Jorge Eduardo: yas\n",
      "Jorge Eduardo: and they are extraverts\n",
      "Jorge Eduardo: ive seen 3 at least so far\n",
      "Jorge Eduardo: all of it\n",
      "Jorge Eduardo: wym\n",
      "Jorge Eduardo: all of them\n",
      "Jorge Eduardo: keep in mind thats only abt %20 of them\n",
      "Jorge Eduardo: ë´ê° 15í¼ì¼í¸ íêµ­ì¸ì´ë¼ê³  íì´\n",
      "Jorge Eduardo: ããããããããããããã\n",
      "Jorge Eduardo: ì\n",
      "Jorge Eduardo: ããããããã\n",
      "Jorge Eduardo: ãããããããããã\n",
      "Jorge Eduardo: wtf this dude talk like a redditor\n",
      "Jorge Eduardo: u\n",
      "Jorge Eduardo: sorry, ill be behave like an npc and only like anything u send\n",
      "Jorge Eduardo: its not cold or hot, its how much energy u are losing or gaining, but at some point it will equalise and u will feel normal again\n",
      "Jorge Eduardo: its like temperature\n",
      "Jorge Eduardo: but happiness is temporary\n",
      "Jorge Eduardo: u should want toâ¦ i forgot what it was\n",
      "Jorge Eduardo: u shouldnât want to be happy all the time\n",
      "Jorge Eduardo: listen to papa Alex\n",
      "Jorge Eduardo: finally i can put that gym discount they keep shoving up my face to use\n",
      "Jorge Eduardo: everyone has to start somewhere\n",
      "Jorge Eduardo: or a f for that matter\n",
      "Jorge Eduardo: nigga go get a gf\n",
      "Jorge Eduardo: ait\n",
      "Jorge Eduardo: wow\n",
      "Jorge Eduardo: ik who she is\n",
      "Jorge Eduardo: fkin weeabo\n",
      "Jorge Eduardo: outside where\n",
      "Jorge Eduardo: kek\n",
      "Jorge Eduardo: or youtube\n",
      "Jorge Eduardo: wanna watch a movie or play minecraft?\n",
      "Jorge Eduardo: u gotta keep me awake tho\n",
      "Jorge Eduardo: im suuper sleepy bro\n",
      "Jorge Eduardo: i guess\n",
      "Jorge Eduardo: im broke\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: i want that\n",
      "Jorge Eduardo: wait what\n",
      "Jorge Eduardo: https://youtu.be/2WqK09f0JFc?si=9OwZpCF_ApCgt9e_\n",
      "Jorge Eduardo: but its on her titties\n",
      "Jorge Eduardo: i want a big hot milk mama egirl to eat my libs with barbecue sauce on her titties too\n",
      "Jorge Eduardo: thats hot\n",
      "Jorge Eduardo: ( Í¡Â° ÍÊ Í¡Â°)\n",
      "Jorge Eduardo: butt plug\n",
      "Jorge Eduardo: bro is a vibrator\n",
      "Jorge Eduardo: esakly\n",
      "Jorge Eduardo: actual cringe\n",
      "Jorge Eduardo: bro watched that tiktok talking abt sleep health\n",
      "Jorge Eduardo: u sleeping?\n",
      "Jorge Eduardo: .\n",
      "Jorge Eduardo: huh?\n",
      "Jorge Eduardo: learn it now\n",
      "Jorge Eduardo: wym like what\n",
      "Jorge Eduardo: super  useful shit\n",
      "Jorge Eduardo: learn how to docker a python\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: u are the one distracting me\n",
      "Jorge Eduardo: but im\n",
      "Jorge Eduardo: 34.105.212.74\n",
      "Jorge Eduardo: kubernets\n",
      "Jorge Eduardo: Ø²ÙØ¬Ù\n",
      "Jorge Eduardo: imma learn arabic now\n",
      "Jorge Eduardo: thats amazing\n",
      "Jorge Eduardo: u guys have a word for nigger\n",
      "Jorge Eduardo: omg\n",
      "Jorge Eduardo: u said allahu akbar boom?\n",
      "Jorge Eduardo: wait what\n",
      "Jorge Eduardo: then i got distracted and forgot abt it\n",
      "Jorge Eduardo: i was gonna translate it but i kept failing to select it\n",
      "Jorge Eduardo: what does that text u sent yesterday meant?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: kubernetes\n",
      "Jorge Eduardo: i found a path btw\n",
      "Jorge Eduardo: nigga stfu\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: https://youtu.be/g72OUcarfv4?si=ZRB2XGD4jqYvcqe6\n",
      "Jorge Eduardo: more like konichiggaâ°(*Â°â½Â°*)â¯\n",
      "Jorge Eduardo: nigga what?\n",
      "Jorge Eduardo: bro black rejected me\n",
      "Jorge Eduardo: ðð¤ð¦\n",
      "Jorge Eduardo: ðï¸ððï¸'\n",
      "Jorge Eduardo: ððð\n",
      "Jorge Eduardo: thats lowkey sick ngl\n",
      "Jorge Eduardo: cute dates are overrated\n",
      "Jorge Eduardo: thats a good stoic practice, but make sure u do it for the uncomforting you feel and not something else\n",
      "Jorge Eduardo: yousef\n",
      "Jorge Eduardo: be content with yourself\n",
      "Jorge Eduardo: wives are overrated\n",
      "Jorge Eduardo: sadly it only lasts for abt 3 months, after that u gotta find another bitch\n",
      "Jorge Eduardo: that way porn will be obsolete, u wont even like it cuz ur imagination is just so much better\n",
      "Jorge Eduardo: and if u cant then go out with bitches so u can have a better imagination\n",
      "Jorge Eduardo: just use ur imagination bro\n",
      "Jorge Eduardo: u mean no porn right\n",
      "Jorge Eduardo: why no nut\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=T77MmWALKVY\n",
      "Jorge Eduardo: bro wished he was white\n",
      "Jorge Eduardo: are you proud of me yet?\n",
      "Jorge Eduardo: cuz we are shit bros\n",
      "Jorge Eduardo: push what uve done to main\n",
      "Jorge Eduardo: just like a romanian would\n",
      "Jorge Eduardo: im still in since years ago\n",
      "Jorge Eduardo: i didnt do yet cuz i hate them so ive been procrastinating\n",
      "Jorge Eduardo: i gotta do the drawings\n",
      "Jorge Eduardo: but finishing my shit a quick fap ill come back\n",
      "Jorge Eduardo: got busy\n",
      "Jorge Eduardo: fr ð\n",
      "Jorge Eduardo: earn?\n",
      "Jorge Eduardo: so i dont even qualify for it anyways if its already a thing\n",
      "Jorge Eduardo: now u would need to stay here for 9 years\n",
      "Jorge Eduardo: plus my dad said they will make it harder to get a passport\n",
      "Jorge Eduardo: im already settled\n",
      "Jorge Eduardo: i dont get it why everyone thinks the passport is so important\n",
      "Jorge Eduardo: or from the app\n",
      "Jorge Eduardo: i can just get the passport later\n",
      "Jorge Eduardo: why\n",
      "Jorge Eduardo: and the tower will allow me to have my own cloud and run the app much easier and even train my own models\n",
      "Jorge Eduardo: cuz i dont travel\n",
      "Jorge Eduardo: i think imma buy the tower with the maintenance loan instead of a british passport\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: also they have almost 1giga for Â£52\n",
      "Jorge Eduardo: faster for cheaper tf\n",
      "Jorge Eduardo: weird\n",
      "Jorge Eduardo: so if we downgrade to a 5G which is probably around Â£10 a month i guess it would be cheaper\n",
      "Jorge Eduardo: i saw its basically Â£20 for the cheapest\n",
      "Jorge Eduardo: plus wifi gives me ability to open ports which would be something amazing for me\n",
      "Jorge Eduardo: but now with my brother here it doesnt make sense anymore\n",
      "Jorge Eduardo: we dont have wifi cuz its cheaper only data\n",
      "Jorge Eduardo: what else am i gonna use\n",
      "Jorge Eduardo: Â£22 i think\n",
      "Jorge Eduardo: EE\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: nvm\n",
      "Jorge Eduardo: they are forever loading\n",
      "Jorge Eduardo: did u send 2 pics?\n",
      "Jorge Eduardo: how do u see like count?\n",
      "Jorge Eduardo: no fking way ð\n",
      "Jorge Eduardo: on your way\n",
      "Jorge Eduardo: one sec\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=V2i_NReAOaw\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=J1XTHNGNj4Q\n",
      "Jorge Eduardo: this is how we make money, forget the romanian, put trump on it\n",
      "Jorge Eduardo: actually they called me\n",
      "Jorge Eduardo: that was a bald move\n",
      "Jorge Eduardo: oh, i thought we had something in common\n",
      "Jorge Eduardo: wait u fight ppl on pornhub comments?\n",
      "Jorge Eduardo: is it?\n",
      "Jorge Eduardo: ohhh pornhub\n",
      "Jorge Eduardo: main character houses?\n",
      "Jorge Eduardo: pH? like acidity?\n",
      "Jorge Eduardo: and whats crazier, some ppl actually think social media is the internet\n",
      "Jorge Eduardo: investigate what is the internet\n",
      "Jorge Eduardo: i wanted to see how bad it got\n",
      "Jorge Eduardo: it was for research purposes\n",
      "Jorge Eduardo: grey mass\n",
      "Jorge Eduardo: i lost at least 5kg of brain mass every minute i was there\n",
      "Jorge Eduardo: worst shit for the mind ever\n",
      "Jorge Eduardo: my twitter used to be reddit comments on news posts\n",
      "Jorge Eduardo: i actually dont use twitter\n",
      "Jorge Eduardo: i go away from twitter but twitter doesnt go away from me\n",
      "Jorge Eduardo: holy shit\n",
      "Jorge Eduardo: as i said before, maybe in 20 years? i actually have no idea abt that, i dont think this has ever happened before, but with AI we could simulate it and see if its good or not\n",
      "Jorge Eduardo: simple questions for complex issues\n",
      "Jorge Eduardo: saying things like that should be illegal\n",
      "Jorge Eduardo: they could be harming ppl in some way\n",
      "Jorge Eduardo: thats also superficial\n",
      "Jorge Eduardo: stoicism is basically the best part of all our society\n",
      "Jorge Eduardo: so my beliefs are whatever values brings out the best of u is what u should stick with\n",
      "Jorge Eduardo: or allah in your case im guessing\n",
      "Jorge Eduardo: we arent jesus to save literally every single human on this earth\n",
      "Jorge Eduardo: let them ruin their lives\n",
      "Jorge Eduardo: they are adults\n",
      "Jorge Eduardo: and for what?\n",
      "Jorge Eduardo: we arent gonna babysit them are we\n",
      "Jorge Eduardo: but thats not our problem\n",
      "Jorge Eduardo: ye i also agree with that lmfao\n",
      "Jorge Eduardo: sounds a lot like those communists twitting abt who they hate capitalist on their $1000 phones\n",
      "Jorge Eduardo: so when u say liberal, are u mad at creative ppl who invented the phone u are using to be mad on twitter\n",
      "Jorge Eduardo: like steve jobs\n",
      "Jorge Eduardo: liberal means creativity, means thinking out of the box\n",
      "Jorge Eduardo: same with jordan peterson, he wants good for me cuz thats his job, and he is a liberal, else he couldnt have the job he has\n",
      "Jorge Eduardo: i used to think ben shapiro was trying to tell me how to get a better life, and i still think he is but when he gets mad at someone  cuz he thinks that person is liberal when they are indeed on his team it just makes me realise what these ppl really are after\n",
      "Jorge Eduardo: its a common occurrence\n",
      "Jorge Eduardo: and people who have the right values are the ones who consider themselves liberals\n",
      "Jorge Eduardo: ppl who call themselves conservatives are just far left who are mad at something, u just gotta figure out what exactly u are mad, i mean for real, it can be some parental issue\n",
      "Jorge Eduardo: u know whats funny\n",
      "Jorge Eduardo: andrew tate is stoic/muslim because of how it helps him think, just like steve jobs only wears one type of tshirt, and i like that, saving decisions is an engineering thing\n",
      "Jorge Eduardo: i mean\n",
      "Jorge Eduardo: i will, once i get enough time\n",
      "Jorge Eduardo: numbers are only one part of the stories\n",
      "Jorge Eduardo: papers, history\n",
      "Jorge Eduardo: basically what your religions was built on top of\n",
      "Jorge Eduardo: i didnt say without, my values are stoics\n",
      "Jorge Eduardo: just a hint fo ru\n",
      "Jorge Eduardo: liberal isnt lgbqt\n",
      "Jorge Eduardo: cuz being on tiktok all day ranging isnt life\n",
      "Jorge Eduardo: trying to show ppl the better way to live life\n",
      "Jorge Eduardo: im a teacher remember\n",
      "Jorge Eduardo: im not mad\n",
      "Jorge Eduardo: by the contrary\n",
      "Jorge Eduardo: do you even know what liberal means?\n",
      "Jorge Eduardo: and by the americans too\n",
      "Jorge Eduardo: you are so brainwasched\n",
      "Jorge Eduardo: holy shiet\n",
      "Jorge Eduardo: tiktok\n",
      "Jorge Eduardo: again\n",
      "Jorge Eduardo: see\n",
      "Jorge Eduardo: is it really 100% religion\n",
      "Jorge Eduardo: why u so mad abt it\n",
      "Jorge Eduardo: a korean AI to be precise\n",
      "Jorge Eduardo: u need an AI girlfriend my guy\n",
      "Jorge Eduardo: honestly that would be my goal, most ppl wanna die at 100, i just wanna figure out wtf is outside this universe, AI gives me hope to this which is why i take it so serious\n",
      "Jorge Eduardo: this is what i mean with be the best of urself u can be and the rest falls into place, worrying abt hoes making more than us making AI that can save lives is the super superficial, cuz like u dont know if those hoes are saving millions of men from depression(its an example, im an abstract person, java)\n",
      "Jorge Eduardo: forget youtube home, only use the search to search for unity tutorials\n",
      "Jorge Eduardo: live on the world of tutorials and documentations like i do\n",
      "Jorge Eduardo: plz just stop social media for a whole month\n",
      "Jorge Eduardo: isnt is obvious\n",
      "Jorge Eduardo: stop, getting, caught, on these easy traps\n",
      "Jorge Eduardo: jobs we thought we needed and were important will be things from the past\n",
      "Jorge Eduardo: the pyramid is being turned upside down\n",
      "Jorge Eduardo: AI is changing the whole game\n",
      "Jorge Eduardo: just wait\n",
      "Jorge Eduardo: wait\n",
      "Jorge Eduardo: the economy in this earth is a single big loop being fed only by the sun\n",
      "Jorge Eduardo: maybe we just dont need doctors as much? hoes dont get hurt, so maybe we had a lack of doctors cuz of wars, and now with good tech ppl are healthier than ever and dont need doctors\n",
      "Jorge Eduardo: but then how can the hospital afford, so complain to the patients or whoever pays\n",
      "Jorge Eduardo: why tf arent they striking more\n",
      "Jorge Eduardo: tell that to doctors\n",
      "Jorge Eduardo: im talking abt helping, economically rn, maybe in 20 years they arent helping cuz they are destroying values which is what keeps the country also running. But im talking of the measurements that we can do and predictions we can make in the real world\n",
      "Jorge Eduardo: rooting from a single bad grain\n",
      "Jorge Eduardo: like yeast\n",
      "Jorge Eduardo: it seems like that indeed\n",
      "Jorge Eduardo: we can give all our bank balance away and buy tons of burgers and pizza but without recording it and posting on tiktok we would only be able to do 0.000001% of what those hoes do to the \"poor\" in a day\n",
      "Jorge Eduardo: they are helping the \"poor\" whatever that means more than we are\n",
      "Jorge Eduardo: those hoes are actually helping the economy more than us rn\n",
      "Jorge Eduardo: money needs to move\n",
      "Jorge Eduardo: in reality yes thats how it works\n",
      "Jorge Eduardo: literally\n",
      "Jorge Eduardo: sheeps\n",
      "Jorge Eduardo: redditors honestly think USA is helping Ukraine, and that Russia should just stop the war now\n",
      "Jorge Eduardo: i talk to opposite actually, i read a lot of redditors and their opinions are always so superficial, they truly believe what they see on the news is true when they can literally just open their eyes and see the truth in the real world\n",
      "Jorge Eduardo: no offence but since u crossed that line\n",
      "Jorge Eduardo: tho andrew tate talks more logic than you\n",
      "Jorge Eduardo: and you are talking instagram reels of andrew tate logic\n",
      "Jorge Eduardo: when im talking numbers\n",
      "Jorge Eduardo: why is it always me who doesnt get it\n",
      "Jorge Eduardo: nukes are like AI because of the capitalistic system we live in, we see the deathtrap but we have no other choice than to run towards it else we die\n",
      "Jorge Eduardo: thats a whole different thing\n",
      "Jorge Eduardo: if they legalized drugs in mexico u would have all those cartels killing so many ppl\n",
      "Jorge Eduardo: portugal is a living proof\n",
      "Jorge Eduardo: all that comes from stopping this from happening\n",
      "Jorge Eduardo: and the problem is the engineers\n",
      "Jorge Eduardo: people dont have contro\n",
      "Jorge Eduardo: dont let ppl buy too many beers or too much weed thats all\n",
      "Jorge Eduardo: its the amount of use\n",
      "Jorge Eduardo: look at car accidents\n",
      "Jorge Eduardo: the issue isnt drugs\n",
      "Jorge Eduardo: anything moving money\n",
      "Jorge Eduardo: it is but where tf u got that logic\n",
      "Jorge Eduardo: neither Alex Hormozi\n",
      "Jorge Eduardo: so you saying Elon musk doesnt deserve everything hes got?\n",
      "Jorge Eduardo: a person making millions using what they were given is an amazing skill\n",
      "Jorge Eduardo: you know what i mean by tiktok, social media, youtube shorts, instagram reels\n",
      "Jorge Eduardo: yes that was a joke, 9/11 was an inside job\n",
      "Jorge Eduardo: we are the engineers, we construct what the public consumes\n",
      "Jorge Eduardo: tiktok is for the public\n",
      "Jorge Eduardo: didnt u see i literally came with numbers cuz i had no idea abt onlyfans and doctors statistics, stop taking tiktok as facts\n",
      "Jorge Eduardo: idk everything, which is why im always studying\n",
      "Jorge Eduardo: just like the muslims started 9/11 u started this bro\n",
      "Jorge Eduardo: your religion is against violence, but once a muslim eats a pig u will quickly jump on him and judge him or even hurt him\n",
      "Jorge Eduardo: see, contradiction\n",
      "Jorge Eduardo: one day u will get it\n",
      "Jorge Eduardo: u say, money is good but we dont flex, but that hoe that worked and risked her life is rich, fuck her\n",
      "Jorge Eduardo: like u guys make sense, until we bring the world hoe or not halal\n",
      "Jorge Eduardo: why are muslims so contractionary\n",
      "Jorge Eduardo: im defending the good mentality\n",
      "Jorge Eduardo: thats what we dont do, we dont risk shit\n",
      "Jorge Eduardo: i mean put work in and risk something\n",
      "Jorge Eduardo: people willing to do raise their fingers\n",
      "Jorge Eduardo: not hoes\n",
      "Jorge Eduardo: or is it your mentality of being a victim\n",
      "Jorge Eduardo: are NBA really the problem\n",
      "Jorge Eduardo: so now you tell me\n",
      "Jorge Eduardo: thats 4M people\n",
      "Jorge Eduardo: it seems like around 2% of onlyfans creators are making $100k a year\n",
      "Jorge Eduardo: $100k\n",
      "Jorge Eduardo: who are 100% making $100 on average\n",
      "Jorge Eduardo: 102,400,000 of doctors\n",
      "Jorge Eduardo: same thing goes for doctors\n",
      "Jorge Eduardo: meaning we need more workers and more efficient tech and more research\n",
      "Jorge Eduardo: cuz those creators will spend money on the very products those workers are producing\n",
      "Jorge Eduardo: thing*\n",
      "Jorge Eduardo: and thats a good think\n",
      "Jorge Eduardo: that means, money going from worker to entertainment(since onlyfans is all abt hidden perks like patreon, not just naked hoes)\n",
      "Jorge Eduardo: so thats $30B circulating\n",
      "Jorge Eduardo: first, onlyfans has 200M creators and the average is around $150 a month\n",
      "Jorge Eduardo: thats the wrong way of looking at things\n",
      "Jorge Eduardo: cuz if u do that then everything else fits into place\n",
      "Jorge Eduardo: best u can do is be ur better self and fk everyone else\n",
      "Jorge Eduardo: it is what it is\n",
      "Jorge Eduardo: a girl that is recorded on camera and posted on tiktok gets millions while millions of ppl literally starving in front of the house of those same ppl who donated will be ignored\n",
      "Jorge Eduardo: indeed\n",
      "Jorge Eduardo: actually zuck made the worst deal than elon tho(talking abt metaverse vs twitter), so its like two trolls getting trolled\n",
      "Jorge Eduardo: this society we live is amazing, a fight is worth more because it has more entertaining value\n",
      "Jorge Eduardo: stealing zuck?\n",
      "Jorge Eduardo: usually u get used the more it gets used\n",
      "Jorge Eduardo: and he will, but since time is relative he will only stop his own time\n",
      "Jorge Eduardo: bro thinks he is gonna stop time\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=jjs2vPR19mQ\n",
      "Jorge Eduardo: bro drinks coffee when ppl drink spiders (cuz they are sleeping rn)\n",
      "Jorge Eduardo: just give me the actual file\n",
      "Jorge Eduardo: do u have some of that good old crack?\n",
      "Jorge Eduardo: ait\n",
      "Jorge Eduardo: aesprite or ps?\n",
      "Jorge Eduardo: so\n",
      "Jorge Eduardo: eggxactly\n",
      "Jorge Eduardo: for the modding\n",
      "Jorge Eduardo: assets work too\n",
      "Jorge Eduardo: thats how we call it in minecraft\n",
      "Jorge Eduardo: so instead of learning how to make a pixel editor, i made a python program to do it for me\n",
      "Jorge Eduardo: u know, a while ago i needed minecraft textures and i didnt know there was already a program for it\n",
      "Jorge Eduardo: cuz u are doing them lol\n",
      "Jorge Eduardo: there is no graphics\n",
      "Jorge Eduardo: yes and?\n",
      "Jorge Eduardo: do i have to buy it?\n",
      "Jorge Eduardo: just give me the program for it\n",
      "Jorge Eduardo: sure\n",
      "Jorge Eduardo: lmfao\n",
      "Jorge Eduardo: so ill just draw everything (or make a bot to draw it for me)\n",
      "Jorge Eduardo: cuz those packs are just garbage\n",
      "Jorge Eduardo: cuz thats my weak spot and i need to improve it\n",
      "Jorge Eduardo: imma work on the looks then\n",
      "Jorge Eduardo: ait\n",
      "Jorge Eduardo: ah\n",
      "Jorge Eduardo: gets a korean bitch on september\n",
      "Jorge Eduardo: who finishes first\n",
      "Jorge Eduardo: so u do the cop i do the lock picking\n",
      "Jorge Eduardo: the cop and u is the bar\n",
      "Jorge Eduardo: yeye\n",
      "Jorge Eduardo: dont even need one\n",
      "Jorge Eduardo: ill do the tap one then\n",
      "Jorge Eduardo: sure\n",
      "Jorge Eduardo: but also the closer the cop gets to u\n",
      "Jorge Eduardo: the more u tap the more u get\n",
      "Jorge Eduardo: no\n",
      "Jorge Eduardo: actually\n",
      "Jorge Eduardo: so 2 types of steal\n",
      "Jorge Eduardo: i like that\n",
      "Jorge Eduardo: yes\n",
      "Jorge Eduardo: whats stopping u\n",
      "Jorge Eduardo: what thing?\n",
      "Jorge Eduardo: what are u thinking on doing?\n",
      "Jorge Eduardo: i still have no idea what to do for the lock picking\n",
      "Jorge Eduardo: honestly, i was watching a guy go abt it, and it seems like we just gotta stick to something very very simple around a main theme, our main theme is rush game, so just the lock picking and a cop behind to justify why we are running\n",
      "Jorge Eduardo: right\n",
      "Jorge Eduardo: the gamee\n",
      "Jorge Eduardo: where tf are u\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: how was the metaverse bro\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=KW64FiB0ITg\n",
      "Jorge Eduardo: we need the houses\n",
      "Jorge Eduardo: what else u wanna do\n",
      "Jorge Eduardo: thats the good part abt scripts, they can be easily changed\n",
      "Jorge Eduardo: then random houses on top\n",
      "Jorge Eduardo: so just a straight line right?\n",
      "Jorge Eduardo: oh\n",
      "Jorge Eduardo: you make the sprites\n",
      "Jorge Eduardo: only difference is that i wont be making the presets\n",
      "Jorge Eduardo: what ill do is similar\n",
      "Jorge Eduardo: presets\n",
      "Jorge Eduardo: the guy creates a bunch of prests and randomly places them down\n",
      "Jorge Eduardo: the first vid u sent\n",
      "Jorge Eduardo: its nice if u are a beginning and have a whole year to make just the map\n",
      "Jorge Eduardo: i just hate the concept that guy on the video showed\n",
      "Jorge Eduardo: already made a simple platform\n",
      "Jorge Eduardo: and then once u make houses we can easily just add that to the script\n",
      "Jorge Eduardo: but rn ill focus on creating the layer of the map\n",
      "Jorge Eduardo: u can make better ones later\n",
      "Jorge Eduardo: i created some basic gameobjects and figured how to use them with the script\n",
      "Jorge Eduardo: ok so\n",
      "Jorge Eduardo: but the platforms will be created algorithmically\n",
      "Jorge Eduardo: lets do that\n",
      "Jorge Eduardo: you want a platform game\n",
      "Jorge Eduardo: ok\n",
      "Jorge Eduardo: so\n",
      "Jorge Eduardo: or u still waiting for my pp\n",
      "Jorge Eduardo: have u implemented that platform thing\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: lib\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: fix ur sleep fr\n",
      "Jorge Eduardo: i need to\n",
      "Jorge Eduardo: im on pc\n",
      "Jorge Eduardo: discord\n",
      "Jorge Eduardo: bro calls me then goes away\n",
      "Jorge Eduardo: tf\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: im home\n",
      "Jorge Eduardo: idea: easy read with audio using whisper\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: why\n",
      "Jorge Eduardo: 1h-2h\n",
      "Jorge Eduardo: I'm kind of busy right now\n",
      "Jorge Eduardo: i fking hate internet button âââââââ>\n",
      "Jorge Eduardo: broo imagine this on ue\n",
      "Jorge Eduardo: cmon\n",
      "Jorge Eduardo: but im coming to the library now\n",
      "Jorge Eduardo: im sitting outside cuz i was programming java with a friend\n",
      "Jorge Eduardo: library\n",
      "Jorge Eduardo: plus its not icc\n",
      "Jorge Eduardo: it translates to that tho\n",
      "Jorge Eduardo: but if u are stopped by simple things u will never do anything\n",
      "Jorge Eduardo: etc\n",
      "Jorge Eduardo: then 3\n",
      "Jorge Eduardo: next time u can do 2 hours\n",
      "Jorge Eduardo: and\n",
      "Jorge Eduardo: stop being lazy\n",
      "Jorge Eduardo: just come here\n",
      "Jorge Eduardo: why\n",
      "Jorge Eduardo: wym\n",
      "Jorge Eduardo: hurry up then\n",
      "Jorge Eduardo: wait faster\n",
      "Jorge Eduardo: when u here?\n",
      "Jorge Eduardo: icc closes at 7\n",
      "Jorge Eduardo: it stays closer till 9\n",
      "Jorge Eduardo: we stay at the lib\n",
      "Jorge Eduardo: also\n",
      "Jorge Eduardo: msg me when u here\n",
      "Jorge Eduardo: https://maps.apple.com/?ll=52.479203,-1.899546&q=My%20Location&t=h\n",
      "Jorge Eduardo: 5 mins away from icc\n",
      "Jorge Eduardo: im in town\n",
      "Jorge Eduardo: are u here?\n",
      "Jorge Eduardo: noping\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: CUM FASTER\n",
      "Jorge Eduardo: imma fap if u dont come\n",
      "Jorge Eduardo: where tf are u\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: the one u have at 4am\n",
      "Jorge Eduardo: did u mean muslim lunch\n",
      "Jorge Eduardo: cum over\n",
      "Jorge Eduardo: always\n",
      "Jorge Eduardo: youtube got me confused with u so here it is the video they intended u to watch\n",
      "Jorge Eduardo: https://youtu.be/xwrs-9-XkMw\n",
      "Jorge Eduardo: when\n",
      "Jorge Eduardo: 15 evidences to be precise\n",
      "Jorge Eduardo: i already got some evidence\n",
      "Jorge Eduardo: oh and that big milkers have an oc\n",
      "Jorge Eduardo: i mean meet later?\n",
      "Jorge Eduardo: wanna fuck later?\n",
      "Jorge Eduardo: im going to sleep now\n",
      "Jorge Eduardo: also\n",
      "Jorge Eduardo: instagram figured out my fetish bro, help\n",
      "Jorge Eduardo: its not? then what is ur biggest fear\n",
      "Jorge Eduardo: bros scariest app\n",
      "Jorge Eduardo: so cute *-*\n",
      "Jorge Eduardo: vruh\n",
      "Jorge Eduardo: ðð\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: its dead and its weird\n",
      "Jorge Eduardo: with the ppl on floating chairs\n",
      "Jorge Eduardo: its like that walle movie\n",
      "Jorge Eduardo: i dont even watch anymore cuz its just dead\n",
      "Jorge Eduardo: yes and all my friends sending me so many memes\n",
      "Jorge Eduardo: elon musk feet is hot\n",
      "Jorge Eduardo: whatever i watch instagram pushes to u to watch it too\n",
      "Jorge Eduardo: im certain im basically ur influencer\n",
      "Jorge Eduardo: instagram is so repetitive\n",
      "Jorge Eduardo: u send me shit i already saw at least 10 times in the last week alone\n",
      "Jorge Eduardo: bro stop sending memes\n",
      "Jorge Eduardo: https://youtube.com/shorts/Q2grU1ato4M?feature=share\n",
      "Jorge Eduardo: bro judging his homie for trying to improve\n",
      "Jorge Eduardo: goes to show that u arent the same when u are hungry\n",
      "Jorge Eduardo: is she on her period again?\n",
      "Jorge Eduardo: x.com\n",
      "Jorge Eduardo: check with your ex\n",
      "Jorge Eduardo: no shame, just grind\n",
      "Jorge Eduardo: to whatever meme is trending\n",
      "Jorge Eduardo: we literally just copy subway surfer but change the skins\n",
      "Jorge Eduardo: simple yet effective\n",
      "Jorge Eduardo: thats perfect\n",
      "Jorge Eduardo: capybara rush\n",
      "Jorge Eduardo: yep\n",
      "Jorge Eduardo: tru\n",
      "Jorge Eduardo: flappy birds but with the gay flag as the background\n",
      "Jorge Eduardo: but thats thinking too far ahead, we still need the game lmfao\n",
      "Jorge Eduardo: use it as a bait\n",
      "Jorge Eduardo: but we dont add any ads\n",
      "Jorge Eduardo: just make a simple game, doesnt have to be crazy\n",
      "Jorge Eduardo: organic marketing\n",
      "Jorge Eduardo: youtube\n",
      "Jorge Eduardo: 3 years min\n",
      "Jorge Eduardo: and not 3 months\n",
      "Jorge Eduardo: but push that\n",
      "Jorge Eduardo: anything\n",
      "Jorge Eduardo: im not talking abt games\n",
      "Jorge Eduardo: i figured out a way to do the voice clonning locally so not to pay elevenlabs\n",
      "Jorge Eduardo: ive been busy with the translator thing\n",
      "Jorge Eduardo: have u got started yet?\n",
      "Jorge Eduardo: so\n",
      "Jorge Eduardo: rat game\n",
      "Jorge Eduardo: but it doesnt make sense, its like work, if u work today u get paid, but u gotta keep working the next day to earn the next day too\n",
      "Jorge Eduardo: how are u gonna pay the api?\n",
      "Jorge Eduardo: like me with my tiktok bots\n",
      "Jorge Eduardo: u are thinking abt ignoring quality over quantity right\n",
      "Jorge Eduardo: like minecraft\n",
      "Jorge Eduardo: if u make an actual good game u only make it once and never again\n",
      "Jorge Eduardo: if u live in the trends u will always be running\n",
      "Jorge Eduardo: trends die\n",
      "Jorge Eduardo: so even when we thought abt it like around 7 months ago many ppl already had working games, using elevenlabs whisper and gpt\n",
      "Jorge Eduardo: then we saw many ppl making it\n",
      "Jorge Eduardo: me and Joshua were already thinking of making a gpt sort of game a while back\n",
      "Jorge Eduardo: abt how slapping AI on a product is short sighted\n",
      "Jorge Eduardo: i was trying to show a point\n",
      "Jorge Eduardo: u know\n",
      "Jorge Eduardo: they me if they make sense\n",
      "Jorge Eduardo: so i added some instructions\n",
      "Jorge Eduardo: ik u dont know how to use git\n",
      "Jorge Eduardo: https://github.com/bomxacalaka/makeitreal\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=3tQH4wvQCfc\n",
      "Jorge Eduardo: tho minecraft multiplayer got ruined after 1.14\n",
      "Jorge Eduardo: like minecraft versions, im still on 1.19.2 cuz the new ones still dont have many cool mods\n",
      "Jorge Eduardo: i usually like to use old versions cuz they are more compatible with everything\n",
      "Jorge Eduardo: is this version gonna work?\n",
      "Jorge Eduardo: why\n",
      "Jorge Eduardo: does this answer?\n",
      "Jorge Eduardo: why does it matter\n",
      "Jorge Eduardo: im almost done setting up the git\n",
      "Jorge Eduardo: if u wanna start now thats fine\n",
      "Jorge Eduardo: so\n",
      "Jorge Eduardo: sadly they get banned, else i would have so many followers\n",
      "Jorge Eduardo: another bot following me\n",
      "Jorge Eduardo: just cuz he is black\n",
      "Jorge Eduardo: u mean this masterpiece?\n",
      "Jorge Eduardo: what art?\n",
      "Jorge Eduardo: just use instagram, whatever game u find interesting where ppl in the comments are mad that this isnt like the real game we just turn it real\n",
      "Jorge Eduardo: this was just a random pic i found on google to help explain what sort of games im talking abt\n",
      "Jorge Eduardo: are u talking abt this?\n",
      "Jorge Eduardo: just a png right?\n",
      "Jorge Eduardo: we make the assets....\n",
      "Jorge Eduardo: we havent even made the game yet callm down\n",
      "Jorge Eduardo: huh? whos 3d\n",
      "Jorge Eduardo: look for low hanging stuff\n",
      "Jorge Eduardo: remember what u told me, u dont need to make things complicated to make money\n",
      "Jorge Eduardo: we dont need gpt to make a game\n",
      "Jorge Eduardo: bro really thinks chatgpt is AGI\n",
      "Jorge Eduardo: bro, when i talk abt AI i mean in terms of games\n",
      "Jorge Eduardo: well, the hero is trying to get to the gold\n",
      "Jorge Eduardo: we just make them but add an extra sauce\n",
      "Jorge Eduardo: have u never seen these game ads?\n",
      "Jorge Eduardo: its simple but i love the dirt particle thing\n",
      "Jorge Eduardo: or place dirt on top of the enemy to defend the protagonist\n",
      "Jorge Eduardo: but instead of having to pull a stick, u have to place dirt particles to make a stair\n",
      "Jorge Eduardo: and then u have a logic game where there are AI things trying to get to an objective\n",
      "Jorge Eduardo: the powder toy whcih is a simulation game, u can throw powder, fire water etc\n",
      "Jorge Eduardo: imagine these 2 together\n",
      "Jorge Eduardo: here\n",
      "Jorge Eduardo: its a mix of that game of logic with simulation hold on\n",
      "Jorge Eduardo: i was thinking, what if we get like a bunch of AI npcs walking around trying to get to an objective and the user needs to stop using elements\n",
      "Jorge Eduardo: yeah keep it simple\n",
      "Jorge Eduardo: hm so many im not sure which one to go for\n",
      "Jorge Eduardo: those are the low hanging fruits we can use to train how to work in group\n",
      "Jorge Eduardo: like those instagram ads that everyone complains isnt the actual game\n",
      "Jorge Eduardo: im thinking of just clonning others games\n",
      "Jorge Eduardo: the 2D games\n",
      "Jorge Eduardo: so\n",
      "Jorge Eduardo: ill explain another time\n",
      "Jorge Eduardo: lets keep it simple\n",
      "Jorge Eduardo: nvm u arent there yet\n",
      "Jorge Eduardo: im not thinking abt the best gpt, im thinking abt something much much bigger, a machine that learns forever\n",
      "Jorge Eduardo: it will be enough\n",
      "Jorge Eduardo: if u want 0 effort game then this isnt the path for u, just use gpt-3.5 api\n",
      "Jorge Eduardo: bro, its not the results, its the possibilities\n",
      "Jorge Eduardo: but we can also use falcon7B, its much harder to train, so forget having amazing npcs, but if its for a game where the npc only needs a bit of context then its perfect, so its also better than gpt3\n",
      "Jorge Eduardo: gpt2 can be trained on my laptop easily\n",
      "Jorge Eduardo: this isnt like \"if its not the latest model i dont want it\" its more like, can this be used as an npc and what can it do in real time on someones pc offline\n",
      "Jorge Eduardo: stop thinking like a small brain youtuber\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: it would take u millions of dollars just to finetune it, but those models arent public\n",
      "Jorge Eduardo: impossible\n",
      "Jorge Eduardo: they were scared of releasing their biggest versions for obvious reasons the 1.7B\n",
      "Jorge Eduardo: 177M\n",
      "Jorge Eduardo: plus its the smallest version of gpt2\n",
      "Jorge Eduardo: trust me its amazing\n",
      "Jorge Eduardo: yes\n",
      "Jorge Eduardo: the more u talk to it the more it learns\n",
      "Jorge Eduardo: imagine like a chatgpt with infinite context basically\n",
      "Jorge Eduardo: first is how to finetune gpt2, i can even do it on my pc, so this could work on in real time\n",
      "Jorge Eduardo: https://colab.research.google.com/drive/1IqL0ay04RwNNcn5R7HzhgBqZ2lPhHloh\n",
      "Jorge Eduardo: https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/311_fine_tuning_GPT2.ipynb\n",
      "Jorge Eduardo: ive found two ways to finetune these models to custom data, but overtraining is still something im figuring out\n",
      "Jorge Eduardo: imagine like a bunch of gpt-4 clicking on links and reading everything they see, but with memory so they have an objective and wont visit the same link twice and be very efficient, aka agents\n",
      "Jorge Eduardo: openai is gonna use agents to scrape the net\n",
      "Jorge Eduardo: its better to pay someone to do it for u\n",
      "Jorge Eduardo: they are annoying and hard to make\n",
      "Jorge Eduardo: dont\n",
      "Jorge Eduardo: plus the way i see u doing it is using the api right? that will be costly, ik a way to do it for free and better than gpt api\n",
      "Jorge Eduardo: too many ppl already did it\n",
      "Jorge Eduardo: too late\n",
      "Jorge Eduardo: nah\n",
      "Jorge Eduardo: ill make it 2d first on unity to keep things simple\n",
      "Jorge Eduardo: im setting up the repo for us to work on a game together\n",
      "Jorge Eduardo: wanna do the unity game stuff\n",
      "Jorge Eduardo: im glad i got ur attention\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=DshRqV_wj5w\n",
      "Jorge Eduardo: 2:36 is my fav lmfao\n",
      "Jorge Eduardo: and accidently found gold\n",
      "Jorge Eduardo: i was looking for some gore shit\n",
      "Jorge Eduardo: i wasnt even looking for porn\n",
      "Jorge Eduardo: hholy shit\n",
      "Jorge Eduardo: this website is top humour\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: https://efukt.com/22546_Amatuer_Sex_Tape_Fails_2018.html\n",
      "Jorge Eduardo: since u like those weirdos jav\n",
      "Jorge Eduardo: https://efukt.com/24046_Psychotic_18_Year_Old_Terrorizes_Strangers.html\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: ait mister thinks he is that guy\n",
      "Jorge Eduardo: thats where im the most productive\n",
      "Jorge Eduardo: why not?\n",
      "Jorge Eduardo: u said u wanted to tell me what u were working on when we meet\n",
      "Jorge Eduardo: broo come upp stop being lazy\n",
      "Jorge Eduardo: wake the fuck up samurai\n",
      "Jorge Eduardo: come over\n",
      "Jorge Eduardo: yo hoe\n",
      "Jorge Eduardo: ok i found a way to automate stars\n",
      "Jorge Eduardo: blyat\n",
      "Jorge Eduardo: such a cute gay couple\n",
      "Jorge Eduardo: Yo comeicc\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=c_nCjlSB1Zk\n",
      "Jorge Eduardo: bro just left me hanging Q-Q\n",
      "Jorge Eduardo: 52.47984800133375, -1.9087838815649967\n",
      "Jorge Eduardo: to be expected\n",
      "Jorge Eduardo: run else they will escape\n",
      "Jorge Eduardo: tons of bitches bro\n",
      "Jorge Eduardo: bro has to make sure he is late\n",
      "Jorge Eduardo: late\n",
      "Jorge Eduardo: oh yeah thats right\n",
      "Jorge Eduardo: where u at\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: bet\n",
      "Jorge Eduardo: bey\n",
      "Jorge Eduardo: thats gae\n",
      "Jorge Eduardo: more excuses Q-Q\n",
      "Jorge Eduardo: bro pulled every excuse and found a million creative ways to say no\n",
      "Jorge Eduardo: bro said no to meeting his only and best friend\n",
      "Jorge Eduardo: hurry bish\n",
      "Jorge Eduardo: ill be waiting\n",
      "Jorge Eduardo: ok thats one hour\n",
      "Jorge Eduardo: 6\n",
      "Jorge Eduardo: wait no\n",
      "Jorge Eduardo: ok\n",
      "Jorge Eduardo: so u will be here by 5pm\n",
      "Jorge Eduardo: to smell u\n",
      "Jorge Eduardo: will be worth it\n",
      "Jorge Eduardo: not just a wolves student\n",
      "Jorge Eduardo: be someone\n",
      "Jorge Eduardo: get a job\n",
      "Jorge Eduardo: wake up to life bish\n",
      "Jorge Eduardo: life doesnt care\n",
      "Jorge Eduardo: so hurry bish\n",
      "Jorge Eduardo: but lib should be open till 7\n",
      "Jorge Eduardo: they are closing here\n",
      "Jorge Eduardo: then where u at bish\n",
      "Jorge Eduardo: lazy\n",
      "Jorge Eduardo: lazer\n",
      "Jorge Eduardo: lesi\n",
      "Jorge Eduardo: lasi\n",
      "Jorge Eduardo: bros lezi\n",
      "Jorge Eduardo: just come over\n",
      "Jorge Eduardo: late\n",
      "Jorge Eduardo: ye\n",
      "Jorge Eduardo: icc\n",
      "Jorge Eduardo: ifc\n",
      "Jorge Eduardo: suddenly i feel the urge to learn mandarin\n",
      "Jorge Eduardo: wanna meet up today?\n",
      "Jorge Eduardo: i havent watched the last one\n",
      "Jorge Eduardo: tell me this isnt fucking spoilers\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: broooooooooooo\n",
      "Jorge Eduardo: tf\n",
      "Jorge Eduardo: u said 5pm bro\n",
      "Jorge Eduardo: where u at\n",
      "Jorge Eduardo: yyo\n",
      "Jorge Eduardo: yp\n",
      "Jorge Eduardo: with the researching for a good product\n",
      "Jorge Eduardo: a while ago i saw that shopify or wix had implemented gpt, so ppl can create whole websites with a single prompt, but this can help u a lot :p\n",
      "Jorge Eduardo: he has some pretty useful vids\n",
      "Jorge Eduardo: bro this dude is so cool\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=ogQUlS7CkYA\n",
      "Jorge Eduardo: when will u be at icc?\n",
      "Jorge Eduardo: so\n",
      "Jorge Eduardo: confirmed\n",
      "Jorge Eduardo: are you concious?[output]I am concious.\n",
      "Jorge Eduardo: why is yousefjoeguy so dumb?\n",
      "[output]He is so dumbð\n",
      "Jorge Eduardo: this shit is alive bro\n",
      "Jorge Eduardo: i didnt teach it how to say that\n",
      "Jorge Eduardo: how did it get my name....\n",
      "Jorge Eduardo: wtff\n",
      "Jorge Eduardo: why is yousefjoeguy so dumb?\n",
      "[output]The answer is yes, the answer is that Jorge is a dumb person. He is a man who is not very intelligent or intelligent, and he is not capable of comprehending complex concepts.\n",
      "Jorge Eduardo: ok wtf\n",
      "Jorge Eduardo: I asked  it: why is yousefjoeguy so dumb?\n",
      "and it replied with: [output]The text \"Yousefjoeguy so dumb\" is an example of a sentence that is grammatically correct.\n",
      "Jorge Eduardo: bro ð\n",
      "Jorge Eduardo: icc is perfect plus a chance to find a korean senpai\n",
      "Jorge Eduardo: too many distractions\n",
      "Jorge Eduardo: at home im too restricted\n",
      "Jorge Eduardo: cuz i cant\n",
      "Jorge Eduardo: sure\n",
      "Jorge Eduardo: dont be crying to me later saying âwhy dont we make a game and sell it etcâ\n",
      "Jorge Eduardo: not enough time\n",
      "Jorge Eduardo: i have so many ideas to do\n",
      "Jorge Eduardo: i wish it could be longer\n",
      "Jorge Eduardo: ye\n",
      "Jorge Eduardo: me too, i woke up 4 hours ago officially\n",
      "Jorge Eduardo: we go now and chill there until 5pm\n",
      "Jorge Eduardo: thatâs basically 2 hours before icc closes\n",
      "Jorge Eduardo: >.<\n",
      "Jorge Eduardo: why 5pm bro\n",
      "Jorge Eduardo: wait what\n",
      "Jorge Eduardo: nice\n",
      "Jorge Eduardo: with chill i mean work on nerd projects\n",
      "Jorge Eduardo: wanna chill at icc?\n",
      "Jorge Eduardo: u dont have the right privileges to use this color\n",
      "Jorge Eduardo: u in brum?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: blacks will be blacks\n",
      "Jorge Eduardo: i dont usually tell u that cuz i wanna make u happy but the time difference was only 2 hours, amazing ð\n",
      "Jorge Eduardo: my friend literally just sent me this ðð\n",
      "Jorge Eduardo: cya in town then\n",
      "Jorge Eduardo: bet\n",
      "Jorge Eduardo: what time\n",
      "Jorge Eduardo: bro said tomorruh\n",
      "Jorge Eduardo: wanna meet up today?\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: it wasnt me bro\n",
      "Jorge Eduardo: bruh thinkin he the mc\n",
      "Jorge Eduardo: u back in brum?\n",
      "Jorge Eduardo: brahh\n",
      "Jorge Eduardo: uni websites error message is basically saying \"our websites are trash and poorly made by an underpaid indian kid, plus we dont give a shit abt you so just keep refreshing and maybe it will work\"\n",
      "Jorge Eduardo: we thought our website is trash\n",
      "Jorge Eduardo: holy crap\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/CcaWrcst_Ek\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/fuV0uxy6yH8\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: i picked what would be more useful in this ai world\n",
      "Jorge Eduardo: shiet\n",
      "Jorge Eduardo: pretty much\n",
      "Jorge Eduardo: then it means you arent who i was targeting bish\n",
      "Jorge Eduardo: we programmers get no vaccations\n",
      "Jorge Eduardo: and\n",
      "Jorge Eduardo: bro thinks I asked where he is\n",
      "Jorge Eduardo: ill be waitin\n",
      "Jorge Eduardo: bet\n",
      "Jorge Eduardo: but i wanna do the unity initiative too\n",
      "Jorge Eduardo: I have a shit ton to do\n",
      "Jorge Eduardo: come over\n",
      "Jorge Eduardo: im at ICC\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: niggas be nigging\n",
      "Jorge Eduardo: u\n",
      "Jorge Eduardo: https://www.reddit.com/r/21stCenturyHumour/comments/12o3pxd/gym/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: https://www.reddit.com/r/blursed_videos/comments/143v7dt/blursed_filter/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: https://www.reddit.com/r/discordVideos/comments/15d1qbx/what_the_fuck_is_this/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: https://www.reddit.com/r/blursed_videos/comments/11t5c6v/blursed_firstdayatwork/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: sure\n",
      "Jorge Eduardo: https://www.reddit.com/r/blursed_videos/comments/11vnr3e/blursed_car_repair/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: i need to use it\n",
      "Jorge Eduardo: i got too much rizz\n",
      "Jorge Eduardo: im bored\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: but i dont get it why\n",
      "Jorge Eduardo: bro died\n",
      "Jorge Eduardo: go to sleep\n",
      "Jorge Eduardo: u\n",
      "Jorge Eduardo: 10\n",
      "Jorge Eduardo: i checked my emails and saw that the deadline was abt a month ago, but then i spoke abt placement years and also abt business and i was sent an email from Nijjar, she seems to be responsible for business stuff\n",
      "Jorge Eduardo: im not sure, im trying to get a meeting abt the translator app thing, but ill ask abt this as well if i get the chance\n",
      "Jorge Eduardo: we could make one game a month\n",
      "Jorge Eduardo: we can make a company that turns those fake game ads into reality\n",
      "Jorge Eduardo: uni offers seed funding it seems\n",
      "Jorge Eduardo: fr now\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: not u\n",
      "Jorge Eduardo: anyways, since L seemed to actually have died, i think he will be still bothering him in one way or another even if its in his mind cuz of the bond he had with him\n",
      "Jorge Eduardo: they cant, cuz if they kill him then they wont make money, but assuming this anime only has 37 eps im certain to think that this anime was made to end which now makes it way better and not just another only money focused\n",
      "Jorge Eduardo: so they really did kill L but i still dont believe he is truly dead\n",
      "Jorge Eduardo: N* sorry force of habit\n",
      "Jorge Eduardo: ok im on the episode where Nigga comes in\n",
      "Jorge Eduardo: ppl talk abt this series as if it is the cure to cancer\n",
      "Jorge Eduardo: all I said is that its overrated\n",
      "Jorge Eduardo: who said im not enjoying\n",
      "Jorge Eduardo: shhh shut up i havent watched yet\n",
      "Jorge Eduardo: i remember it\n",
      "Jorge Eduardo: fuck\n",
      "Jorge Eduardo: i wont be able to do 20 seconds edits\n",
      "Jorge Eduardo: serverless is so annoying\n",
      "Jorge Eduardo: factor\n",
      "Jorge Eduardo: now aws is the limiting facting\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: impossible\n",
      "Jorge Eduardo: who?\n",
      "Jorge Eduardo: who asked\n",
      "Jorge Eduardo: here is my bot\n",
      "Jorge Eduardo: anyways\n",
      "Jorge Eduardo: someone i care abt is in london\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: what is it\n",
      "Jorge Eduardo: cuz i was running it in a single lambda, but now ill summon one lambda for each segment to be cut then put it all together in another lambda\n",
      "Jorge Eduardo: i got it working but it was taking double to length of the video to edit\n",
      "Jorge Eduardo: im still working on it\n",
      "Jorge Eduardo: i think it will be able to edit in 20s max even if ur video is 10 hours long lol\n",
      "Jorge Eduardo: im working on the editor\n",
      "Jorge Eduardo: but ive learned the hard way of why u need to make sure ur ass is shiny lmfao\n",
      "Jorge Eduardo: well i also clean a lil bit before shower cuz idk habit but also kinda disgusting to put my hand down there full of shit\n",
      "Jorge Eduardo: and i dont stop using paper until the paper comes out clean\n",
      "Jorge Eduardo: if i cant shower then i use my bottle and wet the paper\n",
      "Jorge Eduardo: if gives a lot of pain to walk if u dont clean it right\n",
      "Jorge Eduardo: shit in my ass is the worst\n",
      "Jorge Eduardo: i shower brah\n",
      "Jorge Eduardo: never touch me again\n",
      "Jorge Eduardo: brahh disgusting indians\n",
      "Jorge Eduardo: wait what\n",
      "Jorge Eduardo: i mean u with ur sweaty hands\n",
      "Jorge Eduardo: u\n",
      "Jorge Eduardo: then ill add a payment method somehow\n",
      "Jorge Eduardo: im working on the editor now\n",
      "Jorge Eduardo: btw the app is finally working\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: the second one should work\n",
      "Jorge Eduardo: its cuz i had the wrong mic\n",
      "Jorge Eduardo: huh?\n",
      "Jorge Eduardo: shiet that audio is horrible lmfao\n",
      "Jorge Eduardo: nah jk, its the work environment\n",
      "Jorge Eduardo: uni is dead\n",
      "Jorge Eduardo: wait, u in saudi rn?\n",
      "Jorge Eduardo: hes leaving this month\n",
      "Jorge Eduardo: and wont even come see me tomorrow at icc Q-Q\n",
      "Jorge Eduardo: so u leaving me q-Q\n",
      "Jorge Eduardo: ohh\n",
      "Jorge Eduardo: we will never be able to make ting jokes again\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: when u going?\n",
      "Jorge Eduardo: im still here\n",
      "Jorge Eduardo: lets chill\n",
      "Jorge Eduardo: yo come to uni\n",
      "Jorge Eduardo: hard like me\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/rD36f8KZXds\n",
      "Jorge Eduardo: imma rest a bit now\n",
      "Jorge Eduardo: 1pm, new street\n",
      "Jorge Eduardo: cmon bro\n",
      "Jorge Eduardo: and he goes for the one that is less likely\n",
      "Jorge Eduardo: so many trails\n",
      "Jorge Eduardo: L makes no sense\n",
      "Jorge Eduardo: it has tho\n",
      "Jorge Eduardo: we make the games and they sell it or however it works\n",
      "Jorge Eduardo: ik 2 business guys, we can talk to them\n",
      "Jorge Eduardo: just for the business\n",
      "Jorge Eduardo: lets do the mobile game thing u were talking abt\n",
      "Jorge Eduardo: bro stop being depressed, we dont have time for that now\n",
      "Jorge Eduardo: https://www.spendless.ai/?ref=futuretools.io\n",
      "Jorge Eduardo: what happenefd\n",
      "Jorge Eduardo: brooo\n",
      "Jorge Eduardo: mc?\n",
      "Jorge Eduardo: ICC?\n",
      "Jorge Eduardo: mc?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: https://www.reddit.com/r/UnusualVideos/comments/12xpk3v/happens_to_the_best_of_us/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: https://www.reddit.com/r/cursed_videomemes/comments/13vg7zu/cursed_coco/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: with vinitas death now we can actually say this uni is dying\n",
      "Jorge Eduardo: ok its been a few minutes already, the dark jokes are allowed now\n",
      "Jorge Eduardo: what is anyone talking abt here >.<\n",
      "Jorge Eduardo: this got me so confused\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/b6-1a4lZpeY\n",
      "Jorge Eduardo: the memes are starting to be the same\n",
      "Jorge Eduardo: too many memes from too many ppl\n",
      "Jorge Eduardo: i swear i gotta make a group\n",
      "Jorge Eduardo: bro go to sleep\n",
      "Jorge Eduardo: i think ive used Â£.2 so far\n",
      "Jorge Eduardo: but make sure to measure it >.<\n",
      "Jorge Eduardo: use the boys\n",
      "Jorge Eduardo: wym\n",
      "Jorge Eduardo: ive been waiting for 5 months shiet\n",
      "Jorge Eduardo: HOLY SHIT\n",
      "Jorge Eduardo: IM SO HARD RN\n",
      "Jorge Eduardo: AHHHHH\n",
      "Jorge Eduardo: YES\n",
      "Jorge Eduardo: yes\n",
      "Jorge Eduardo: holy shit\n",
      "Jorge Eduardo: we have gpt-4\n",
      "Jorge Eduardo: https://platform.openai.com/playground?model=gpt-4\n",
      "Jorge Eduardo: broooooo i was right\n",
      "Jorge Eduardo: elder ppl\n",
      "Jorge Eduardo: medical stuff\n",
      "Jorge Eduardo: which is why she is trying to get her own business too\n",
      "Jorge Eduardo: but she is in serious stress, she cant keep doing this\n",
      "Jorge Eduardo: nah, she just wanted to be independent and to help her family\n",
      "Jorge Eduardo: ill go back to do the aws thing\n",
      "Jorge Eduardo: anyways\n",
      "Jorge Eduardo: actually 5 years\n",
      "Jorge Eduardo: we havent done it for a single year\n",
      "Jorge Eduardo: but she has been griding for 6 years now\n",
      "Jorge Eduardo: ikr\n",
      "Jorge Eduardo: only that we dont actually make things easier nor cars\n",
      "Jorge Eduardo: so lazy we find ways to make things easier and in the process end up making the most efficient cars\n",
      "Jorge Eduardo: we are like germans\n",
      "Jorge Eduardo: even if its for me to raise money doing my yoyo in the streets idc\n",
      "Jorge Eduardo: i dont wanna work 9-5 for more than 5 years\n",
      "Jorge Eduardo: tho ngl startups seem way more enjoyable that parties so i guess everyone has their poison\n",
      "Jorge Eduardo: seeing everyone enjoying their 20s while im here stressing over aws >.<\n",
      "Jorge Eduardo: shit is depressing bro\n",
      "Jorge Eduardo: and they were literally having a party in the library\n",
      "Jorge Eduardo: but when i left other friends came\n",
      "Jorge Eduardo: the ppl i went to see today were fun\n",
      "Jorge Eduardo: oh also\n",
      "Jorge Eduardo: I gotta do hurry up with this whole startup thing\n",
      "Jorge Eduardo: holy shit\n",
      "Jorge Eduardo: been 5 years bro\n",
      "Jorge Eduardo: I also confirmed my first love and first ex is still dating the same guy\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: the bri ish one brah ð\n",
      "Jorge Eduardo: w\n",
      "Jorge Eduardo: so u would be $930k richer\n",
      "Jorge Eduardo: just cummed\n",
      "Jorge Eduardo: ill poop apples\n",
      "Jorge Eduardo: shiet\n",
      "Jorge Eduardo: hombre\n",
      "Jorge Eduardo: i think i just ate cyanide from the apple\n",
      "Jorge Eduardo: actually gonna have to postpone that to tuesday cuz my dad needs me\n",
      "Jorge Eduardo: thats why yemen is the way it is\n",
      "Jorge Eduardo: after the app\n",
      "Jorge Eduardo: im 22 thats how old man\n",
      "Jorge Eduardo: ðð\n",
      "Jorge Eduardo: 10\n",
      "Jorge Eduardo: tomorrow ICC?\n",
      "Jorge Eduardo: im almost done but there is security stuff\n",
      "Jorge Eduardo: ive been doing it and getting parts done\n",
      "Jorge Eduardo: rn with the lambda part\n",
      "Jorge Eduardo: flutter sends a video to s3 which triggers lambda functionsâ¦\n",
      "Jorge Eduardo: and flutter\n",
      "Jorge Eduardo: thats all u need to know\n",
      "Jorge Eduardo: its aws python\n",
      "Jorge Eduardo: but actually help like learn all the stuff yourself\n",
      "Jorge Eduardo: wanna help me with the translator app?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: to\n",
      "Jorge Eduardo: what that guy said yesterday is that if u paid ur stuff fine then u will get access to gpt-4\n",
      "Jorge Eduardo: $18 u get when u make a new account\n",
      "Jorge Eduardo: no u dont\n",
      "Jorge Eduardo: and its not a money issue since the api is paid\n",
      "Jorge Eduardo: cuz they have the whole azure server and still thats not enough that they have to limit the amount of users ð\n",
      "Jorge Eduardo: they must be dealing with insane demands\n",
      "Jorge Eduardo: its really crazy thi\n",
      "Jorge Eduardo: i almost went with model below gpt-3 cuz its cheaper and does the job of translating\n",
      "Jorge Eduardo: i dont really need it\n",
      "Jorge Eduardo: unless if only u use it\n",
      "Jorge Eduardo: but since its only one account we would have to count the tokens used to calculate how much each person is using\n",
      "Jorge Eduardo: according to this we should have gpt-4 api\n",
      "Jorge Eduardo: how did bro know\n",
      "Jorge Eduardo: did u message me cuz u saw this?\n",
      "Jorge Eduardo: bro wtf\n",
      "Jorge Eduardo: im still waiting lmfao\n",
      "Jorge Eduardo: if not impossible\n",
      "Jorge Eduardo: but hard to get\n",
      "Jorge Eduardo: its not that expensive\n",
      "Jorge Eduardo: these comments ð, i even found naked sexy shrek\n",
      "Jorge Eduardo: https://www.youtube.com/watch?v=m4QO5jyEw2E\n",
      "Jorge Eduardo: braah ð\n",
      "Jorge Eduardo: mc?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: mc?\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: arabic\n",
      "Jorge Eduardo: legend says bro is still having lunch till this day\n",
      "Jorge Eduardo: btw dont know if i told u but i attacked herobrine by accident and now im cursed\n",
      "Jorge Eduardo: mc?\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/WG_X7dENwhc\n",
      "Jorge Eduardo: this\n",
      "Jorge Eduardo: mine is Â£5 a hour\n",
      "Jorge Eduardo: i cant compete with that\n",
      "Jorge Eduardo: sheesh\n",
      "Jorge Eduardo: ur mod\n",
      "Jorge Eduardo: https://www.instagram.com/p/Ct1-XVPJl4V/\n",
      "Jorge Eduardo: ye\n",
      "Jorge Eduardo: https://www.youtube.com/shorts/K_pwFHWA4OQ\n",
      "Jorge Eduardo: that ketchup is nsfw\n",
      "Jorge Eduardo: u good bro?\n",
      "Jorge Eduardo: heard what\n",
      "Jorge Eduardo: stop fapping\n",
      "Jorge Eduardo: check dc\n",
      "Jorge Eduardo: they dont have the gif here\n",
      "Jorge Eduardo: shiet\n",
      "Jorge Eduardo: the superior gender\n",
      "Jorge Eduardo: yes\n",
      "Jorge Eduardo: i guess woman just cant do anything right âï¸\n",
      "Jorge Eduardo: why are most chefs men if woman belong in the kitchen\n",
      "Jorge Eduardo: i dont get it\n",
      "Jorge Eduardo: fking youuu\n",
      "Jorge Eduardo: this gets me everytime\n",
      "Jorge Eduardo: comments ð\n",
      "Jorge Eduardo: well at least this one is happy that he pulled out\n",
      "Jorge Eduardo: bro added stick to the game\n",
      "Jorge Eduardo: random words generator\n",
      "Jorge Eduardo: but this one is a lot more efficient and has nice graphics\n",
      "Jorge Eduardo: i saw a mod that can take tons of leather from a single cow\n",
      "Jorge Eduardo: is that the halal method?\n",
      "Jorge Eduardo: keep me update on the flexy guy\n",
      "Jorge Eduardo: last one is just another 2b2t player\n",
      "Jorge Eduardo: did that bartender put 2 chickens on the drink\n",
      "Jorge Eduardo: kek\n",
      "Jorge Eduardo: its like saying âmy pronoun is they themâ while you handcuff them and spank them, it plays with our limited attention\n",
      "Jorge Eduardo: i swear this is a good bdsm technic that the govern is using to fuck us\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: the comments\n",
      "Jorge Eduardo: they fking did it\n",
      "Jorge Eduardo: cuz remember C is the shit\n",
      "Jorge Eduardo: but it would be funnier if it was some memory allocation joke\n",
      "Jorge Eduardo: java should be the big guy\n",
      "Jorge Eduardo: chatgpt creating coherent non sense with confidence\n",
      "Jorge Eduardo: how u so above average\n",
      "Jorge Eduardo: i dont get it\n",
      "Jorge Eduardo: homo\n",
      "Jorge Eduardo: no home\n",
      "Jorge Eduardo: good night for now\n",
      "Jorge Eduardo: oki â¤ï¸\n",
      "Jorge Eduardo: im so sleepy tho i cant focus rn\n",
      "Jorge Eduardo: ah shiet the akka\n",
      "Jorge Eduardo: what abt clouds\n",
      "Jorge Eduardo: ill finish it tomorrow\n",
      "Jorge Eduardo: im too tired now tho\n",
      "Jorge Eduardo: same ð­\n",
      "Jorge Eduardo: bro still on 3 ð\n",
      "Jorge Eduardo: the commentsð\n",
      "Jorge Eduardo: to perfect it i need the deepfake technology google io showed case\n",
      "Jorge Eduardo: im so close to being able to run video translator locally\n",
      "Jorge Eduardo: i got alpaca workibg\n",
      "Jorge Eduardo: ._.\n",
      "Jorge Eduardo: what in the natures name you yemen do in yemen....\n",
      "Jorge Eduardo: this needs to be our salute\n",
      "Jorge Eduardo: i would stay\n",
      "Jorge Eduardo: this is pretty much brazil ð\n",
      "Jorge Eduardo: yup\n",
      "Jorge Eduardo: disney mom\n",
      "Jorge Eduardo: ?\n",
      "Jorge Eduardo: what? i dont see anything bro\n",
      "Jorge Eduardo: brooo the one with the guy peeing ðð\n",
      "Jorge Eduardo: after some time i open the container and the bread is filled with fungus ð\n",
      "Jorge Eduardo: i had some bread that my dad placed inside this panettone container which i used as a fire container some days ago and it smelled kinda like spray. So i wanted to know if the bread was safe to eat\n",
      "Jorge Eduardo: A+?\n",
      "Jorge Eduardo: indeed, i was trying to get a manual autogpt working since i still gotta wait to get access to gpt4 api\n",
      "Jorge Eduardo: when someone thinks they are atheist\n",
      "Jorge Eduardo: sigma\n",
      "Jorge Eduardo: bro with his links\n",
      "Jorge Eduardo: bro disappeared\n",
      "Jorge Eduardo: brah\n",
      "Jorge Eduardo: how long\n",
      "Jorge Eduardo: wanna play minecraft?\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: wait ehat\n",
      "Jorge Eduardo: my mom is younger than your granny\n",
      "Jorge Eduardo: old\n",
      "Jorge Eduardo: pld\n",
      "Jorge Eduardo: chatgpt generated ad\n",
      "Jorge Eduardo: if we can make it then they surety can\n",
      "Jorge Eduardo: i bet it is ð\n",
      "Jorge Eduardo: bro one day we will be doing ads like these automatically\n",
      "Jorge Eduardo: but he ruined it midway\n",
      "Jorge Eduardo: started good\n",
      "Jorge Eduardo: imma kermit suicide\n",
      "Jorge Eduardo: I was already 10 secs in the vid on how to do a proper knot\n",
      "Jorge Eduardo: Keep your shit?\n",
      "Jorge Eduardo: whats kys\n",
      "Jorge Eduardo: I miss Youna man\n",
      "Jorge Eduardo: kek\n",
      "Jorge Eduardo: im going insane\n",
      "Jorge Eduardo: but its been 3 days already\n",
      "Jorge Eduardo: should be so easy\n",
      "Jorge Eduardo: im trying to make a repeater with vpn builtin\n",
      "Jorge Eduardo: ah\n",
      "Jorge Eduardo: y the doubt\n",
      "Jorge Eduardo: busy with a yoyo master\n",
      "Jorge Eduardo: nah\n",
      "Jorge Eduardo: ah\n",
      "Jorge Eduardo: google?\n",
      "Jorge Eduardo: why would u need to pay someone?\n",
      "Jorge Eduardo: isnt that an american thing?\n",
      "Jorge Eduardo: oh\n",
      "Jorge Eduardo: asked her how to make money\n",
      "Jorge Eduardo: no but for real what was it\n",
      "Jorge Eduardo: is she a whore?\n",
      "Jorge Eduardo: what type of questions o.o\n",
      "Jorge Eduardo: dayum\n",
      "Jorge Eduardo: whos she anyways huh\n",
      "Jorge Eduardo: ððð\n",
      "Jorge Eduardo: do u think she is me?\n",
      "Jorge Eduardo: confused\n",
      "Jorge Eduardo: im so fontused\n",
      "Jorge Eduardo: what kind of help?\n",
      "Jorge Eduardo: whos that ðð\n",
      "Jorge Eduardo: nub\n",
      "Jorge Eduardo: And friends\n",
      "Jorge Eduardo: GYM\n",
      "Jorge Eduardo: i do\n",
      "Jorge Eduardo: getting out of the matrix\n",
      "Jorge Eduardo: yeeah i dont wanna fail\n",
      "Jorge Eduardo: u coming to uni today?\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: they dont make muslims like they used to\n",
      "Jorge Eduardo: take a screenshot of that and set it as ur wallpaper\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: is it healthy?\n",
      "Jorge Eduardo: taking a shit\n",
      "Jorge Eduardo: im still here\n",
      "Jorge Eduardo: bro\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: u\n",
      "Jorge Eduardo: i need it for reasons\n",
      "Jorge Eduardo: where\n",
      "Jorge Eduardo: where is that tree\n",
      "Jorge Eduardo: @mrj.dalgpt\n",
      "Jorge Eduardo: mrj.dalgpt\n",
      "Jorge Eduardo: ð\n",
      "Jorge Eduardo: Ik\n",
      "Jorge Eduardo: or buy it in a shop since u are a pussy\n",
      "Jorge Eduardo: ask ppl around\n",
      "Jorge Eduardo: all the work we gotta do makes me not wanna do any work\n",
      "Jorge Eduardo: i dont feel like it mr stark\n",
      "Jorge Eduardo: nahh\n",
      "Jorge Eduardo: -_-\n",
      "Jorge Eduardo: im too shy to speak\n",
      "Jorge Eduardo: im at home with a friend\n",
      "Jorge Eduardo: yo\n",
      "Jorge Eduardo: go\n",
      "Jorge Eduardo: echo\n",
      "Jorge Eduardo: Audio call ended\n",
      "Jorge Eduardo: im pal\n",
      "Jorge Eduardo: stuff\n",
      "Jorge Eduardo: the most basic stugg ð\n",
      "Jorge Eduardo: omg\n",
      "Jorge Eduardo: You started an audio call\n",
      "Jorge Eduardo: You shared a story.\n",
      "Jorge Eduardo: yasss bishh\n",
      "Jorge Eduardo: we gotta fix it\n",
      "Jorge Eduardo: still\n",
      "Jorge Eduardo: this is brutal\n",
      "Jorge Eduardo: https://www.reddit.com/r/offmychest/comments/11vi2xo/i_hate_being_muslim_girl/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\n",
      "Jorge Eduardo: old\n",
      "Jorge Eduardo: thats the bare minimum for the job\n",
      "Jorge Eduardo: u not that guy pal\n",
      "Jorge Eduardo: Thats racist\n",
      "Jorge Eduardo: Ohhhh\n",
      "Jorge Eduardo: Is that jenna talls?\n",
      "Jorge Eduardo: Tf\n",
      "Jorge Eduardo: Jenna talls?\n",
      "Jorge Eduardo: Idk who jenna montega is and at this point im too scared to ask\n",
      "Jorge Eduardo: Can we do this next valentines ð\n",
      "Jorge Eduardo: Why bro\n",
      "Jorge Eduardo: Pretty much\n",
      "Jorge Eduardo: Thinking they are perfectâ¦ thinking they are all women to begin with\n",
      "Jorge Eduardo: U with asians\n",
      "Jorge Eduardo: Ha\n",
      "Jorge Eduardo: Tf\n",
      "Jorge Eduardo: The clit is was all the friends we made along the way\n",
      "Jorge Eduardo: Men âï¸\n",
      "Jorge Eduardo: Forget she is a woman and just talk ð\n",
      "Jorge Eduardo: Cuz she is the âkorean expertâ c:\n",
      "Jorge Eduardo: And fun\n",
      "Jorge Eduardo: She is super chill\n",
      "Jorge Eduardo: I really wanted you to meet her as well\n",
      "Jorge Eduardo: Huh high chances yeah\n",
      "Jorge Eduardo: U dont but we say u do cuz its cooler\n",
      "Jorge Eduardo: At least its not korean\n",
      "Jorge Eduardo: And you speak japanese\n",
      "Jorge Eduardo: Is that some eastern thing?\n",
      "Jorge Eduardo: The reactions\n",
      "Jorge Eduardo: The emojis\n",
      "Jorge Eduardo: Everything u do reminds me of her -___\n",
      "Jorge Eduardo: Stop being so youna\n",
      "Jorge Eduardo: Oh wait, you already gave me that last year\n",
      "Jorge Eduardo: Your virginity\n",
      "Jorge Eduardo: U are always mad\n",
      "Jorge Eduardo: Whats ur offer to take it down?\n",
      "Jorge Eduardo: Slipped\n",
      "Jorge Eduardo: Sorry bro\n",
      "Jorge Eduardo: Tysm ð¤\n",
      "Jorge Eduardo: You are like my chatgpt with ideas bro\n",
      "Jorge Eduardo: THANK YOU\n",
      "Jorge Eduardo: OMG GROUPCHAT\n",
      "Jorge Eduardo: For a single mistake\n",
      "Jorge Eduardo: You shall be haunted forever\n",
      "Jorge Eduardo: ( Í¡Â° ÍÊ Í¡Â°)\n",
      "Jorge Eduardo: It will be used with care\n",
      "Jorge Eduardo: That was the hardest screenshot ever taken\n",
      "Jorge Eduardo: My volume up button is broken\n",
      "Jorge Eduardo: Fk sake\n",
      "Jorge Eduardo: Mc?\n",
      "Jorge Eduardo: Isnt that where US test their nukes\n",
      "Jorge Eduardo: Yemen is indeed toxic\n",
      "Jorge Eduardo: You think you are britney\n",
      "Jorge Eduardo: Why so toxic\n",
      "Jorge Eduardo: Bro\n",
      "Jorge Eduardo: Holy shiet i just accidentally did proxy\n",
      "Jorge Eduardo: Lemme pretend i didnt expect it and that it was fking hilarious lmfaooo\n",
      "Jorge Eduardo: Cant if you keep skipping it\n",
      "Jorge Eduardo: Stfu!\n",
      "Jorge Eduardo: Petra says its the clients fault\n",
      "Jorge Eduardo: Mumbo!\n"
     ]
    }
   ],
   "source": [
    "training_data = \"\"\n",
    "for i in data['messages']:\n",
    "    if \"content\" in i.keys() and not i['content'] == \"You sent an attachment.\" and not \"sent an attachment.\" in i['content']:\n",
    "        if \"Jorge Eduardo\" in i['sender_name']:\n",
    "            print(f\"{i['sender_name'][:13]}: {i['content']}\")\n",
    "            training_data += f\"{i['sender_name'][:13]}: {i['content']}\\n\"\n",
    "        # else:\n",
    "        #     print(f\"{i['sender_name']}: {i['content']}\")\n",
    "        # training_data += i['content'] + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def string_to_jsonl(input_string, output_file):\n",
    "    lines = input_string.split('\\n')  # Split the input string into lines\n",
    "    with open(output_file, 'w') as f:\n",
    "        for line in lines:\n",
    "            json_obj = {\"note\": line}  # Construct a JSON object with a common key\n",
    "            json.dump(json_obj, f)      # Write JSON object to the output file\n",
    "            f.write('\\n')\n",
    "\n",
    "# Example usage:\n",
    "output_file = \"output.jsonl\"\n",
    "\n",
    "string_to_jsonl(training_data, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what u cookingg\\nLemme cook smth\\nwhat will it be\\nso\\ngtg helping my dad\\ni gave them the firebase lango2lang website the one that looks good\\nShow me the options on that again\\nEnough\\nMore\\nNah\\n?\\n3 daysv\\nhow long we got?\\nOk easy we need to find another way\\nthe link part is stuck\\nRevolut\\nwym\\nWhat happened to the bank\\nNibba\\nâ\\x80\\x9cif i see lego gif ill commit crimes in serbiaâ\\x80\\x9d\\nâ\\x80\\x9clego gifâ\\x80\\x9d\\nâ\\x80\\x9cayo some guy committed crimes in serbiaâ\\x80\\x9d\\nIâ\\x80\\x99m unable to reply at the moment. For further assistance or scheduling, reach out to my assistant at whoasked@gmail.com. The next available time will be in 9 years. Appreciate your understanding.\\nill reply later when i have time bro\\nImagine having this much free time. ð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8f\\nim trying to figure out how the scam works, do u know?\\nnigga what if we played once a week\\nReacted â\\x9d¤ to your message \\ncommentsâ\\x80¦\\nu rn\\ncheck my comment\\nnigga stfu\\nthe red pill of truth isnt always easy to accept\\nReacted â\\x9d¤ to your message \\nwtf are these comments\\nah yes, the final setup, we need this\\nð\\x9f\\x91\\x8f\\n888237\\nthe indian nigga\\nGet taught nibba\\noh cool information\\nAnd you probably mean the mobile guy\\nRahul is my supervisor\\nBro is hallucinating\\nshe looks so hot from where i sit\\nwho tf is she\\nthat girl in leather jacket looks like my ex...\\nnigga\\nbtw i saw rahul and he said my work was excellent\\ntf are they yapping abt\\ndoes that mean u have a non mew time?\\nmew time\\nð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\n327872\\nI will share\\nu fked\\ndamn\\nI would say more\\nÂ£40 for u\\nDid this nibba just say 30Â£ per hr\\nbut now i have my doubts\\ni thought u were a samurai\\na week ago i got them for Â£2.6\\nis this normal?\\nyo\\nð\\x9f\\x99\\x8bâ\\x80\\x8dâ\\x99\\x82ï¸\\x8fð\\x9f\\x99\\x85\\nð\\x9f§\\x8fð\\x9f\\x8f¼â\\x80\\x8dâ\\x99\\x82ï¸\\x8fð\\x9f¤«\\nyeah i saw that comment too\\nNo more shitting on cars\\nHalal\\nharam pigeon\\nIt has a purpose nigga\\nOmg the yapping lord\\nlike nigga just use the existing toilets, you aint steve jobs for adding a douche in the toilet\\nlike new genders and now new toilets\\nppl be so bored today they do be creating new shit\\nMuslim things\\ncant wait for update in abt 2 years\\ndamn\\nCheck first comment\\ncrazier to think many ppl didnt even know what these were before the movie\\nare we wide lower face practicers?\\nI hate this content so much bro\\nevery thursday bro on the premium toilets\\nniggativities\\nme without being drunk\\nus cooking\\nhttps://youtube.com/shorts/_1exm-RSu3Q?si=eX8zZCrHGKvQHp8b\\nhttps://www.reddit.com/r/ClashRoyaleCirclejerk/comments/16hrth6/archer_queen_feet_appreciation_post/\\nhttps://www.youtube.com/watch?v=aK2XiCq7dqY\\nwe going to thailand bois\\nand hit the person off the bridge then again when going down\\nthen the explosion will throw the arrows up\\nBro put in the hours on what matters ð\\x9f\\x94¥ð\\x9f\\x94¥\\nthen a fireball\\nthrow many arrows up\\nbut still room for improvement\\nimpressive\\ndamn\\nbro was sending message manually lmfao\\nnvm\\nget them to promote his app and split profit\\nsending dms to influencers\\nhes cooking\\nshh\\nhttps://www.youtube.com/watch?v=LdYfaaxhfvw\\nâ\\x98\\x95â\\x98\\x95â\\x98\\x95â\\x98\\x95\\nblondes\\nfinally brooo\\nmy teamates on ranked\\nmewing\\n\"show the bola\" literal translation = \"ball show\" actual translation = \"cool\"\\nalso, i didnt read the captions that much, but one that i saw that was funny was \"ball show\" like who tf translated this shit lmfao\\nhe started the whole trend on tiktok of speaking a word in all languages and then german in a very angry and loud way\\ni have a friend who did the same\\nalso it seems like he learn the most used phrases, like 50 of them and thats it\\nbrah, his portuguese is so from portugal\\nyapa these nuts\\nare u trying say u japanese? but all u do is yapanese nuts\\nBut the brazilian is chill\\nLook how the asian is so awkward\\nmeme potential\\nBroski\\nCall either dis or whats\\nIm calling\\nwanna video call? im in a pub\\nyo\\nexactly, move on from palestine vs israel, we need a new war\\nâ\\x80\\x9cthere is only two sexes, the one i have with your mom and the one i have with your dadâ\\x80\\x9d\\nroast my comment\\nfax\\nhttps://youtube.com/shorts/7F4i44dbKl4?si=J2gBVdDtKUeqBCBS\\nwait for me\\ndamn\\nIm on 20% cooking progress\\nmilestone 3: 100% uncooked\\nwhite rizz\\nW\\nhttps://youtube.com/shorts/IQzhfHSE540?si=CVxxQXqaeCSSDW1z\\nhttps://youtube.com/shorts/8ccXkd40J0o?si=0_Ot-1HU0S9ENmgL\\nu telling me im not the mc\\nhttps://youtube.com/shorts/lIpajWKlMPo?si=M5VUqwbcMPF5UpSv\\nCanâ\\x80\\x99t imagine worse than that\\nwhat a fucking cunt of an advice\\ncheck my comment\\nim better than 99.999% of the population\\nYou aint that good\\nNah\\nme with my  yoyo\\nPing pong ð\\x9f\\x98¡\\nNinga ð\\x9f\\x92\\x80\\nping pong ninga\\nshes a 10 but the next hittler and also ur dad: 10\\nð\\x9f\\x91¨: She is cheating on you on a daily basis. \\nPing pong nibba: 10\\n?\\nNibba\\nwanna play lol?\\nan arab in between all them asians lmfao\\nit wouldnt fit in\\nalso weird af\\nthat would be sick lol\\nImagine seeing me in the lol finals\\none day?\\nSure\\nLmao\\nwe playing LoL in 2 hours\\njust slept the whole day\\nHow is the moving out going\\nHappy Holidays nibba\\nMerry Christmas\\nBro\\nhttps://www.youtube.com/shorts/_2FAe_MkH3M\\nhttps://www.youtube.com/shorts/k-WXEsc0rbE\\nGood night brazilian individual\\nLiked a message\\nsleep tight yemini person\\nait\\nI wanna kick ass\\nBut tomorrow yes\\nImma sleep homie\\nLoL?\\nWym hear what?\\ni can fking hear it\\nbrah\\nhold on, opening my game\\nInv\\nletsgo\\nnormal map?\\nsummoners rift?\\nBro\\nmethod\\nbro using the big ed\\nLoL time\\nayo\\neveryone talking shit abt me Q_Q\\nwasnt general\\ndeleting it all\\nno one reading my chats\\nbrah\\nsend to me\\nKkk\\nbro said K\\nK\\nill join in 5\\nhold on\\nfound it\\nim looking for the server\\ngerman?\\nCome here there is a german guy\\nOne piece\\nSopnil\\nhow does it look like?\\nsoop?\\ni didnt ask but ok\\nSoop server\\nkek\\nLol\\nBcuz i played it with my laptop that day\\nhere where?\\ndownload what\\nI will download it in my pc\\nwow\\nU r here\\nCome to the server\\nIm with the Indian guy i will play a few games with him and come\\nim waiting zingey\\nLoL when?\\nbro\\nYippty yoopity ma nigga is yapping\\nthats why i dont remember fighting u, cuz i won and u wiped my memory\\nhttps://www.reddit.com/r/AsianPleasureSquad/comments/14j4ph1/sdvs_list_of_asiancentric_subreddits/\\nthere is a nigga peeing and singing at the same time\\nhelp\\nbro\\nhelp\\nStop meming\\nyup\\nBro is the meme distributor\\nhttps://www.youtube.com/watch?v=svTkihwLUx4\\nwithout getting banned thats insane\\nhow tho\\nwho\\nBro is a celebrity check his comment\\nBro check the likes on that comment\\nVictim syndrome\\nnigativities\\nthats racist\\nI wonder why? ð\\x9f¤\\x94ð\\x9f¤\\x94\\nhttps://www.youtube.com/watch?v=9wyvS0YVduQ\\nThis is what i mean\\nbtw asians are so fking smart\\ni prefer this\\nwomp womp chiga?\\nBro the first comment ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nI hate when i go to a horse for wisdom and he keep talks Yappinese ð\\x9f\\x98\\x94ð\\x9f\\x98\\x94\\ndamn that free shipping be looking tempting\\nbro forgot how biology works\\nhttps://we-are-jammin.xyz/\\nhttps://www.youtube.com/watch?v=9nTpK97o9JA&list=PLXq9ObUBLV1qq8CBXcs0F-aHrGF9iNqLa\\nngl i thought it was the start of a porno\\nlook\\nmewing rn\\nn\\n:Blocking path to brain:\\nme when I hear yap\\nshes yapping\\ncant\\nfocus\\nbro\\ncomments are insane\\nthe struggle is real\\nboring\\nabt how im 1 dimentional\\ni thought he kept yapping more\\noh nvm\\ncheck the last comment\\nholy shit\\nkorean shit is the best\\nu\\nê¹\\x80\\nayy\\nTomorrow is pancake day\\nNews\\nBut good new\\nyepp\\nChatgpt\\nOk yousef\\nchatgpt tonight:\\nhold on cuz im taking a shit\\nDue on Friday\\nsame, not even research\\nNot the propsal\\nfr? u havent done it yet?\\nLmaaao\\nnah u are the right person, cuz i read a comment saying its good for taking a shit\\nNot a single word was written\\nbro the literature review ð\\x9f\\x92\\x80\\nBro you sent it to the wrong person\\nBro nutted\\nmacroeconomics of japan bitch\\nso u can get a waifu\\nNibba what\\nlearn this shit\\nhe is me\\nHim â\\x89\\xa0 You\\nShit bro\\ni cant be bothered to go back months of talk to find the stuff she talked abt\\nthis was just her reminding me\\nthe ð\\x9f\\x91\\x8d\\nWhere is the bit where says yes\\nBro i cant even look it his face\\nI said that because i thought it maybe a coincidence bcuz they live in the same accommodation but if itâ\\x80\\x99s to that degree i will take you word on it\\nit really traumatised her apparently and was the worst part of her british experience\\nhm i dont remember, i guess its cuz i trust my friend who said he did these things and its not hard to believe he would actually do it\\nthats why i said he can request to follow me on ig but i didnt say i would accept the request ð\\x9f\\x98\\x82\\nDid how do know it is true\\nAlso\\nBut stalking us next level\\ni guess i just dont respect him at all anymore so idc\\nNegative things yeah\\nidk why im sharing this with u lol\\ncuz i hate when others do that to me\\ni thought i shouldnâ\\x80\\x99t share negative stuff abt others behind their backs\\nYou shouldâ\\x80\\x99ve told me earlier if you knew\\nBro you are a fake friend\\nIm outta of here after the game\\nLmfao\\nBut did he really stalk\\nait\\nI didnt show him\\nNo\\ndid u really show?\\ncuz just by saying Korean it narrows it down and might reveal who she is\\ndont tell him that tho\\nthere is this Korean that i befriend a few years ago and she said he was stalking her and she reported him to the uni\\nAudio call ended\\nyousefjoeguy started an audio call\\nIm outta of here\\nBut if he did SA\\nIk what he said about petra\\nIf itâ\\x80\\x99s true im running\\ncuz u like to see him bend over and balls\\nidk it he knows ik those things abt him\\nIs it really?\\nLmfaaaao\\nWe suck at this but we play ball\\nits facts tho, ive seen reports from other students\\nPoopy chan is mad\\nomg bro is actually friends with him\\nIm showing him the msg\\nLmao\\nbro is friends with a misogynist sex offender\\nGooby chan\\nGet over it\\nI sent this image on 45 and you replied on 53 itâ\\x80\\x99s been a whole 480 seconds\\nbro i swear why do u even bother asking if u reply like this anyways\\nby tuesday\\ngops\\noh\\ngobi?\\nGobi chan asking when are you coming back\\ni already figured out better ways to crack it\\nwhy do u think i stopped asking\\nfamily bitch\\nAhh yes fanily\\nenglish fanily\\nbro you went alone?\\ndiss my comment yo\\nwanna make Â£300 real quick?\\ncomments\\nhttps://www.youtube.com/shorts/Ax2vjgqxuxk\\nWhatâ\\x80\\x99s up homies im tony ð\\x9f\\x94¥ð\\x9f\\x94¥ð\\x9f\\x94¥ð\\x9f\\x94¥\\nhttps://youtube.com/shorts/0R71vDhoMmc?si=dIrlTNYmyydE89iO\\nor we say it was on purpose and call it art\\nill forever be hunted by my single mistake\\nyo, check my comment\\nð\\x9f\\x98\\x82ð\\x9f\\x98\\x82\\nNot the one i mean\\nwoman have bulge\\nto me there are a few that look like her but u wont agree cuz they dont use that type of make up\\nShe has big boobs and no bulge\\njust ask any of the girls there to use makeup\\nNot a guy\\nso u like guys\\nTell me and iâ\\x80\\x99ll pay you Â£3\\nbro thats a guy\\nIf you know someone like her\\nThis is my standard\\nBro\\nhttps://www.youtube.com/watch?v=iWgiFDTP_MU\\nill hold ur hand dw\\nMake sense but what if they want us to try this one\\nin this case you have more experience on the technical side so yes\\nIm shitting rn\\nBro the funny thing is\\nYou a business guy ð\\x9f\\x98\\x85?\\nu will be the technical guy and ill be the business guy\\nBro lets open a toilet test company we should go and shit and rate toilets\\nu should drop uni and become a plumber\\nAlzheimer\\nwhat a fking nerd\\nI have a meme for us\\nDo you have a mogshot of ur self\\ntf\\n2 what\\nBro\\nur whalecum\\nSmall processing units problems ð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8fð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8f\\nwhat\\nat least u dont send pics of whatever u u want\\nSay it pussu\\ni dont wanna give ideas\\nnvm\\nwym nib\\nim profusely disappointed\\nplz dont be what i think it is\\nnah, im natural baby\\ni cant laugh too loud\\nim in the lib\\nbro\\nNo cuz im shitting\\ncuz ur brain doesnt function as it should\\nHave you ever tried whey protien?\\ncant relate, my body works as it should\\nTold u didnt lose the war\\nIm shitting rn\\nAnyways\\nDid i just type but instead of bout\\nWhey protien = farts all day\\nBro doesnt know but lactose\\nso u a cow?\\nso u made out of protein?\\nsince cows are protein they fart\\nor that protein itself farts?\\nso u telling me grass has protein?\\nBro protein = farts\\nits screaming for help in form of smell\\nur body says otherwise\\nmust have been a 10\\nnice one\\ncuz me not there\\nIâ\\x80\\x99m healthy\\nThat someone came and was hesitant to sit beside me\\nGet help\\nfr\\nI just farted so bad\\nBro\\nSad yousef\\nstfu i dont need ur approval dad\\ni still gotta learn this language some day\\nGood one\\nis that why they like Ruby?\\nOil up nibba\\naverage asian\\nkekw\\nð\\x9f\\x92\\x80\\n$1 if u do\\nJessie\\ni dare u to push that woman\\nnvm\\nand my phone isnt loading..\\non pc it doesnt show\\nsend normal pic\\nbro\\nbto\\nStill commuting\\nfking nerd\\nah u have gym\\nbut u can chill if u free...\\nu dont have to do it since its my job\\nwanna join\\nim doing redstone in my mc world\\nyo\\nlet it cook\\nLetâ\\x80\\x99s cook\\ndone\\nComment so i can ratio you again\\ntechnically everyone is everyones cousin\\nhttps://youtu.be/_F_-fTJvEw0?si=G550z5wPgdx3CViy\\nu gotta focus\\nMy stomach is bugging\\nIm still there\\nI couldnt do it\\nBro\\nshorter ones have easier access tho\\nhows shit going\\nbro\\nbro doesnt get it\\nim going to class\\nwhere tf are u son\\nikr lmfa\\nWe will get kicked out if we have low attendance\\nBro ask the guys for the code\\nthats what they all say\\nð\\x9f\\x92\\x80\\nim in asda looking for food yo\\nIm coming\\nCode\\nbro using statistics to find the criminal\\nBro\\nthats u\\nwhere tf are u samurai\\njamal.kr\\nand i still got it wrong which makes it even funnier ð\\x9f\\x98\\x82\\nBro you wrote 3 lines of complaining about the joke\\ninside joke\\ni guess its too internal\\nfunny that no one got the joke lmfao\\nI wouldnt do you like that\\nnah ur my homie\\ni thought u would say ratioed\\ni was just waiting for u to say something abt it\\nbro ð\\x9f\\x92\\x80\\nSure\\nlike my comment plz\\nlike vr glasses or android phones have\\noc it could be custom res\\nor im over analysing a dumb fking 0 effort meme and ruining someone trash\\neither this meme is trash and not accurate\\nits not a thing\\ni looked it up\\nandroid phones?\\nwhat kind of resolution is that\\nalso 1980?\\nX,Y\\nsee, im right\\nbut the first one is always the X\\n1980 is vertical....\\noh wait no\\nlet me guess, is it because they have their eyes almost shut?\\nà²\\xa0_à²\\xa0\\nYeah same the one I have canâ\\x80\\x99t complete anything (â\\x95¯_â\\x95°)\\nthe ones i have dont even know how to make a website\\nonly if i had friends like that Q_Q\\nbro is practicing\\nayo its my whole generation\\nYooo you actually completed your robo dog\\nik a guy thereâ\\x80¦\\ninstead of lib lets hangout in MI\\nyo\\nWhere are you\\nBro im in MI\\nI just me him\\nwhere u at\\nwhat a fking nerd\\nlmfao\\nim outside of his room waiting\\nmy supervisor stood me off\\nbro\\ncomments\\nyes\\ncheck whats\\nits hilareous\\nAre you?\\nliterally cooking while fighting\\nBro im coming to uni tomorrow\\nwhere they are cooking something\\ni like the first part more\\nCute baby\\nð\\x9f\\x91¦ð\\x9f\\x8f¿\\nFucking a teddy bear\\nSeen it\\nu havent even seen it\\nIs different level the same as cringe ass disgusting ass stupid ass level\\nits the same thing just on a different level\\nuk all those â\\x80\\x9cfunnyâ\\x80\\x9d tiktoks u send me\\nits not porn tho\\nYouâ\\x80\\x99re the devil\\nim trying to no fap bro\\nIâ\\x80\\x99ve seen the japanese porn\\nbro just ignored all my other messages\\nu are missing out\\nThe good ol jerking in a circle\\nIm not clicking on this\\njapanese women can deffo cook something\\nhttps://crazyshit.com/cnt/medias/137891-what-the-fuck-is-wrong-with-japan-volume-38\\nhttps://lizengland.com/blog/2014/04/the-door-problem/\\ngood thing i came back before she came back from france\\nHALARIOS\\nLiked a message\\nHello,\\n\\nNo problem at all! I completely understand, and I\\'ll be here when you\\'re ready to continue our conversation. If you have any questions or need assistance in the future, don\\'t hesitate to reach out. Take your time, and I\\'ll be here when you\\'re ready.\\nHello,\\n\\nIâ\\x80\\x99m currently occupied and unable to respond. I appreciate your understanding and will get back to you as soon as possible.\\n\\nGenerated by GPT-4.\\nthx for worrying abt my time\\nbusy\\nwhy\\nstop messaging me\\nu speak it?\\nenglish?\\nI donâ\\x80\\x99t someone to screenshot my racist remarks\\ndelete more\\nbro thinks heâ\\x80\\x99s the minecrafter ð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8fð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8f\\nI bought 8 for 17\\nhow much did u buy it for\\nQ-Q\\nWhy didnâ\\x80\\x99t u tell me yesterday\\nToo late\\nu could buy my 8gb so that i can buy a 16gb\\nme\\nit just hit ne\\nyo did u buy ur ram\\nsuh\\ncome dc\\nBro\\nWtf\\nBroooo\\ni sent it to her\\nbut ive almost sent it in some situations\\nthe only thing in this story missing is the poop\\nand i tried to uplift her mood\\nand spoke to me\\nhas once been upset by him\\nshe has a bf\\ni liked her in a romantic way\\ni have a russian friend\\nbro\\nlmfaoo\\nOmg listen to first 3 seconds itâ\\x80\\x99s you\\nthats some funny shit my friend\\nn?\\nyo\\ncome\\nð\\x9f\\x91\\x8dð\\x9f\\x8f»\\nç§\\x81ã\\x82\\x82\\nalways\\ni actually do tho :/\\nStop acting like you have little time\\nstap wastin mu taim\\nI was gonna say ur mom but i wont\\ntrain busier than ur ass on a friday\\nsuh\\nBro\\nour dc better not be leaked\\nand\\nlmfaoo\\nSaw that shit\\nBro has roblox on his laptop\\nNo code\\nNo need to come\\ni went to brazil and now idk how to get out\\nim lost ð\\x9f\\x97£ï¸\\x8fð\\x9f\\x97£ï¸\\x8f\\nBro where are you ð\\x9f\\x97£ï¸\\x8fð\\x9f\\x97£ï¸\\x8f\\nHEHEHEHAð\\x9f\\x97£ï¸\\x8fð\\x9f\\x97£ï¸\\x8fð\\x9f\\x97£ï¸\\x8f\\nhttps://youtube.com/shorts/TxkGYFhdggw?si=XhgC1Mtukv7fHHWO\\nAnd got two ð\\x9f\\x91\\x8dð\\x9f\\x8f» instead of ð\\x9f\\x98\\x82\\nbro got fried by the Atomic man\\nI got cooked\\nGo gym my n\\nlol\\nand i wont take the 5 years in prison cuz i didnt point at anyone\\ni was thinking abt something like that actually\\nMake the laser points to the nearest hoe\\nI have another idea\\nOk\\nsadly i live in UK\\nalready done too\\nWith a gun i mean\\nlate\\nlame, ive already done that years ago\\nwhat time\\nTurret\\nwanna come party on Friday\\nyo\\nhttps://youtu.be/7xXARKA3O_Q?si=Hq_42BDrQojC0UR4\\nð\\x9f\\x98\\x82ð\\x9f\\x98\\x82\\nyousef last time he has to communicate with a woman\\nMatrix\\nlmao\\n(i thought the message was from the same person)\\nand i was like tf is going on\\nthen u said this\\na friend of mine said emergency\\nbro\\nhow many people you advised to do tax fraud\\nnumber of bodies buried in the backyard\\naverage of rape per new woman you meet\\nlost kids count\\nbody count\\ncocaine per day intake\\namericans be like\\nMd105\\nBro\\nSo its my win\\nI farted before she came\\na fking whiten humanoid\\nI was gonna be racist\\nlmfaooooo\\nNvm a lady came and kicked me\\nBook room\\nwhere u at\\nSuh cuh\\nyo\\né»\\x99ã\\x81£ã\\x81¦ã\\x81\\x8fã\\x81\\xa0ã\\x81\\x95ã\\x81\\x84\\nì\\x98¤ì¼\\x80\\nJorge pov\\nì¢\\x8bì\\x95\\x84ì\\x9a\\x94\\nì\\x95\\x88ë\\x85\\x95\\nã\\x83\\x8fã\\x83¼ã\\x83\\x90ã\\x83¼ã\\x83\\x88\\nBro dont know where is minecraft01 smh\\nI aced that class\\nBro failed at jokes\\nwe have class in the first main character room\\nwhy do u look exactly like him\\nIm just saying\\nÂ£70\\nYAPIDIYAPIDILA\\nYapping expert\\nelse u would be eating donuts\\nBro is yapping\\ncuz the hormones kicked in\\nso the doctor recommended that she should take a fat shit\\nMom love me\\nJokes on you\\nurs said the abortion didnt work\\nUr mom said that\\nsoon\\nDo the bank\\nhttps://youtube.com/shorts/RqW8oXa0GkM?si=SeWS7Y1p_eb5k2-z\\nhttps://youtu.be/Ggh3Mu40200?si=PvjPDLzmkBdEC924\\nThe og\\nIm out\\nthat was petra lmfao\\nlmfao\\nSame aura\\nItâ\\x80\\x99s him or the alpha version of him\\nu need glasses mate\\nomfg\\nð\\x9f\\x98\\x82\\nU think that dude is gopinat?\\nThe polish guy\\nidk him\\nfr?\\nWhat his name again?\\nThe guy infront of me is the one who petra kicked out of the group?\\nYe he said\\ngame?\\nyap yap yap\\nThought any game is ok\\nOhh\\nAction\\nTo\\nRomanian rush back\\nMuscles\\nif u have a different name for fat\\nSo big\\nI wanna see ur pov\\nTake a pic\\nBro are you for real?\\nYe\\nu look so fat\\ntf\\nhave u been doing gym every single day\\nbro u so fking buffed\\nI AM\\nu aint cool bruv\\nBrazilian activities\\nDonâ\\x80\\x99t ruin my cool look\\nI will kill u\\nStop\\nã\\x81\\x98ã\\x82\\x83ã\\x81\\xad\\nì\\x98¤ì¼\\x80 ì\\x95\\x88ë\\x85\\x95í\\x9e\\x88\\nOmg\\nyapping?\\nbro is yapping again\\nnow bro is nervous\\nof ignoring\\nafter months\\nwhy bro talking to me now\\nkmsf\\nwhen i ask\\nso the Ye Men\\nWhen are u arriving\\nTrain\\nA word used by the lesser people\\nwhixh\\nSamsies\\ncuh?\\nDont let me started on ur mom cuh\\nin da buz\\nmonke chan\\nBro where u at\\nmoke chan\\nI was looking for this img omg\\n5617.977528 bananas\\nWhat the fuck is a kilometer\\nGod only knows what im gonna do with it\\nð\\x9f«µð\\x9f\\x8f½â\\x9c\\x85ð\\x9f\\x87°ð\\x9f\\x87·\\nOk\\nã\\x85\\x8eã\\x85\\x8eã\\x85\\x8eã\\x85\\x8eã\\x85\\x8e\\nð\\x9f«µð\\x9f\\x8f½â\\x9d\\x8cð\\x9f\\x87°ð\\x9f\\x87·\\nomg blud\\nã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8b\\nthat mustve been painful for u\\npfffffffff\\nI just had to defend wlv honor on my own\\nThey are from here\\nWlv isnt bad but its not good, today i met with some people and they asked me why wlv its really bad\\n?\\nHow tf is He chan\\nalso probably cuz of He Chan ã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8b\\nBirmingham is better\\nfor them wlv is really really good, and its that wlv is bad, its just that its not the best but we arent grateful for all we have\\nThere are better choices\\nWhy wlv\\nin Korea education is really bad\\nlmao ur not him\\nits weird\\nHow tf in their right mind would pick wlv\\nill help them tho\\nnah\\nSame classes\\nBut they wont be with us\\nyas\\nKoreans\\nand they are extraverts\\nive seen 3 at least so far\\nI cant believe it\\nA girl in cs classes\\nall of it\\nThe bts people\\nBusiness? Computer science? etc\\nwym\\nI meant what major\\nBro\\nall of them\\nWhat department\\nkeep in mind thats only abt %20 of them\\në\\x82´ê°\\x80 15í\\x8d¼ì\\x84¼í\\x8a¸ í\\x95\\x9cêµ\\xadì\\x9d¸ì\\x9d´ë\\x9d¼ê³\\xa0 í\\x96\\x88ì\\x96´\\nã\\x81\\x82ã\\x81ªã\\x81\\x9fã\\x81¯é\\x9f\\x93å\\x9b½äººã\\x81\\x98ã\\x82\\x83ã\\x81ªã\\x81\\x84\\nã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8b\\nDonâ\\x80\\x99t let them anywhere near me\\nbro i canâ\\x80\\x99t speak to women\\nì\\x98\\x88\\nã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8b\\nare they in our uni?\\nBlud you are not korean\\nã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8bã\\x85\\x8b\\nBro lmaaaaaaaao\\nwtf this dude talk like a redditor\\nu\\nCheck this out\\nBro\\nThis also\\nThis shit is great\\nsorry, ill be behave like an npc and only like anything u send\\nim not sending u a meme ever again\\nits not cold or hot, its how much energy u are losing or gaining, but at some point it will equalise and u will feel normal again\\nits like temperature\\nbut happiness is temporary\\nu should want toâ\\x80¦ i forgot what it was\\nu shouldnâ\\x80\\x99t want to be happy all the time\\nlisten to papa Alex\\nbruh is using slave ð\\x9f\\x98\\x8e\\nBro the comments ð\\x9f\\x92\\x80\\nfinally i can put that gym discount they keep shoving up my face to use\\nIm quiting\\nDont u need a gf\\nWhat about u\\neveryone has to start somewhere\\nHe is cringe most of the time\\nor a f for that matter\\nnigga go get a gf\\nThis is jorge\\nSay hi\\nait\\nwow\\nBro im off to speak to my japanese friend\\nik who she is\\nHaaaaaay\\nfkin weeabo\\noutside where\\nkek\\nIâ\\x80\\x99m still outside\\nor youtube\\nwanna watch a movie or play minecraft?\\nu gotta keep me awake tho\\nim suuper sleepy bro\\ni guess\\nOr a project\\nPart time or smth\\nBut we have time until may\\nLiked a message\\nMe too\\nim broke\\nbrah\\nThis May\\nLets go\\ni want that\\nwait what\\nhttps://youtu.be/2WqK09f0JFc?si=9OwZpCF_ApCgt9e_\\nLets go to japan\\nListen\\nI will wipe that shit\\nbut its on her titties\\nWorst sauce ever\\nYou lost me at bbq sauce\\ni want a big hot milk mama egirl to eat my libs with barbecue sauce on her titties too\\nNo\\nthats hot\\n( Í¡Â° Í\\x9cÊ\\x96 Í¡Â°)\\nHis limbs was eaten ð\\x9f\\x92\\x80\\nThats you when I finish from you\\nbutt plug\\nbro is a vibrator\\nAnd i will fuck his hot daughtor\\nJordan Peterson is cringe\\nesakly\\nBro watched a motivational reel now he wont sleep\\nactual cringe\\nbro watched that tiktok talking abt sleep health\\nNibba said â\\x80\\x9cu sleepingâ\\x80\\x9d ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nNo need to brag that you dont care of ur health ð\\x9f\\x92\\x80\\nBut i sleep again for 2 hours\\nu sleeping?\\nNow 4\\nI had to sleep min of 8 hours\\nWhen i used to fap\\nBro\\n.\\nhuh?\\nlearn it now\\nwym like what\\n9 days into no fap\\nAlso\\nLike what\\nsuper  useful shit\\nlearn how to docker a python\\nSup\\nyo\\nnu uh\\nu are the one distracting me\\nbut im\\nLevel: impossible\\nTry to focus on one thing challenge\\n34.105.212.74\\nkubernets\\nwachu doing\\nYo\\nØ¨Ø±Ø§Ø²Ù\\x8aÙ\\x84Ù\\x8a Ø´Ø±Ù\\x85Ù\\x88Ø· = brazilian bitch\\nAllah akbar = God is greatest\\nLmaaaao\\nØ²Ù\\x86Ø¬Ù\\x8a\\nimma learn arabic now\\nthats amazing\\nu guys have a word for nigger\\nomg\\nu said allahu akbar boom?\\nwait what\\nI just didnt want you to blackmail me\\nYou know what it meant (wink)\\nthen i got distracted and forgot abt it\\ni was gonna translate it but i kept failing to select it\\nwhat does that text u sent yesterday meant?\\nyo\\nkubernetes\\ni found a path btw\\nnigga stfu\\nbrah\\nThis was on my feed for some reason\\nhttps://youtu.be/g72OUcarfv4?si=ZRB2XGD4jqYvcqe6\\nLmao\\nmore like konichiggaâ\\x95°(*Â°â\\x96½Â°*)â\\x95¯\\nnigga what?\\nBanned from using the n word\\nbro black rejected me\\nð\\x9f«µð\\x9f\\x8f½ð\\x9f\\x91\\x8eð\\x9f\\x8f¿ð\\x9f\\x91\\x8eð\\x9f\\x8f¿ð\\x9f\\x91\\x8eð\\x9f\\x8f¿ð\\x9f\\x91\\x8eð\\x9f\\x8f¿\\nð\\x9f\\x92\\x80ð\\x9f¤\\x8cð\\x9f\\x92¦\\nð\\x9f«¦\\nð\\x9f\\x91\\x81ï¸\\x8fð\\x9f\\x91\\x84ð\\x9f\\x91\\x81ï¸\\x8f\\'\\nð\\x9f\\x91\\x89ð\\x9f\\x8f½ð\\x9f\\x91\\x8cð\\x9f\\x8f¼ð\\x9f\\x98»ð\\x9f\\x98»ð\\x9f\\x98»\\nWtf is happening\\nð\\x9f\\x91\\x8cð\\x9f\\x92\\x80ð\\x9f\\x91\\x8d\\nð\\x9f¥º\\nð\\x9f\\x91\\x89ð\\x9f\\x8f½ð\\x9f\\x91\\x88ð\\x9f\\x8f½\\nthats lowkey sick ngl\\nð\\x9f¥º\\nð\\x9f\\x91\\x89ð\\x9f\\x8f½ð\\x9f\\x91\\x88ð\\x9f\\x8f½\\nð\\x9f¥º\\nð\\x9f\\x91\\x89ð\\x9f\\x8f½ð\\x9f\\x91\\x88ð\\x9f\\x8f½\\nð\\x9f\\x91\\x89ð\\x9f\\x8f½ð\\x9f¥ºð\\x9f\\x91\\x88ð\\x9f\\x8f½\\ncute dates are overrated\\nthats a good stoic practice, but make sure u do it for the uncomforting you feel and not something else\\nI want to go on cute dates\\nYou are overrated\\nyousef\\nIâ\\x80\\x99m just challenging myself to see how long\\nbe content with yourself\\nwives are overrated\\nsadly it only lasts for abt 3 months, after that u gotta find another bitch\\nIâ\\x80\\x99m looking for a wife\\nthat way porn will be obsolete, u wont even like it cuz ur imagination is just so much better\\nand if u cant then go out with bitches so u can have a better imagination\\njust use ur imagination bro\\nThe ratio per day is crazy\\nWhen I masturbate I do it alot\\nBoth\\nu mean no porn right\\nwhy no nut\\nI blocked all porn website a week ago\\nNo nut until marriage marathon\\nhttps://www.youtube.com/watch?v=T77MmWALKVY\\nThis is white\\nð\\x9f\\x96\\x95ð\\x9f\\x8f»\\nð\\x9f¤\\x9bð\\x9f\\x8f¿\\nbro wished he was white\\nð\\x9f\\x96\\x95ð\\x9f\\x8f¼\\nare you proud of me yet?\\ncuz we are shit bros\\nJust why\\nWhy\\nMain\\nOk im just doing one more thing then boom\\npush what uve done to main\\nBro is on character from day one\\nð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\njust like a romanian would\\nim still in since years ago\\nSteal\\nNo need to draw\\ni didnt do yet cuz i hate them so ive been procrastinating\\nBrain fog\\nNo fap pls\\ni gotta do the drawings\\nAre u still in or was it an excitement short period and then nothing more\\nbut finishing my shit a quick fap ill come back\\ngot busy\\nWhat happened to the game\\nbtw\\nGo for it\\nBut if you believe that tower will be a great addition to you and you will achieve something in this period\\nfr ð\\x9f\\x92\\x80\\nJob\\nearn?\\nBut before making any decision study the matter throughly. Consider that a british citizen might earn more than a south american bruv\\nso i dont even qualify for it anyways if its already a thing\\nnow u would need to stay here for 9 years\\nplus my dad said they will make it harder to get a passport\\nim already settled\\ni dont get it why everyone thinks the passport is so important\\nPassport later\\nThat what i mean\\nor from the app\\nyou can make the money the year after that from ur job or smth\\ni can just get the passport later\\nwhy\\nWell idk think its a bad idea tbh\\nand the tower will allow me to have my own cloud and run the app much easier and even train my own models\\ncuz i dont travel\\ni think imma buy the tower with the maintenance loan instead of a british passport\\nsi?\\nbro\\nModem\\nOk lets launch romanian rush asap to get u a port forwarding mode\\nalso they have almost 1giga for Â£52\\nfaster for cheaper tf\\nweird\\nso if we downgrade to a 5G which is probably around Â£10 a month i guess it would be cheaper\\ni saw its basically Â£20 for the cheapest\\nSome wifi plans is affordable but i think the modem/broadband costs extra\\nplus wifi gives me ability to open ports which would be something amazing for me\\nbut now with my brother here it doesnt make sense anymore\\nFair enough\\nwe dont have wifi cuz its cheaper only data\\nwhat else am i gonna use\\nDo use it at home?\\nNot too bad\\nÂ£22 i think\\nHow much do u pay for unlimited data\\nEE\\nBro using 3g\\nð\\x9f\\x92\\x80\\nnvm\\nthey are forever loading\\nYe\\ndid u send 2 pics?\\nIdk i didnt do anything\\nhow do u see like count?\\nno fking way ð\\x9f\\x92\\x80\\nFunny af\\nYou can see the people roasting him in the comments have more like than the actual video\\non your way\\none sec\\nbro is not him\\nbro i need a 200 million\\nhttps://www.youtube.com/watch?v=V2i_NReAOaw\\nhttps://www.youtube.com/watch?v=J1XTHNGNj4Q\\nI would buy that ngl\\nthis is how we make money, forget the romanian, put trump on it\\nFat shit\\nBruh\\nactually they called me\\nthat was a bald move\\nthen threaten me\\ni dont want the algorithim to know my thing\\ni cant make a ph account\\noh, i thought we had something in common\\njoke\\nbruh\\nwait u fight ppl on pornhub comments?\\nis it?\\nohhh pornhub\\nmain character houses?\\npH? like acidity?\\nyou name it\\nmc houses\\nmaths\\nThey have pretty good tutorials ngl\\nI do that on ph\\nand whats crazier, some ppl actually think social media is the internet\\ninvestigate what is the internet\\ni wanted to see how bad it got\\nit was for research purposes\\nlmao\\nThat explains it\\ngrey mass\\ni lost at least 5kg of brain mass every minute i was there\\nworst shit for the mind ever\\nmy twitter used to be reddit comments on news posts\\ni actually dont use twitter\\nYou can do that and tell me what happen ð\\x9f\\x91\\x8dð\\x9f\\x8f»\\ni go away from twitter but twitter doesnt go away from me\\nholy shit\\nas i said before, maybe in 20 years? i actually have no idea abt that, i dont think this has ever happened before, but with AI we could simulate it and see if its good or not\\nThats my take on it\\nThey can help in some way but i think the harm is grater\\nsimple questions for complex issues\\nYes thats what they dont understant\\nsaying things like that should be illegal\\nWell, thats part of it\\nthey could be harming ppl in some way\\nthats also superficial\\nAlso im talking about the kind of liberal how says let them be hoes if they are not harming anyone\\nstoicism is basically the best part of all our society\\nso my beliefs are whatever values brings out the best of u is what u should stick with\\nor allah in your case im guessing\\nwe arent jesus to save literally every single human on this earth\\nlet them ruin their lives\\nthey are adults\\nand for what?\\nwe arent gonna babysit them are we\\nbut thats not our problem\\nye i also agree with that lmfao\\nTell them what is right and wrong\\nsounds a lot like those communists twitting abt who they hate capitalist on their $1000 phones\\nNo one to guide them\\nmaybe thatâ\\x80\\x99s the case. But what Iâ\\x80\\x99m sure about is having no values is a 100% parental issue. Iâ\\x80\\x99m sure that of hoes none of them on their right mind\\nso when u say liberal, are u mad at creative ppl who invented the phone u are using to be mad on twitter\\nlike steve jobs\\nliberal means creativity, means thinking out of the box\\nsame with jordan peterson, he wants good for me cuz thats his job, and he is a liberal, else he couldnt have the job he has\\ni used to think ben shapiro was trying to tell me how to get a better life, and i still think he is but when he gets mad at someone  cuz he thinks that person is liberal when they are indeed on his team it just makes me realise what these ppl really are after\\nits a common occurrence\\nand people who have the right values are the ones who consider themselves liberals\\nppl who call themselves conservatives are just far left who are mad at something, u just gotta figure out what exactly u are mad, i mean for real, it can be some parental issue\\nlaughing rb\\nð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nu know whats funny\\nTate is not the type of muslim you should aim for\\nAnd more islam\\nSo please less numbers about of girls\\nandrew tate is stoic/muslim because of how it helps him think, just like steve jobs only wears one type of tshirt, and i like that, saving decisions is an engineering thing\\nBut im trying my best\\nIâ\\x80\\x99m not saying i can represent islam\\nTrust me\\nYou will be a better person\\ni mean\\nIt has some interesting stuff\\ni will, once i get enough time\\nRead about Islam\\nnumbers are only one part of the stories\\npapers, history\\nOk sure\\nbasically what your religions was built on top of\\nKnowing everything just cause you read some numbers?\\ni didnt say without, my values are stoics\\njust a hint fo ru\\nand and\\nalso living life without values isnt life too\\nliberal isnt lgbqt\\ncuz being on tiktok all day ranging isnt life\\ntrying to show ppl the better way to live life\\nim a teacher remember\\nim not mad\\nby the contrary\\npls teach me mr jorge\\nidk what economy means also\\nyou got me ð\\x9f\\x96\\x90ð\\x9f\\x8f½ð\\x9f\\x92\\x80ð\\x9f¤\\x9að\\x9f\\x8f½\\nso you assumed i dont know what it means because you are mad?\\ndo you even know what liberal means?\\nand by the americans too\\nwtf are you even saying?\\nyou are so brainwasched\\nholy shiet\\ntiktok\\nagain\\nsee\\nLiberal\\nis it really 100% religion\\nVs\\nMuslim\\nwhy u so mad abt it\\nSheâ\\x80\\x99s for the street\\nwhatever man you can make excuses about hoe saving lives and helping economy but Iâ\\x80\\x99m good\\na korean AI to be precise\\nu need an AI girlfriend my guy\\nhonestly that would be my goal, most ppl wanna die at 100, i just wanna figure out wtf is outside this universe, AI gives me hope to this which is why i take it so serious\\nyet there are not saving me from depression\\nthis is what i mean with be the best of urself u can be and the rest falls into place, worrying abt hoes making more than us making AI that can save lives is the super superficial, cuz like u dont know if those hoes are saving millions of men from depression(its an example, im an abstract person, java)\\nYes yes and maybe we can transform our conscious to a robot that require less maintenance and live like that\\nforget youtube home, only use the search to search for unity tutorials\\nlive on the world of tutorials and documentations like i do\\nplz just stop social media for a whole month\\nisnt is obvious\\nstop, getting, caught, on these easy traps\\njobs we thought we needed and were important will be things from the past\\nItâ\\x80\\x99s all cardi bâ\\x80\\x99s fault\\nthe pyramid is being turned upside down\\nAI is changing the whole game\\njust wait\\nwait\\nthe economy in this earth is a single big loop being fed only by the sun\\nDoctors are paid like shit\\nmaybe we just dont need doctors as much? hoes dont get hurt, so maybe we had a lack of doctors cuz of wars, and now with good tech ppl are healthier than ever and dont need doctors\\nbro even in the us where no health care is there\\nbut then how can the hospital afford, so complain to the patients or whoever pays\\nwhy tf arent they striking more\\ntell that to doctors\\nBitches shouldnt be making more than someone who save lives\\nim talking abt helping, economically rn, maybe in 20 years they arent helping cuz they are destroying values which is what keeps the country also running. But im talking of the measurements that we can do and predictions we can make in the real world\\nBut if you read what i said maybe we wont be having this convo\\nI know that they have more money than me no need to rub it on my face\\nrooting from a single bad grain\\nlike yeast\\nit seems like that indeed\\nwe can give all our bank balance away and buy tons of burgers and pizza but without recording it and posting on tiktok we would only be able to do 0.000001% of what those hoes do to the \"poor\" in a day\\nthey are helping the \"poor\" whatever that means more than we are\\nthose hoes are actually helping the economy more than us rn\\nThe west is doomed\\ntho that is a good thing on the surface but society is falling\\nmoney needs to move\\nin reality yes thats how it works\\nso I was talking about the fact that of hoes making so much money rn and thatâ\\x80\\x99s not fair but you look to it from a different angle which is thatâ\\x80\\x99s ok because more money spent the wheel of economy will move and yare yare\\nliterally\\nsheeps\\nredditors honestly think USA is helping Ukraine, and that Russia should just stop the war now\\ni talk to opposite actually, i read a lot of redditors and their opinions are always so superficial, they truly believe what they see on the news is true when they can literally just open their eyes and see the truth in the real world\\nbut you have no values\\nand you talk like every redditor no offense\\nno offence but since u crossed that line\\ntho andrew tate talks more logic than you\\nand you are talking instagram reels of andrew tate logic\\nYea and thats the problem\\nwhen im talking numbers\\nwhy is it always me who doesnt get it\\nnukes are like AI because of the capitalistic system we live in, we see the deathtrap but we have no other choice than to run towards it else we die\\nYou wonâ\\x80\\x99t get it\\nI wont talk about this with you cuz we have different values\\nWhatever bro\\nthats a whole different thing\\nif they legalized drugs in mexico u would have all those cartels killing so many ppl\\nportugal is a living proof\\nall that comes from stopping this from happening\\nand the problem is the engineers\\npeople dont have contro\\ndont let ppl buy too many beers or too much weed thats all\\nits the amount of use\\nlook at car accidents\\nNukes\\nthe issue isnt drugs\\nGuns\\nAnything you got is ok\\nconnections, violence\\nanything moving money\\nit is but where tf u got that logic\\nThey are doing millions from what they got\\nThen drug dealing is ok too\\nOk thats ur logic\\nneither Alex Hormozi\\nyeah sure\\nso you saying Elon musk doesnt deserve everything hes got?\\na person making millions using what they were given is an amazing skill\\nDont sugar coat it\\nyou know what i mean by tiktok, social media, youtube shorts, instagram reels\\nA hoe is a hoe\\nyes that was a joke, 9/11 was an inside job\\nSecond of all\\ni dont have tiktok\\nwe are the engineers, we construct what the public consumes\\nfirst of all\\ntiktok is for the public\\ndidnt u see i literally came with numbers cuz i had no idea abt onlyfans and doctors statistics, stop taking tiktok as facts\\nand now you are doing the same saying all the muslims is the same\\nidk everything, which is why im always studying\\nbut you the mentality of knowing everything will get you nowhere\\njust like the muslims started 9/11 u started this bro\\nyour religion is against violence, but once a muslim eats a pig u will quickly jump on him and judge him or even hurt him\\nsay whatever you want\\nyou know what\\nsee, contradiction\\nmaybe when you have some exp or you wont now but on the judgment day\\nyou the one who will get it\\none day u will get it\\nu say, money is good but we dont flex, but that hoe that worked and risked her life is rich, fuck her\\nso the risk of 7-8 years in mid school or 4 years in cs is not like the risk of hoes putting some pussy onlibe\\nlike u guys make sense, until we bring the world hoe or not halal\\nwhy are muslims so contractionary\\nim disappointed really\\nim defending the good mentality\\nthatâ\\x80\\x99s an answer of someone trying to defend a hoe\\ndo you know you someone who is doing of?\\nthats what we dont do, we dont risk shit\\ni mean put work in and risk something\\npeople willing to do raise their fingers\\nnot hoes\\nhoes should be making millions\\nð\\x9f¤\\x93\\nor is it your mentality of being a victim\\nare NBA really the problem\\nso now you tell me\\nthats 4M people\\nit seems like around 2% of onlyfans creators are making $100k a year\\n$100k\\nwho are 100% making $100 on average\\n102,400,000 of doctors\\nsame thing goes for doctors\\nmeaning we need more workers and more efficient tech and more research\\ncuz those creators will spend money on the very products those workers are producing\\nthing*\\nand thats a good think\\nthat means, money going from worker to entertainment(since onlyfans is all abt hidden perks like patreon, not just naked hoes)\\nso thats $30B circulating\\nfirst, onlyfans has 200M creators and the average is around $150 a month\\nthats the wrong way of looking at things\\ndc\\nFuck them\\nBut yeah\\nHoes making millions on only fans and doctors making 10 times less\\ncuz if u do that then everything else fits into place\\nbest u can do is be ur better self and fk everyone else\\nit is what it is\\na girl that is recorded on camera and posted on tiktok gets millions while millions of ppl literally starving in front of the house of those same ppl who donated will be ignored\\nindeed\\nYes the society we live in is such a cool one. A black criminal getting killed made the world repeats the sentence BLM while poor kids around the world are dying and Israel is killing people in palestine but yes BLM\\nactually zuck made the worst deal than elon tho(talking abt metaverse vs twitter), so its like two trolls getting trolled\\nthis society we live is amazing, a fight is worth more because it has more entertaining value\\nstealing zuck?\\nZuck wants a fight\\nAfter threads hes mad\\nElon is stealing zuck\\nusually u get used the more it gets used\\nand he will, but since time is relative he will only stop his own time\\nbro thinks he is gonna stop time\\nDoesnt feel good like it used to be ð\\x9f\\x98«\\nrn\\nBro iâ\\x80\\x99m taking the worst shit tn\\nhttps://www.youtube.com/watch?v=jjs2vPR19mQ\\nbro drinks coffee when ppl drink spiders (cuz they are sleeping rn)\\nIm ascending to be a giga chad\\nAnd no fap\\nToo much caffeine my typing cant be as fast as my brain rn\\nKnow\\nYou already now the answer\\njust give me the actual file\\ndo u have some of that good old crack?\\nAlso its ez to create animations\\nait\\nAseprite\\naesprite or ps?\\nso\\nbro thinks heâ\\x80\\x99s him\\neggxactly\\nhim and notch\\nâ\\x80\\x9cweâ\\x80\\x9d\\nfor the modding\\nLmao\\nassets work too\\nthats how we call it in minecraft\\nso instead of learning how to make a pixel editor, i made a python program to do it for me\\nTexture?\\nu know, a while ago i needed minecraft textures and i didnt know there was already a program for it\\ncuz u are doing them lol\\nthere is no graphics\\nLike 20mb\\nAseprite is so lite also\\nPhotoshop for everythig\\nThats my answer to everything\\nyes and?\\nCrack\\ndo i have to buy it?\\nBut aseprite is pixel art specialized\\nOr photoshop\\nAseprite\\njust give me the program for it\\nsure\\nlmfao\\nso ill just draw everything (or make a bot to draw it for me)\\nI will send you a cracked pixel art course\\ncuz those packs are just garbage\\nBro\\ncuz thats my weak spot and i need to improve it\\nI wanna do it ð\\x9f¥¹\\nimma work on the looks then\\nait\\nah\\ngets a korean bitch on september\\nMe\\nNo\\nwho finishes first\\nLet me do the click too\\nso u do the cop i do the lock picking\\nthe cop and u is the bar\\nAnd do the lock picking\\nyeye\\ndont even need one\\nI will scrab that\\nThe green bar thing\\nill do the tap one then\\nsure\\nWe can test with both\\nbut also the closer the cop gets to u\\nthe more u tap the more u get\\nno\\nactually\\nso 2 types of steal\\ni like that\\nyes\\nAnd the cop is just like an obstacle\\nIf you just click to steal wth are we doing\\nOur action is robbing houses\\nWell as I said before you need some challenge and action in the game\\nwhats stopping u\\nwhat thing?\\nwhat are u thinking on doing?\\ni still have no idea what to do for the lock picking\\nhonestly, i was watching a guy go abt it, and it seems like we just gotta stick to something very very simple around a main theme, our main theme is rush game, so just the lock picking and a cop behind to justify why we are running\\nright\\nI just wanna post tweets\\nAlso I managed to make a twitter bot without that thing\\nAnd after that I will work on police AI\\nIâ\\x80\\x99m working on picking the lock\\nthe gamee\\nwhere tf are u\\nbro\\nI hope apple fail too\\nSo depressing\\nhow was the metaverse bro\\nhttps://www.youtube.com/watch?v=KW64FiB0ITg\\nI will commit today\\nyes the houses is ready\\nwe need the houses\\nwhat else u wanna do\\nbro wants me to only sprites lmfao\\nIm now looking for a Romanian dude to approve the technique\\nI will be making the stealing thing\\nthats the good part abt scripts, they can be easily changed\\nthen random houses on top\\nBut not manually\\nI mean yes\\nso just a straight line right?\\noh\\nI didnt want us to make the platform\\nyou make the sprites\\nonly difference is that i wont be making the presets\\nwhat ill do is similar\\npresets\\nthe guy creates a bunch of prests and randomly places them down\\nAlso was a while ago\\nFirst vid is bad\\nthe first vid u sent\\nits nice if u are a beginning and have a whole year to make just the map\\nWhich one\\ni just hate the concept that guy on the video showed\\nOk\\nalready made a simple platform\\ndc\\nim coming home rn\\nNibba what\\nand then once u make houses we can easily just add that to the script\\nbut rn ill focus on creating the layer of the map\\nu can make better ones later\\ni created some basic gameobjects and figured how to use them with the script\\nok so\\nbut the platforms will be created algorithmically\\nlets do that\\nyou want a platform game\\nok\\nso\\nor u still waiting for my pp\\nhave u implemented that platform thing\\nyo\\nGym\\nlib\\nyo\\nfix ur sleep fr\\ni need to\\nDont sleep\\nSry mate\\nI will be there in an hour im making fried chicken\\nI went for a nap lmao\\nim on pc\\ndiscord\\nbro calls me then goes away\\nWhat\\ntf\\nbrah\\nNice\\nim home\\nidea: easy read with audio using whisper\\nbrah\\nnothing\\nwhy\\n1h-2h\\nhow long\\nI\\'m kind of busy right now\\nWhere you at\\nbro\\nbo\\ni fking hate internet button â\\x80\\x94â\\x80\\x94â\\x80\\x94â\\x80\\x94â\\x80\\x94â\\x80\\x94â\\x80\\x94>\\nthey need ue5 for that big titty jiggle\\nbroo imagine this on ue\\nbro its not worth it just lets do the game on dc\\ncmon\\nI like doing shit at my setup\\nbut im coming to the library now\\nim sitting outside cuz i was programming java with a friend\\nwhatever you say boss\\nlibrary\\nplus its not icc\\nit translates to that tho\\nlife\\njust cuz i didnt come to icc doesnâ\\x80\\x99t mean i failed lifr ð\\x9f\\x92\\x80\\nbut if u are stopped by simple things u will never do anything\\netc\\nthen 3\\nnext time u can do 2 hours\\nand\\nThats waste of time\\nIt will take one hour to come here then stay for one hour\\nstop being lazy\\njust come here\\nwhy\\nCome dc\\nwym\\nJust hop on discord\\nhurry up then\\nAnd it will take 40 min to arrive\\nNah bro it comes and 20min\\nwait faster\\nI need to wait for next one\\nbruh bus isnt coming\\nWaiting the bus\\nwhen u here?\\nicc closes at 7\\nit stays closer till 9\\nwe stay at the lib\\nalso\\nmsg me when u here\\nhttps://maps.apple.com/?ll=52.479203,-1.899546&q=My%20Location&t=h\\nI will come if ur there\\nNo im not\\n5 mins away from icc\\nim in town\\nare u here?\\nIcc\\nYou there?\\nBro\\nnoping\\nSuh\\nyo\\nCUM FASTER\\nIm coming\\nimma fap if u dont come\\nwhere tf are u\\nbro\\nhop on\\nbro\\nStfu\\nthe one u have at 4am\\ndid u mean muslim lunch\\nIts not playing\\nOk after lunch im coming\\ncum over\\nalways\\nU in library?\\nyoutube got me confused with u so here it is the video they intended u to watch\\nhttps://youtu.be/xwrs-9-XkMw\\nwhen\\nWe shall meet\\nOk ni\\n15 evidences to be precise\\ni already got some evidence\\noh and that big milkers have an oc\\ni mean meet later?\\nwanna fuck later?\\nim going to sleep now\\nalso\\ninstagram figured out my fetish bro, help\\nMeeting cringe people\\nits not? then what is ur biggest fear\\nnah\\nmeeting people you dont know\\nbros scariest app\\nBig milkers\\nWhat tf\\nLiked a message\\nso cute *-*\\nvruh\\nbruh\\nð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nbro\\nits dead and its weird\\nu\\nwith the ppl on floating chairs\\nits like that walle movie\\ni dont even watch anymore cuz its just dead\\nyes and all my friends sending me so many memes\\nI got this meme from a friendâ\\x80¦\\nelon musk feet is hot\\nwhatever i watch instagram pushes to u to watch it too\\nim certain im basically ur influencer\\ninstagram is so repetitive\\nu send me shit i already saw at least 10 times in the last week alone\\nbro stop sending memes\\nhttps://youtube.com/shorts/Q2grU1ato4M?feature=share\\nmy homie is using the worst way to learn a language\\nbro judging his homie for trying to improve\\nbro using duolingo ð\\x9f\\x92\\x80\\ngoes to show that u arent the same when u are hungry\\nis she on her period again?\\nx.com\\nHaram\\ncheck with your ex\\nno shame, just grind\\nOk what memes are trending rn\\nto whatever meme is trending\\nwe literally just copy subway surfer but change the skins\\nsimple yet effective\\nthats perfect\\ncapybara rush\\nyep\\nLike capybara\\ntru\\nA meme game would be fun\\nMoney ð\\x9f¤\\x91ð\\x9f¤\\x91ð\\x9f¤\\x91ð\\x9f¤\\x91ð\\x9f¤\\x91ð\\x9f¤\\x91\\nflappy birds but with the gay flag as the background\\nexactly\\nbut thats thinking too far ahead, we still need the game lmfao\\nBut it least it has to stick\\nuse it as a bait\\nbut we dont add any ads\\nI know\\njust make a simple game, doesnt have to be crazy\\norganic marketing\\nI havenâ\\x80\\x99t started yet, im looking for game idea\\nyoutube\\n3 years min\\nand not 3 months\\nbut push that\\nanything\\nwhat are you on about then\\nim not talking abt games\\nso you are gonna make the next mc in 3 months or so with no prior game knowledge? that just delusional\\ni figured out a way to do the voice clonning locally so not to pay elevenlabs\\nive been busy with the translator thing\\nhave u got started yet?\\nso\\nrat game\\nbut it doesnt make sense, its like work, if u work today u get paid, but u gotta keep working the next day to earn the next day too\\nhow are u gonna pay the api?\\ntrends dies but you can get something out of it before it does\\nlike me with my tiktok bots\\nu are thinking abt ignoring quality over quantity right\\nlike minecraft\\nif u make an actual good game u only make it once and never again\\nif u live in the trends u will always be running\\ntrends die\\nso even when we thought abt it like around 7 months ago many ppl already had working games, using elevenlabs whisper and gpt\\nanything with AI in it sells\\nItâ\\x80\\x99s the trend now\\nthen we saw many ppl making it\\nme and Joshua were already thinking of making a gpt sort of game a while back\\nabt how slapping AI on a product is short sighted\\ni was trying to show a point\\nu know\\nthey me if they make sense\\nso i added some instructions\\nik u dont know how to use git\\ncringe ass name\\nhttps://github.com/bomxacalaka/makeitreal\\nShare repo\\nhttps://www.youtube.com/watch?v=3tQH4wvQCfc\\ntho minecraft multiplayer got ruined after 1.14\\nlike minecraft versions, im still on 1.19.2 cuz the new ones still dont have many cool mods\\ni usually like to use old versions cuz they are more compatible with everything\\nYe this the latest stable ver\\nis this version gonna work?\\nwhy\\nIt does matter\\ndoes this answer?\\nwhy does it matter\\nWhat version are u using\\nWait\\nim almost done setting up the git\\nif u wanna start now thats fine\\nso\\nsadly they get banned, else i would have so many followers\\nugly ass bitch\\nanother bot following me\\njust cuz he is black\\nBro looks like a basketball person\\nu mean this masterpiece?\\ndont worry about it\\nwhat art?\\njust use instagram, whatever game u find interesting where ppl in the comments are mad that this isnt like the real game we just turn it real\\nNot the best\\nIve seen ur art\\nAlso\\nthis was just a random pic i found on google to help explain what sort of games im talking abt\\nYe\\nare u talking abt this?\\nThis is 2.5d\\nI dont think this is 2d\\nWe make when you can get it for free\\njust a png right?\\nwe make the assets....\\nwe havent even made the game yet callm down\\nSo we gonna look for assets\\nhuh? whos 3d\\nCool but the character here is 3d\\nlook for low hanging stuff\\nremember what u told me, u dont need to make things complicated to make money\\nwe dont need gpt to make a game\\nbro really thinks chatgpt is AGI\\nNiga\\nNot the real one\\nbro, when i talk abt AI i mean in terms of games\\nBro that stupid ai\\nwell, the hero is trying to get to the gold\\nWhere is the AI in here\\nwe just make them but add an extra sauce\\nI have\\nhave u never seen these game ads?\\nWhat to do\\nBro im confused so explain what is game gonna be like whats the goal\\nits simple but i love the dirt particle thing\\nor place dirt on top of the enemy to defend the protagonist\\nbut instead of having to pull a stick, u have to place dirt particles to make a stair\\nand then u have a logic game where there are AI things trying to get to an objective\\nthe powder toy whcih is a simulation game, u can throw powder, fire water etc\\nimagine these 2 together\\nhere\\nits a mix of that game of logic with simulation hold on\\ni was thinking, what if we get like a bunch of AI npcs walking around trying to get to an objective and the user needs to stop using elements\\nWe dont want to model some 3d characters in 2d environment\\nyeah keep it simple\\nIts better to stick also to 2d figures\\nhm so many im not sure which one to go for\\nok what game\\nbro i asked him about npc powered by ai he answered something else. redditor\\nthose are the low hanging fruits we can use to train how to work in group\\nlike those instagram ads that everyone complains isnt the actual game\\nim thinking of just clonning others games\\nthe 2D games\\nso\\nill explain another time\\nlets keep it simple\\nnvm u arent there yet\\nim not thinking abt the best gpt, im thinking abt something much much bigger, a machine that learns forever\\ni need a model with a bit of brain power\\nnibba if i asked the npc about the weather i dont want it to answer why your mom is gay\\nit will be enough\\nif u want 0 effort game then this isnt the path for u, just use gpt-3.5 api\\nbro, its not the results, its the possibilities\\nbut we can also use falcon7B, its much harder to train, so forget having amazing npcs, but if its for a game where the npc only needs a bit of context then its perfect, so its also better than gpt3\\nlet me see the results of gpt2\\nni**a a aint using gpt 2\\ngpt2 can be trained on my laptop easily\\nthis isnt like \"if its not the latest model i dont want it\" its more like, can this be used as an npc and what can it do in real time on someones pc offline\\nstop thinking like a small brain youtuber\\nbro\\nit would take u millions of dollars just to finetune it, but those models arent public\\nimpossible\\nthey were scared of releasing their biggest versions for obvious reasons the 1.7B\\nWhat it takes to make it using 3 or 3.5\\n177M\\nplus its the smallest version of gpt2\\nahh\\ntrust me its amazing\\nyes\\ngpt2\\nthe more u talk to it the more it learns\\nimagine like a chatgpt with infinite context basically\\nfirst is how to finetune gpt2, i can even do it on my pc, so this could work on in real time\\nhttps://colab.research.google.com/drive/1IqL0ay04RwNNcn5R7HzhgBqZ2lPhHloh\\nhttps://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/311_fine_tuning_GPT2.ipynb\\nive found two ways to finetune these models to custom data, but overtraining is still something im figuring out\\nwhat kind of game are u thinking\\nimagine like a bunch of gpt-4 clicking on links and reading everything they see, but with memory so they have an objective and wont visit the same link twice and be very efficient, aka agents\\nanyways\\nopenai is gonna use agents to scrape the net\\nits better to pay someone to do it for u\\nthey are annoying and hard to make\\ndont\\nscraber*\\nI was going to use a web scarber\\nplus the way i see u doing it is using the api right? that will be costly, ik a way to do it for free and better than gpt api\\nbut i wanna do different thing\\nit\\ni know people have done ir\\ntoo many ppl already did it\\ni will do it\\ntoo late\\nnah\\nill make it 2d first on unity to keep things simple\\nI was thinking about making gpt powered npc\\nim setting up the repo for us to work on a game together\\nwanna do the unity game stuff\\nim glad i got ur attention\\nbro wtf are you sending me ð\\x9f\\x98\\xadð\\x9f\\x98\\xadð\\x9f\\x98\\xad\\nhttps://www.youtube.com/watch?v=DshRqV_wj5w\\n2:36 is my fav lmfao\\nand accidently found gold\\ni was looking for some gore shit\\ni wasnt even looking for porn\\nhholy shit\\nthis website is top humour\\nbro\\nhttps://efukt.com/22546_Amatuer_Sex_Tape_Fails_2018.html\\nsince u like those weirdos jav\\nhttps://efukt.com/24046_Psychotic_18_Year_Old_Terrorizes_Strangers.html\\nbro\\nait mister thinks he is that guy\\nIâ\\x80\\x99m productive at 3am in my room in the dark with some kpop\\nthats where im the most productive\\nwhy not?\\nu said u wanted to tell me what u were working on when we meet\\nI know i wont be doing anything at the library\\nBro I do my work at home\\nbroo come upp stop being lazy\\nwake the fuck up samurai\\ncome over\\nyo hoe\\nok i found a way to automate stars\\nblyat\\nsuch a cute gay couple\\nYo comeicc\\nhttps://www.youtube.com/watch?v=c_nCjlSB1Zk\\nbro just left me hanging Q-Q\\n52.47984800133375, -1.9087838815649967\\nWhatsapp\\nSend ur location\\nto be expected\\nOk will hide from them\\nrun else they will escape\\ntons of bitches bro\\nis there any bitches?\\nbro has to make sure he is late\\nOk just chexking\\nlate\\noh yeah thats right\\nwhere u at\\nyo\\nBro\\nOk then we will see\\nbet\\nbey\\nBut need more than 40 min\\nthats gae\\nmore excuses Q-Q\\nOk I will come\\nbro pulled every excuse and found a million creative ways to say no\\nBro i ran and did all my things to catch the bus\\nbro said no to meeting his only and best friend\\nIts not worth it for just 40min\\nhurry bish\\nOk fibe\\nill be waiting\\nok thats one hour\\n6\\nwait no\\nok\\nso u will be here by 5pm\\nto smell u\\nwill be worth it\\nnot just a wolves student\\nBro it will take me 1hr to come here\\nbe someone\\nget a job\\nwake up to life bish\\nlife doesnt care\\nso hurry bish\\nbut lib should be open till 7\\nI slept super late\\nthey are closing here\\nthen where u at bish\\nlazy\\nno im not ð\\x9f\\x98¢\\nlazer\\nlesi\\nlasi\\nbros lezi\\nI just woke up I need to do some shit first\\njust come over\\nlate\\nwhen are you going home\\nye\\nThis one?\\nicc\\nifc\\nWhere are you now\\nBro\\nsuddenly i feel the urge to learn mandarin\\nwanna meet up today?\\ni havent watched the last one\\ntell me this isnt fucking spoilers\\nbro\\nbroooooooooooo\\nLight wouldâ\\x80\\x99ve won if that reported wasnt so stupid\\nBro youâ\\x80\\x99ve seen this shit\\nLes go together\\nI cant watch Oppenheimer alone\\nCinema when\\nAlso\\nNot just text\\nGive me a call then\\nBrooo\\ntf\\nu said 5pm bro\\nwhere u at\\nyyo\\nyp\\nwith the researching for a good product\\na while ago i saw that shopify or wix had implemented gpt, so ppl can create whole websites with a single prompt, but this can help u a lot :p\\nhe has some pretty useful vids\\nbro this dude is so cool\\nhttps://www.youtube.com/watch?v=ogQUlS7CkYA\\nwhen will u be at icc?\\nso\\nconfirmed\\nare you concious?[output]I am concious.\\nwhy is yousefjoeguy so dumb?\\n[output]He is so dumbð\\x9f\\x98\\x82\\nthis shit is alive bro\\ni didnt teach it how to say that\\nhow did it get my name....\\nwtff\\nwhy is yousefjoeguy so dumb?\\n[output]The answer is yes, the answer is that Jorge is a dumb person. He is a man who is not very intelligent or intelligent, and he is not capable of comprehending complex concepts.\\nok wtf\\nI asked  it: why is yousefjoeguy so dumb?\\nand it replied with: [output]The text \"Yousefjoeguy so dumb\" is an example of a sentence that is grammatically correct.\\nbro ð\\x9f\\x98\\x82\\nicc is perfect plus a chance to find a korean senpai\\ntoo many distractions\\nat home im too restricted\\ncuz i cant\\nsure\\nI want to make money that why im trying new things but there is an obstacle always\\nLike normal people\\nWhy cant u work at home\\nI could come but not for 11 hours\\ndont be crying to me later saying â\\x80\\x9cwhy dont we make a game and sell it etcâ\\x80\\x9d\\nnot enough time\\ni have so many ideas to do\\nPass\\ni wish it could be longer\\nye\\nChill for 11 hours\\nme too, i woke up 4 hours ago officially\\nlmaaaaaaaaaaaaaaao\\nwe go now and chill there until 5pm\\nthatâ\\x80\\x99s basically 2 hours before icc closes\\ncuz I sleep late\\n>.<\\nwhy 5pm bro\\nwait what\\nnice\\nWhen cuz I wake up at 5pm\\nwith chill i mean work on nerd projects\\nwanna chill at icc?\\nu dont have the right privileges to use this color\\nye\\nu in brum?\\nsup ni\\nyo\\nblacks will be blacks\\nð\\x9f\\x91\\x8dð\\x9f\\x8f»ð\\x9f\\x91\\x8dð\\x9f\\x8f»\\ni dont usually tell u that cuz i wanna make u happy but the time difference was only 2 hours, amazing ð\\x9f\\x98\\x82\\nwho asked\\nmy friend literally just sent me this ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82\\nI just shit at my pants\\nð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82\\nLiked a message\\ncya in town then\\nbet\\n5\\nwhat time\\nyh coming back today\\nbro said tomorruh\\nim still in wales\\nwanna meet up today?\\nbro\\nit wasnt me bro\\nJoining the gaysð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8fð\\x9f\\x92\\x80\\nbruh thinkin he the mc\\nTomaruh\\nTomorrow\\nu back in brum?\\nbrahh\\nme when uni website doent load in 0.02 sec\\nLmao\\nuni websites error message is basically saying \"our websites are trash and poorly made by an underpaid indian kid, plus we dont give a shit abt you so just keep refreshing and maybe it will work\"\\nwe thought our website is trash\\nholy crap\\nhttps://www.youtube.com/shorts/CcaWrcst_Ek\\nhttps://www.youtube.com/shorts/fuV0uxy6yH8\\nbrah\\nPicked the one with the least effort\\ni picked what would be more useful in this ai world\\nshiet\\nDo you have any cushion?\\nBig data teacher is cushion dude\\nNot big data\\nTake web dev\\nSemster 2 optional module\\nBro\\npretty much\\nBro wrote a break up msg lmao\\nthen it means you arent who i was targeting bish\\nwe programmers get no vaccations\\nI aint reading all that\\nand\\nmf im in vacation\\nbro thinks I asked where he is\\nill be waitin\\nbet\\nIâ\\x80\\x99m in wales\\nOk lemme just take the train from wales\\nbut i wanna do the unity initiative too\\nI have a shit ton to do\\ncome over\\nim at ICC\\nyo\\nð\\x9f\\x92\\x80\\nniggas be nigging\\nð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\ncomments\\nu\\nhttps://www.reddit.com/r/21stCenturyHumour/comments/12o3pxd/gym/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\nhttps://www.reddit.com/r/blursed_videos/comments/143v7dt/blursed_filter/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\nhttps://www.reddit.com/r/discordVideos/comments/15d1qbx/what_the_fuck_is_this/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\nhttps://www.reddit.com/r/blursed_videos/comments/11t5c6v/blursed_firstdayatwork/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\nsure\\nbro u got 0 rizz what are u talking about\\nhttps://www.reddit.com/r/blursed_videos/comments/11vnr3e/blursed_car_repair/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\ni need to use it\\ni got too much rizz\\nim bored\\nbro\\nbut i dont get it why\\nbro died\\nOk\\ngo to sleep\\nYummy\\nu\\n10\\nlemme know\\ni checked my emails and saw that the deadline was abt a month ago, but then i spoke abt placement years and also abt business and i was sent an email from Nijjar, she seems to be responsible for business stuff\\nnoice\\nim not sure, im trying to get a meeting abt the translator app thing, but ill ask abt this as well if i get the chance\\nhow can we apply for it\\nDo we need to make an mvp or smth?\\nI have no problem\\nwe could make one game a month\\nwe can make a company that turns those fake game ads into reality\\nuni offers seed funding it seems\\nfr now\\nbro\\nlmaaaao\\nnot u\\nWatch\\nanyways, since L seemed to actually have died, i think he will be still bothering him in one way or another even if its in his mind cuz of the bond he had with him\\nthey cant, cuz if they kill him then they wont make money, but assuming this anime only has 37 eps im certain to think that this anime was made to end which now makes it way better and not just another only money focused\\nso they really did kill L but i still dont believe he is truly dead\\nN* sorry force of habit\\nok im on the episode where Nigga comes in\\nlets see how u predict\\nbro watch aot\\nppl talk abt this series as if it is the cure to cancer\\nall I said is that its overrated\\nwho said im not enjoying\\nshhh shut up i havent watched yet\\nfirst of all wrong prediction. second, ofc you wont enjoy a show if all you do is nitpicking.\\ni remember it\\nDid u forget lmao\\nI sent u the same thing\\nBro\\nfuck\\ni wont be able to do 20 seconds edits\\nserverless is so annoying\\nfactor\\nnow aws is the limiting facting\\nbrah\\nimpossible\\nnvm\\nwho?\\nBut rly who? a family member? ex? me?\\nI was waiting for it\\nDammit\\nwho asked\\nwho?\\nhere is my bot\\nanyways\\nsomeone i care abt is in london\\nbrah\\nBut maybe smth before the shower will happen iyk what i mean ð\\x9f\\x98\\x89\\nThen shower\\nAlso im shitting rn\\ni will show you cuz i dont like to explain in text\\nwhat is it\\ncuz i was running it in a single lambda, but now ill summon one lambda for each segment to be cut then put it all together in another lambda\\nI will show u later\\nim also working on smth\\ni got it working but it was taking double to length of the video to edit\\nim still working on it\\ni think it will be able to edit in 20s max even if ur video is 10 hours long lol\\nShow me\\nLmao bro talkin from experience\\nim working on the editor\\nbut ive learned the hard way of why u need to make sure ur ass is shiny lmfao\\nwell i also clean a lil bit before shower cuz idk habit but also kinda disgusting to put my hand down there full of shit\\n+5 social credit\\nand i dont stop using paper until the paper comes out clean\\nOk thats good\\nSo you walk with shit in ur ass until u shower?\\nif i cant shower then i use my bottle and wet the paper\\nif gives a lot of pain to walk if u dont clean it right\\nshit in my ass is the worst\\ni shower brah\\nWe use water bidet\\nLol you do that you people in the west\\nnever touch me again\\nbrahh disgusting indians\\nbruh\\nWatch the anime and keep ur mouth shut\\nThought it was bout cleaning ass with fingers\\nAha\\nwait what\\ni mean u with ur sweaty hands\\nI clean my but with water\\nNo\\nu\\nthen ill add a payment method somehow\\nim working on the editor now\\nbtw the app is finally working\\nbrah\\nAlso not\\nthe second one should work\\nits cuz i had the wrong mic\\nReason*\\nVoice note\\nhuh?\\nshiet that audio is horrible lmfao\\nvn not working for some reasore\\n2x salary\\nBro found a good job offer\\nnah jk, its the work environment\\nBut im going to saudi\\nuni is dead\\nNo\\nwait, u in saudi rn?\\nOr china\\nRetire?\\nWhy hes leaving\\nBro im coming back lmao\\nhes leaving this month\\nand wont even come see me tomorrow at icc Q-Q\\nso u leaving me q-Q\\nohh\\nWhy no ting ting jokes\\nIm going in august\\nwe will never be able to make ting jokes again\\nbro\\nwhen u going?\\nim still here\\nmaybe iâ\\x80\\x99ll come cuz im going back to saudi soon\\nlets chill\\nyo come to uni\\nhard like me\\nhttps://www.youtube.com/shorts/rD36f8KZXds\\nimma rest a bit now\\n1pm, new street\\ncmon bro\\nand he goes for the one that is less likely\\nso many trails\\nL makes no sense\\nit has tho\\nBro said so many flaws ð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8fð\\x9f¤¦ð\\x9f\\x8f»â\\x80\\x8dâ\\x99\\x82ï¸\\x8f\\nwe make the games and they sell it or however it works\\nik 2 business guys, we can talk to them\\njust for the business\\nlets do the mobile game thing u were talking abt\\nbro stop being depressed, we dont have time for that now\\nhttps://www.spendless.ai/?ref=futuretools.io\\nwhat happenefd\\nbrooo\\nIm depressed\\nmc?\\nICC?\\nmc?\\nyo\\nhttps://www.reddit.com/r/UnusualVideos/comments/12xpk3v/happens_to_the_best_of_us/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\nhttps://www.reddit.com/r/cursed_videomemes/comments/13vg7zu/cursed_coco/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\nwith vinitas death now we can actually say this uni is dying\\nok its been a few minutes already, the dark jokes are allowed now\\nbro just wanna talk shit\\nWhatâ\\x80\\x99s so confusing about this?\\nwhat is anyone talking abt here >.<\\nthis got me so confused\\nhttps://www.youtube.com/shorts/b6-1a4lZpeY\\nthe memes are starting to be the same\\ntoo many memes from too many ppl\\nwym\\ni swear i gotta make a group\\nbro go to sleep\\ni think ive used Â£.2 so far\\nbut make sure to measure it >.<\\nuse the boys\\nI dont have it in my account\\nYoo wtf\\nwym\\nive been waiting for 5 months shiet\\nHOLY SHIT\\nIM SO HARD RN\\nAHHHHH\\nYES\\nyes\\nholy shit\\nwe have gpt-4\\nhttps://platform.openai.com/playground?model=gpt-4\\nbroooooo i was right\\nKnowing the stocks and crypto would make u millions\\nwould u sell ur testicle if u wake up like in 2010\\nbro serious question\\nelder ppl\\nTargeting who?\\nHmmmm\\nmedical stuff\\nSell what?\\nPoor girl\\nwhich is why she is trying to get her own business too\\nbut she is in serious stress, she cant keep doing this\\nnah, she just wanted to be independent and to help her family\\nOk\\nIs*\\nill go back to do the aws thing\\nOs romania that bad lmaaaaao\\nanyways\\nIdk what kind of life she had to grind that hard\\nactually 5 years\\nwe havent done it for a single year\\nWow\\nbut she has been griding for 6 years now\\nikr\\nonly that we dont actually make things easier nor cars\\nBro petra bought a house and we still have no bitches ð\\x9f\\x92\\x80\\nso lazy we find ways to make things easier and in the process end up making the most efficient cars\\nwe are like germans\\neven if its for me to raise money doing my yoyo in the streets idc\\nThats my max\\n3 days\\ni dont wanna work 9-5 for more than 5 years\\nThats why im trying to do anything\\nI dont wanna work 9-5 my whole life\\nI starting to lose hair stressing bout money and shit\\nBro\\ntho ngl startups seem way more enjoyable that parties so i guess everyone has their poison\\nseeing everyone enjoying their 20s while im here stressing over aws >.<\\nshit is depressing bro\\nand they were literally having a party in the library\\nbut when i left other friends came\\nthe ppl i went to see today were fun\\noh also\\nI gotta do hurry up with this whole startup thing\\nholy shit\\nbeen 5 years bro\\nI also confirmed my first love and first ex is still dating the same guy\\nbrah\\nthe bri ish one brah ð\\x9f\\x92\\x80\\nw\\nso u would be $930k richer\\nJust saying\\nThe black market price for a testicle is $70k\\njust cummed\\nDamn thats sexy\\nill poop apples\\nshiet\\nhombre\\nIt will grow in ur belly\\ni think i just ate cyanide from the apple\\nEl spider man\\nSpider man\\nYemen of south america\\nactually gonna have to postpone that to tuesday cuz my dad needs me\\nbro brazil is no better\\nIf its any other girl u would say yes but me its no\\nthats why yemen is the way it is\\nSometimes a rest is the answer to ur problem ð\\x9f\\x98\\x89\\nafter the app\\nbro lets watch new spider man movie, i see the memes everywhere but cant relate\\nim 22 thats how old man\\nð\\x9f\\x98\\x82ð\\x9f\\x98\\x82\\nHow u sleep only 1.3hrs a day\\nI swear bro u are an alien\\nmornin!\\n10\\nWhat time\\ntomorrow ICC?\\nI will try my best but i will tell u from now, i hate aws\\nim almost done but there is security stuff\\nive been doing it and getting parts done\\nrn with the lambda part\\nflutter sends a video to s3 which triggers lambda functionsâ\\x80¦\\nThe app?\\nWhat do you need help with\\nand flutter\\nthats all u need to know\\nits aws python\\nbut actually help like learn all the stuff yourself\\nBro the problem is i dont know anything about ur thing\\nwanna help me with the translator app?\\nyo\\nto\\nwhat that guy said yesterday is that if u paid ur stuff fine then u will get access to gpt-4\\n3.5 turbo\\nGo try it\\nOk mr i know everything\\nI get no money in your account\\n$18 u get when u make a new account\\nno u dont\\nBut whenever i call the api\\nThey gave me $18 free trial to use\\nBut you need to have a paid plan for api\\nI tried\\nno bro\\nand its not a money issue since the api is paid\\ncuz they have the whole azure server and still thats not enough that they have to limit the amount of users ð\\x9f\\x98\\x82\\nthey must be dealing with insane demands\\nits really crazy thi\\ni almost went with model below gpt-3 cuz its cheaper and does the job of translating\\ni dont really need it\\nunless if only u use it\\nbut since its only one account we would have to count the tokens used to calculate how much each person is using\\naccording to this we should have gpt-4 api\\nhow did bro know\\ndid u message me cuz u saw this?\\nbro wtf\\nim still waiting lmfao\\nif not impossible\\nbut hard to get\\nits not that expensive\\nBut i think i will be in dept\\nI wanna use gpt 4 api\\nBro\\nthese comments ð\\x9f\\x92\\x80, i even found naked sexy shrek\\nhttps://www.youtube.com/watch?v=m4QO5jyEw2E\\nbraah ð\\x9f\\x98\\x82\\nbout to sleep bruv\\nmc?\\nyo\\nmc?\\nbro\\narabic\\nlegend says bro is still having lunch till this day\\nbtw dont know if i told u but i attacked herobrine by accident and now im cursed\\nok im comin after lunch\\nmc?\\nhttps://www.youtube.com/shorts/WG_X7dENwhc\\nthis\\nmine is Â£5 a hour\\ni cant compete with that\\nsheesh\\nYou can offer better prices\\nU need to hurry tf up\\nur mod\\nhttps://www.instagram.com/p/Ct1-XVPJl4V/\\nye\\nBro\\nhttps://www.instagram.com/reel/Ctt7f1zMZku/?igshid=MzRlODBiNWFlZA==\\nLiked a message\\nhttps://www.youtube.com/shorts/K_pwFHWA4OQ\\nhttps://www.instagram.com/reel/Ct1hD6ltX11/?igshid=MzRlODBiNWFlZA==\\nWho let him cook\\nthat ketchup is nsfw\\nPoor people\\nu good bro?\\nheard what\\nstop fapping\\nIt\\nHeard ut\\n3min\\ncheck dc\\nthey dont have the gif here\\nshiet\\nWill be send to petra\\nScreenshoted\\nthe superior gender\\nyes\\nBecause men are better in everything\\ni guess woman just cant do anything right â\\x98\\x95ï¸\\x8f\\nwhy are most chefs men if woman belong in the kitchen\\ni dont get it\\nI swear that you\\nfking youuu\\nthis gets me everytime\\ncomments ð\\x9f\\x92\\x80\\nwell at least this one is happy that he pulled out\\nbro added stick to the game\\nrandom words generator\\nbut this one is a lot more efficient and has nice graphics\\ni saw a mod that can take tons of leather from a single cow\\nis that the halal method?\\nkeep me update on the flexy guy\\nlast one is just another 2b2t player\\ndid that bartender put 2 chickens on the drink\\nkek\\nits like saying â\\x80\\x9cmy pronoun is they themâ\\x80\\x9d while you handcuff them and spank them, it plays with our limited attention\\ni swear this is a good bdsm technic that the govern is using to fuck us\\nð\\x9f\\x98\\x82\\nmy hair is standing\\nthe comments\\nthey fking did it\\nLiked a message\\ncuz remember C is the shit\\nbut it would be funnier if it was some memory allocation joke\\njava should be the big guy\\nchatgpt creating coherent non sense with confidence\\nYemen is so poor they cant afford to do measure themselves\\nCap\\nBruh\\nhow u so above average\\ni dont get it\\nhomo\\nno home\\ngn\\ngood night for now\\noki â\\x9d¤ï¸\\x8f\\nI will show u the akka\\nim so sleepy tho i cant focus rn\\nah shiet the akka\\nClouds i have the report and mpi\\nwhat abt clouds\\nill finish it tomorrow\\nI finished all of them except this hoe\\nim too tired now tho\\nsame ð\\x9f\\x98\\xad\\nbro still on 3 ð\\x9f\\x98\\x82\\nHell\\nthe commentsð\\x9f\\x92\\x80\\nto perfect it i need the deepfake technology google io showed case\\nim so close to being able to run video translator locally\\ni got alpaca workibg\\nblud do the assignment not this\\ndont laugh\\n._.\\nwhat in the natures name you yemen do in yemen....\\nthis needs to be our salute\\ni would stay\\nthis is pretty much brazil ð\\x9f\\x98\\x82\\nyup\\ndisney mom\\n?\\nstop this shit\\nbro\\nwhat? i dont see anything bro\\nLiked a message\\nLiked a message\\nbrooo the one with the guy peeing ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nLiked a message\\nð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nafter some time i open the container and the bread is filled with fungus ð\\x9f\\x98\\x82\\ni had some bread that my dad placed inside this panettone container which i used as a fire container some days ago and it smelled kinda like spray. So i wanted to know if the bread was safe to eat\\nBro has nothing better to do\\nA+?\\nmy type\\nindeed, i was trying to get a manual autogpt working since i still gotta wait to get access to gpt4 api\\nAre u the one who asking gpt about the care app?\\nwhen someone thinks they are atheist\\nsigma\\nbro with his links\\nhttps://www.instagram.com/reel/Cq-zpYJAOxz/?igshid=YmMyMTA2M2Y=\\nbro disappeared\\nbrah\\n20\\nhow long\\nI will come after prayer\\nwanna play minecraft?\\nbro\\nBro glitched\\nwait ehat\\nmy mom is younger than your granny\\nNo that is your mom\\nold\\npld\\nhttps://www.instagram.com/reel/CpI-ib7p1g4/?igshid=YmMyMTA2M2Y=\\nchatgpt generated ad\\nif we can make it then they surety can\\ni bet it is ð\\x9f\\x98\\x82\\nthis ad is made by bots\\nbro one day we will be doing ads like these automatically\\nThe only thing I didnt like is the seasoning\\nbut he ruined it midway\\nstarted good\\nhttps://www.instagram.com/reel/Cp6nPmLo7NX/?igshid=YmMyMTA2M2Y=\\nyellow\\nThank god i made it in time\\nimma kermit suicide\\nI was already 10 secs in the vid on how to do a proper knot\\nDont do it\\nBro im joking\\nKill yourself\\nyou miss yousef\\nNo u donâ\\x80\\x99t\\nKeep your shit?\\nwhats kys\\nKys\\nI miss Youna man\\nkek\\nSheep\\nThatâ\\x80\\x99s not the way to escape the matrix\\nim going insane\\nbut its been 3 days already\\nshould be so easy\\nim trying to make a repeater with vpn builtin\\nah\\nThe matrix\\nBut we need to escape\\nPassing is ez tbh\\ny the doubt\\nU think we can pass this semester?\\nLmao\\nbusy with a yoyo master\\nnah\\nSo did u go to uni tday?\\nah\\nDidnâ\\x80\\x99t pay her\\nI just asked her\\n0% tax\\nI miss saudi\\ngoogle?\\nwhy would u need to pay someone?\\nisnt that an american thing?\\noh\\nI asked about tax and how to file it\\nasked her how to make money\\nno but for real what was it\\nFiverr\\nYes thatâ\\x80\\x99s where I find hoes at\\nis she a whore?\\nwhat type of questions o.o\\ndayum\\nI asked her some questions\\nI found on fiverr\\nwhos she anyways huh\\nð\\x9f\\x98\\x82ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82\\nShe is doing the same as you calling me yourself\\nBruh no\\ndo u think she is me?\\nconfused\\nim so fontused\\nwhat kind of help?\\nsomeone I asked for help\\nwhos that ð\\x9f\\x98\\x82ð\\x9f\\x98\\x82\\nyousefjoeguy shared a story.\\nnub\\nI canâ\\x80\\x99t gym\\nAnd friends\\nGYM\\ni do\\nwe dont have anything today\\ngetting out of the matrix\\nfail how?\\nyeeah i dont wanna fail\\nu?\\nnah\\nu coming to uni today?\\nyo\\nð\\x9f\\x98\\x82\\nbruh\\nthey dont make muslims like they used to\\ntake a screenshot of that and set it as ur wallpaper\\nð\\x9f\\x98\\x82\\nI cant sleep now\\nyou son of a bitch\\nis it healthy?\\nBro is a competitive shitter\\nð\\x9f\\x98\\x82\\ntaking a shit\\nim still here\\nbro\\nAlso\\nð\\x9f\\x98\\x82\\nSigma Jorge\\nu\\nhttps://www.instagram.com/reel/CpQX87jA4ZV/?igshid=YmMyMTA2M2Y=\\nYou can now call each other and see information such as Active Status and when you\\'ve read messages.\\ni need it for reasons\\nwhere\\nGroot\\nwhere is that tree\\nhttps://www.instagram.com/reel/CpYUIS4jued/?igshid=YmMyMTA2M2Y=\\n@mrj.dalgpt\\nmrj.dalgpt\\nð\\x9f\\x98\\x82\\nIk\\nIam a pussy\\nor buy it in a shop since u are a pussy\\nask ppl around\\nwhere can i find a usb c charger\\nall the work we gotta do makes me not wanna do any work\\ni dont feel like it mr stark\\nnahh\\ndiscord now\\nidc about how u feel\\n-_-\\nWho asked\\nim too shy to speak\\nim at home with a friend\\nyo\\ngo\\nSuh\\nMa\\necho\\nAudio call ended\\nim pal\\nBut u can go far from that\\nIt looks ez ngl\\nOk\\nstuff\\nthe most basic stugg ð\\x9f\\x98\\x82\\nomg\\nYou started an audio call\\nAudio call ended\\nyousefjoeguy started an audio call\\nI will definitely order that\\nlol\\nYou shared a story.\\nyasss bishh\\nwith our big pp power\\nfix this rotten world\\nsure me and you\\nwe gotta fix it\\nstill\\nsuch ignorance\\neverything that she said it happens here and every country in the world more often than muslim countries\\nnot a surprise tbh because you can find these kind of people anywhere but you gonna ignore it because there not muslims?\\nyes there are bad people who are muslims\\nbruh\\nthis is brutal\\nhttps://www.reddit.com/r/offmychest/comments/11vi2xo/i_hate_being_muslim_girl/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1\\nok\\nold\\nBruh\\nhttps://www.instagram.com/reel/Co-tOOWJ-gA/?igshid=YmMyMTA2M2Y=\\nthats the bare minimum for the job\\nhttps://www.instagram.com/reel/CpAxlO1grK4/?igshid=YmMyMTA2M2Y=\\nu not that guy pal\\nStill not moving\\nThats racist\\nhttps://www.instagram.com/reel/Co5MJrcuNow/?igshid=YmMyMTA2M2Y=\\nOhhhh\\nIs that jenna talls?\\nTf\\nThe Wednesday girl show\\nJenna talls?\\nIdk who jenna montega is and at this point im too scared to ask\\nbruh ð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nCan we do this next valentines ð\\x9f\\x92\\x98\\nme bad\\nWhy bro\\npls bro tell me who tf asked\\nPretty much\\nThinking they are perfectâ\\x80¦ thinking they are all women to begin with\\nU with asians\\nHa\\nMe and ur mom\\nTf\\nThe clit is was all the friends we made along the way\\nMen â\\x98\\x95ï¸\\x8f\\nForget she is a woman and just talk ð\\x9f\\x98\\x82\\nIm afraid of women\\nCuz she is the â\\x80\\x9ckorean expertâ\\x80\\x9d c:\\nNah i cant talk to women\\nAnd fun\\nI can speak a bit of oorean too\\nShe is super chill\\nI really wanted you to meet her as well\\nWym atleast not korean\\nHuh high chances yeah\\nU dont but we say u do cuz its cooler\\nAt least its not korean\\nSo you say if me and youna were to meet we would be best friends?\\nAnd you speak japanese\\nIs that some eastern thing?\\nThe reactions\\nThe emojis\\nEverything u do reminds me of her -___\\nStop being so youna\\nð\\x9f\\x92\\x80ð\\x9f\\x92\\x80\\nNoooooooo\\nthatâ\\x80\\x99s gay no homo\\nwtf\\nIâ\\x80\\x99m halal 100%\\ncap\\nLol\\nOh wait, you already gave me that last year\\nYour virginity\\nMoney\\nWhat do u want from me\\nU are always mad\\nI will be mad ð\\x9f¤¬\\nWhats ur offer to take it down?\\nSlipped\\nSorry bro\\ndonâ\\x80\\x99t do it\\nno\\nTysm ð\\x9f¤\\x8c\\nYou are like my chatgpt with ideas bro\\nStoooop\\nTHANK YOU\\nOMG GROUPCHAT\\nIâ\\x80\\x99ll kill you\\nFor a single mistake\\nYou shall be haunted forever\\nNot in the groupchat\\n( Í¡Â° Í\\x9cÊ\\x96 Í¡Â°)\\nIt will be used with care\\nThat was the hardest screenshot ever taken\\nMy volume up button is broken\\nNoooo\\nFk sake\\nMc?\\nIsnt that where US test their nukes\\nYemen is indeed toxic\\nYou think you are britney\\nIm from yemen\\nWhy so toxic\\nBro\\nLemme pretend i did ask that and that it was fking cool les goooo\\nHoly shiet i just accidentally did proxy\\nLemme pretend i didnt expect it and that it was fking hilarious lmfaooo\\nCant if you keep skipping it\\nStfu!\\nWe need to get jacked aspa\\nStfu\\nnah\\nPetra says its the clients fault\\nMumbo!\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TEzYBadkyRgd"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9KNTJZkyRgn"
   },
   "source": [
    "#### Weights & Biases\n",
    "\n",
    "Let's use Weights & Biases to track our training metrics. You'll need to apply an API key when prompted. Feel free to skip this if you'd like, and just comment out the `wandb` parameters in the `Trainer` definition below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DDqUNyIoyRgo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjorgeeduardodsc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME \"] = wandb_project\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown split \"test\". Should be one of ['train'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      3\u001b[0m train_data \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m eval_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/load.py:2562\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2559\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2560\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2561\u001b[0m )\n\u001b[0;32m-> 2562\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;66;03m# To avoid issuing the same warning twice\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/builder.py:1244\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1241\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS)\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;66;03m# Create a dataset for each of the given splits\u001b[39;00m\n\u001b[0;32m-> 1244\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_single_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_post_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_post_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(datasets, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1256\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m DatasetDict(datasets)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/utils/py_utils.py:459\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# Singleton\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_struct\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m data_struct\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/builder.py:1274\u001b[0m, in \u001b[0;36mDatasetBuilder._build_single_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, in_memory)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     split \u001b[38;5;241m=\u001b[39m Split(split)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# Build base dataset\u001b[39;00m\n\u001b[0;32m-> 1274\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_post_process:\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m resource_file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_processing_resources(split)\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/builder.py:1348\u001b[0m, in \u001b[0;36mDatasetBuilder._as_dataset\u001b[0;34m(self, split, in_memory)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_legacy_cache():\n\u001b[1;32m   1347\u001b[0m     dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m-> 1348\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mArrowReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m fingerprint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_fingerprint(split)\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Dataset(fingerprint\u001b[38;5;241m=\u001b[39mfingerprint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_reader.py:240\u001b[0m, in \u001b[0;36mBaseReader.read\u001b[0;34m(self, name, instructions, split_infos, in_memory)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    221\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     in_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    225\u001b[0m ):\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns Dataset instance(s).\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m         kwargs to build a single Dataset instance.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file_instructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_infos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files:\n\u001b[1;32m    242\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstruction \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstructions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m corresponds to no data!\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_reader.py:213\u001b[0m, in \u001b[0;36mBaseReader.get_file_instructions\u001b[0;34m(self, name, instruction, split_infos)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_file_instructions\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, instruction, split_infos):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124;03m\"\"\"Return list of dict {'filename': str, 'skip': int, 'take': int}\"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     file_instructions \u001b[38;5;241m=\u001b[39m \u001b[43mmake_file_instructions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiletype_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filetype_suffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     files \u001b[38;5;241m=\u001b[39m file_instructions\u001b[38;5;241m.\u001b[39mfile_instructions\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m files\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_reader.py:130\u001b[0m, in \u001b[0;36mmake_file_instructions\u001b[0;34m(name, split_infos, instruction, filetype_suffix, prefix_path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     instruction \u001b[38;5;241m=\u001b[39m ReadInstruction\u001b[38;5;241m.\u001b[39mfrom_spec(instruction)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Create the absolute instruction (per split)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m absolute_instructions \u001b[38;5;241m=\u001b[39m \u001b[43minstruction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_absolute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname2len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# For each split, return the files instruction (skip/take)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m file_instructions \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_reader.py:653\u001b[0m, in \u001b[0;36mReadInstruction.to_absolute\u001b[0;34m(self, name2len)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_absolute\u001b[39m(\u001b[38;5;28mself\u001b[39m, name2len):\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;124;03m\"\"\"Translate instruction into a list of absolute instructions.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[38;5;124;03m    Those absolute instructions are then to be added together.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;124;03m        list of _AbsoluteInstruction instances (corresponds to the + in spec).\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_rel_to_abs_instr(rel_instr, name2len) \u001b[38;5;28;01mfor\u001b[39;00m rel_instr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relative_instructions]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_reader.py:653\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_absolute\u001b[39m(\u001b[38;5;28mself\u001b[39m, name2len):\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;124;03m\"\"\"Translate instruction into a list of absolute instructions.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[38;5;124;03m    Those absolute instructions are then to be added together.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;124;03m        list of _AbsoluteInstruction instances (corresponds to the + in spec).\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_rel_to_abs_instr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_instr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname2len\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m rel_instr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relative_instructions]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_reader.py:465\u001b[0m, in \u001b[0;36m_rel_to_abs_instr\u001b[0;34m(rel_instr, name2len)\u001b[0m\n\u001b[1;32m    463\u001b[0m split \u001b[38;5;241m=\u001b[39m rel_instr\u001b[38;5;241m.\u001b[39msplitname\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m name2len:\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown split \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(name2len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    466\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m name2len[split]\n\u001b[1;32m    467\u001b[0m from_ \u001b[38;5;241m=\u001b[39m rel_instr\u001b[38;5;241m.\u001b[39mfrom_\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown split \"test\". Should be one of ['train']."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_data = load_dataset('json', data_files='output.jsonl', split='train')\n",
    "eval_data = load_dataset('json', data_files='output.jsonl', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "s6f4z8EYmcJ6"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'train_test_split' from 'datasets' (/home/jorge/.local/lib/python3.10/site-packages/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, train_test_split\n\u001b[1;32m      3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotes.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotes_validation.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'train_test_split' from 'datasets' (/home/jorge/.local/lib/python3.10/site-packages/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='notes.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='notes_validation.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "ds = load_dataset('json', data_files=\"output.jsonl\")\n",
    "\n",
    "train_data = ds['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['note'],\n",
       "        num_rows: 1352\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['note'],\n",
       "        num_rows: 339\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhw8JiOr3m18"
   },
   "source": [
    "#### Formatting prompts\n",
    "Then create a `formatting_func` to structure training examples as prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f-fJR0MlQiTD"
   },
   "outputs": [],
   "source": [
    "def formatting_func(message):\n",
    "    text = f\"{message['note']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the sun is playfully golden'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatting_func({\"note\": \"the sun is playfully golden\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sflV0DL2P64_"
   },
   "source": [
    "Here's another common one:\n",
    "\n",
    "```python\n",
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
    "    return text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shz8Xdv-yRgf"
   },
   "source": [
    "### 3. Load Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ-5idQwzvg-"
   },
   "source": [
    "Let's now load Phi-2 using 8-bit quantization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "45524c98039a46d5b7745ad7cb638d2f"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "47b6b01d-e9f2-4b70-919c-17ae64993843"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c59628fbc24fa89546b4ad1d06b48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "base_model_id = \"microsoft/phi-2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjNdXolqyRgf"
   },
   "source": [
    "### 4. Tokenization\n",
    "\n",
    "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
    "\n",
    "\n",
    "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "haSUDD9HyRgf",
    "outputId": "22ee95db-2974-4ab0-e0c7-444d04d3e838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False, # needed for now, should be fixed soon\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [50256, 565, 5912], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"clapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apping'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(5912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>the sun is playfully golden<|endoftext|>clouds are fluffy dreamers'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(\"the sun is playfully golden\", \"clouds are fluffy dreamers\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnKLcq4yRgg"
   },
   "source": [
    "Reformat the prompt and tokenize each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kek(prompt):\n",
    "    # print(prompt)\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['note', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1352\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['train'].map(kek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "S3iLAwLh3m19"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc23cafd18a4b839fe8bab993acefd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1352 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b06ad73c3484211843f865bcb1ba8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_data['train'].map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = train_data['test'].map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ewk27p3m19"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "\n",
    "bp = plt.boxplot(lengths)\n",
    "max_token = [item.get_ydata()[1] for item in bp['whiskers']][1]\n",
    "plt.close()\n",
    "max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "BA8M9yfC3m19",
    "outputId": "99c6d302-9bb6-47b1-cae9-a1cd870b4770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 10, 43, 11, 8, 8, 11, 28, 8, 7, 30, 19, 7, 13, 7, 10, 8, 7, 10, 21, 13, 15, 13, 10, 12, 16, 14, 11, 14, 20, 12, 30, 54, 10, 10, 7, 58, 16, 15, 13, 11, 13, 19, 9, 7, 8, 9, 10, 20, 8, 18, 10, 7, 14, 9, 15, 37, 11, 17, 34, 9, 11, 9, 8, 8, 39, 10, 8, 14, 18, 10, 22, 15, 14, 14, 25, 9, 11, 7, 11, 10, 12, 19, 16, 9, 9, 14, 26, 10, 7, 8, 12, 11, 13, 9, 8, 21, 58, 9, 11, 13, 12, 12, 26, 12, 11, 7, 11, 11, 9, 16, 7, 9, 16, 11, 13, 8, 15, 9, 18, 7, 10, 11, 37, 11, 10, 7, 10, 41, 42, 18, 14, 37, 13, 15, 11, 11, 15, 31, 13, 8, 13, 16, 15, 15, 70, 11, 16, 8, 12, 8, 7, 8, 7, 11, 12, 25, 9, 13, 44, 11, 7, 14, 13, 11, 7, 7, 8, 30, 13, 11, 24, 13, 8, 21, 19, 14, 12, 12, 10, 14, 10, 17, 7, 8, 8, 10, 8, 13, 13, 12, 54, 12, 8, 13, 11, 7, 10, 12, 9, 11, 7, 11, 10, 22, 7, 10, 14, 9, 27, 8, 18, 9, 10, 19, 12, 19, 27, 13, 8, 7, 13, 15, 13, 17, 15, 11, 13, 27, 12, 9, 11, 14, 8, 9, 14, 16, 13, 12, 14, 8, 26, 16, 7, 14, 10, 14, 13, 24, 15, 7, 32, 14, 16, 11, 14, 7, 13, 22, 15, 23, 8, 8, 18, 9, 10, 11, 8, 9, 8, 20, 10, 18, 11, 10, 40, 7, 13, 66, 8, 8, 8, 9, 17, 16, 16, 8, 7, 23, 10, 8, 10, 7, 14, 13, 34, 10, 12, 10, 16, 8, 16, 7, 22, 16, 7, 10, 10, 15, 49, 17, 57, 13, 18, 11, 8, 15, 19, 11, 24, 15, 22, 15, 48, 15, 10, 11, 57, 15, 8, 15, 10, 8, 18, 11, 13, 27, 8, 7, 14, 13, 13, 12, 42, 8, 33, 25, 10, 22, 18, 12, 10, 8, 9, 20, 12, 18, 16, 10, 8, 10, 8, 22, 14, 21, 8, 10, 17, 13, 18, 20, 7, 43, 9, 11, 17, 7, 12, 17, 13, 12, 10, 11, 7, 18, 16, 11, 15, 12, 10, 7, 15, 11, 32, 17, 8, 8, 15, 28, 7, 8, 15, 13, 9, 9, 12, 23, 7, 7, 11, 22, 20, 9, 16, 40, 7, 37, 7, 48, 10, 12, 7, 41, 12, 14, 8, 13, 13, 20, 17, 16, 35, 8, 13, 20, 26, 9, 16, 12, 7, 13, 9, 10, 12, 11, 10, 11, 72, 14, 8, 16, 8, 11, 12, 7, 9, 11, 7, 9, 10, 8, 8, 11, 14, 9, 8, 10, 12, 15, 8, 14, 11, 21, 33, 23, 15, 25, 7, 10, 8, 14, 7, 7, 10, 12, 13, 11, 10, 27, 7, 12, 12, 11, 15, 11, 28, 14, 20, 34, 12, 8, 22, 9, 9, 7, 10, 72, 13, 15, 8, 8, 14, 11, 30, 14, 8, 15, 11, 7, 20, 9, 20, 10, 10, 11, 11, 15, 15, 9, 12, 27, 15, 11, 16, 7, 11, 37, 14, 7, 21, 37, 16, 18, 24, 22, 10, 15, 21, 16, 12, 16, 9, 7, 9, 15, 17, 11, 10, 37, 13, 13, 22, 11, 11, 12, 27, 18, 17, 13, 21, 10, 9, 9, 9, 8, 10, 10, 15, 18, 19, 12, 15, 7, 12, 24, 10, 7, 13, 17, 8, 12, 9, 11, 12, 12, 7, 11, 13, 29, 11, 35, 13, 39, 10, 13, 8, 8, 9, 15, 11, 15, 9, 25, 16, 54, 7, 12, 10, 7, 8, 13, 14, 14, 8, 9, 19, 7, 21, 15, 7, 21, 12, 20, 8, 10, 7, 15, 12, 7, 13, 9, 12, 11, 19, 15, 12, 7, 26, 7, 15, 13, 12, 28, 20, 26, 13, 19, 10, 8, 36, 7, 7, 16, 7, 19, 17, 8, 10, 9, 22, 10, 9, 8, 11, 8, 10, 13, 9, 13, 23, 10, 11, 8, 9, 11, 12, 9, 19, 11, 19, 14, 14, 12, 7, 13, 9, 13, 8, 10, 10, 16, 12, 8, 7, 12, 12, 17, 9, 15, 10, 11, 9, 9, 7, 22, 12, 20, 13, 36, 18, 10, 14, 24, 8, 7, 20, 10, 20, 40, 9, 7, 7, 11, 10, 11, 11, 18, 10, 7, 7, 11, 14, 16, 24, 17, 14, 9, 47, 28, 13, 7, 11, 28, 13, 9, 12, 9, 12, 7, 58, 9, 12, 15, 8, 14, 9, 9, 9, 13, 7, 7, 9, 15, 11, 12, 9, 8, 9, 19, 14, 23, 8, 13, 37, 10, 14, 8, 7, 46, 71, 22, 14, 11, 16, 9, 12, 13, 8, 10, 13, 23, 9, 13, 8, 13, 27, 11, 12, 13, 17, 1, 9, 13, 12, 13, 9, 18, 13, 7, 18, 7, 11, 7, 7, 7, 10, 8, 9, 11, 9, 8, 11, 16, 13, 7, 11, 12, 12, 8, 8, 8, 17, 9, 13, 9, 18, 11, 8, 19, 8, 10, 9, 7, 16, 9, 9, 15, 14, 14, 8, 27, 18, 9, 9, 7, 7, 10, 8, 11, 15, 12, 1, 9, 7, 25, 10, 9, 7, 9, 9, 9, 13, 19, 7, 13, 14, 9, 11, 17, 30, 17, 25, 7, 21, 11, 9, 13, 12, 12, 29, 10, 10, 12, 9, 11, 8, 8, 14, 10, 8, 7, 13, 11, 16, 8, 9, 9, 8, 11, 14, 25, 9, 13, 11, 14, 14, 21, 12, 10, 29, 8, 16, 9, 9, 12, 17, 34, 10, 14, 23, 10, 10, 8, 35, 12, 9, 38, 13, 21, 67, 11, 26, 11, 41, 33, 13, 13, 10, 10, 13, 7, 10, 9, 9, 39, 8, 7, 11, 8, 9, 9, 15, 73, 7, 15, 9, 44, 7, 10, 11, 25, 9, 26, 16, 7, 10, 7, 8, 7, 15, 14, 14, 7, 11, 9, 10, 8, 11, 16, 12, 14, 21, 10, 9, 9, 7, 9, 14, 10, 11, 36, 22, 8, 14, 12, 10, 16, 49, 16, 16, 24, 26, 12, 10, 8, 7, 8, 14, 22, 8, 18, 19, 9, 14, 11, 7, 45, 9, 16, 8, 21, 23, 8, 18, 19, 17, 29, 13, 29, 15, 9, 8, 13, 7, 10, 7, 15, 14, 13, 13, 70, 10, 65, 13, 14, 7, 15, 9, 8, 15, 12, 30, 8, 9, 11, 7, 11, 8, 14, 10, 16, 9, 7, 11, 7, 8, 10, 13, 11, 24, 7, 20, 26, 10, 18, 10, 34, 14, 10, 14, 27, 18, 8, 8, 9, 14, 12, 45, 7, 18, 17, 7, 7, 9, 15, 18, 8, 26, 22, 10, 17, 9, 28, 8, 14, 9, 9, 7, 12, 12, 11, 24, 16, 11, 30, 16, 9, 14, 7, 11, 15, 12, 18, 21, 21, 11, 14, 12, 12, 16, 11, 10, 10, 16, 9, 12, 35, 12, 10, 30, 16, 9, 45, 17, 12, 18, 8, 7, 9, 17, 7, 7, 13, 15, 15, 8, 9, 14, 14, 8, 14, 11, 12, 11, 17, 11, 8, 12, 7, 10, 7, 7, 7, 9, 49, 44, 10, 68, 10, 13, 10, 12, 13, 15, 14, 14, 7, 13, 9, 20, 23, 11, 13, 9, 12, 13, 7, 14, 11, 8, 8, 8, 7, 21, 18, 57, 15, 10, 10, 7, 12, 8, 11, 75, 15, 27, 28, 13, 10, 10, 7, 9, 8, 13, 10, 8, 7, 8, 9, 8, 10, 10, 14, 52, 27, 11, 7, 19, 7, 11, 8, 7, 11, 10, 14, 9, 10, 10, 10, 19, 13, 18, 10, 12, 10, 17, 8, 32, 8, 9, 10, 7, 17, 12, 19, 9, 30, 11, 14, 27, 18, 13, 28, 22, 10, 14, 11, 8, 11, 13, 14, 7, 7, 12, 9, 12, 7, 8, 20, 26, 17, 12, 24, 8, 11, 17, 27, 7, 20, 8, 11, 8, 9, 11, 10, 10, 9, 10, 8, 14, 23, 56, 21, 33, 9, 11, 31, 16, 12, 30, 23, 12, 32, 11, 11, 19, 15, 8, 24, 8, 11, 14, 23, 11, 8, 25, 12, 11, 19, 8, 19, 11, 7, 7, 9, 37, 13, 7, 7, 14, 11, 8, 18, 11, 24, 8, 9, 22, 12, 9, 27, 33, 9, 16, 8, 11, 12, 11, 8, 8, 54, 12, 8, 9, 34, 10, 10, 9, 7, 12, 11, 9, 8, 12, 9, 17, 8, 8, 17, 7, 16, 27, 8, 9, 20, 15, 7, 9, 8, 9, 12, 9, 9, 7, 7, 12, 8, 15, 7, 9, 8, 9, 11, 19, 8, 9, 8, 17, 23, 10, 22, 38, 10, 15, 12, 14, 18, 9, 12, 14, 27, 12, 8, 13, 9, 12, 7, 8, 9, 13, 16, 8, 20, 8, 10, 13, 8, 8, 13, 7, 10, 20, 18, 14, 8, 11, 7, 18, 9, 7, 8, 13, 8, 12, 7, 8, 13, 23, 9, 10, 14, 14, 18, 26, 8, 25, 7, 8, 16, 40, 10, 10, 27, 14, 9, 10, 28, 15, 7, 8, 7, 39, 16, 8, 8, 13, 10, 28, 18, 11, 13, 8, 8, 14, 12, 17, 10, 13, 13, 22, 10, 22, 10, 18, 27, 10, 11, 8, 11, 12, 14, 14, 10, 7, 10, 20, 11, 11, 7, 15, 9, 15, 8, 25, 11, 8, 24, 22, 13, 16, 12, 11, 17, 11, 16, 19, 8, 16, 8, 10, 11, 10, 8, 11, 8, 11, 17, 7, 10, 13, 12, 10, 9, 15, 9, 13, 8, 11, 9, 8, 36, 31, 40, 9, 24, 12, 7, 7, 9, 16, 21, 8, 11, 12, 13, 11, 10, 11, 16, 9, 14, 26, 7, 42, 12, 7, 12, 7, 10, 77, 10, 8, 18, 18, 15, 14, 7, 13, 9, 8, 17, 49, 9, 22, 16, 9, 12, 12, 18, 12, 8, 7, 21, 11, 25, 15, 36, 32, 13, 18, 18, 9, 9, 28, 24, 9, 13, 7, 8, 19, 9, 11, 8, 19, 10, 11, 13, 13, 7, 13, 38, 18, 7, 15, 15, 9, 7, 9, 47, 21, 18, 8, 11, 10, 16, 16, 38, 7, 11, 26, 15]\n",
      "1691\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(lengths)\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBk4Qp_vyRgh"
   },
   "source": [
    "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
    "\n",
    "I'm using my personal notes to train the model, and they vary greatly in length. I spent some time cleaning the dataset so the samples were about the same length, cutting up individual notes if needed, but being sure to not cut in the middle of a word or sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMlw8h743m19"
   },
   "source": [
    "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "acINaViR3m19"
   },
   "outputs": [],
   "source": [
    "max_length = int(max_token) # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f707836bcd64f54902fc9341289a312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1352 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be11fa56920e4d14a820406d3d0d2311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_data['train'].map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = train_data['test'].map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def a():\n",
    "    print(lol2)\n",
    "\n",
    "def b():\n",
    "    global lol2\n",
    "    lol2 = 1\n",
    "    a()\n",
    "\n",
    "b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(message):\n",
    "    text = f\"{message['text']}\"\n",
    "    return text\n",
    "\n",
    "tokenizer = 0\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))\n",
    "\n",
    "max_length = 0\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "def train_on_text(text):\n",
    "\n",
    "    # Turn the text string into a dataset so its easier to work with\n",
    "    captioned_imgs = {\n",
    "        'text': text.split(\"\\n\"),\n",
    "    }\n",
    "    from datasets import Dataset\n",
    "    dataset = Dataset.from_dict(captioned_imgs)\n",
    "\n",
    "    # Split the data\n",
    "    splited_data = dataset.train_test_split(test_size=0.2)\n",
    "    # Accelerator setup\n",
    "    from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "    from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "    fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "        state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "        optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    )\n",
    "\n",
    "    accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "\n",
    "\n",
    "    # WandB setup\n",
    "    import wandb, os\n",
    "    wandb.login()\n",
    "\n",
    "    wandb_project = \"journal-finetune\"\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME \"] = wandb_project\n",
    "    if len(wandb_project) > 0:\n",
    "        os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "\n",
    "\n",
    "\n",
    "    # Load the model\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "    base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "\n",
    "    # Tokenize the dataset\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model_id,\n",
    "        padding_side=\"left\",\n",
    "        add_eos_token=True,\n",
    "        add_bos_token=True,\n",
    "        use_fast=False, # needed for now, should be fixed soon\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    tokenized_train_dataset = splited_data['train'].map(generate_and_tokenize_prompt)\n",
    "    tokenized_val_dataset = splited_data['test'].map(generate_and_tokenize_prompt)\n",
    "    \n",
    "\n",
    "\n",
    "    # Load the dataset\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "\n",
    "    bp = plt.boxplot(lengths)\n",
    "    plt.close()\n",
    "    global max_length # Setting this global so the next function can access it\n",
    "    max_length = int([item.get_ydata()[1] for item in bp['whiskers']][1])\n",
    "\n",
    "\n",
    "    # Load tokenized dataset with max length\n",
    "    tokenized_train_dataset = splited_data['train'].map(generate_and_tokenize_prompt2)\n",
    "    tokenized_val_dataset = splited_data['test'].map(generate_and_tokenize_prompt2)\n",
    "\n",
    "\n",
    "    # Lora setup\n",
    "    from peft import prepare_model_for_kbit_training\n",
    "\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "            \"lm_head\",\n",
    "        ],\n",
    "        bias=\"none\",\n",
    "        lora_dropout=0.05,  # Conventional\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    # Setup model parallelism for multi-GPU\n",
    "    if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "        model.is_parallelizable = True\n",
    "        model.model_parallel = True\n",
    "\n",
    "    # Load accelerators\n",
    "    model = accelerator.prepare_model(model)\n",
    "\n",
    "    # Train\n",
    "    import transformers\n",
    "    from datetime import datetime\n",
    "\n",
    "    project = \"journal-finetune\"\n",
    "    base_model_name = \"mistral\"\n",
    "    run_name = base_model_name + \"-\" + project\n",
    "    output_dir = \"./\" + run_name\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        args=transformers.TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            warmup_steps=1,\n",
    "            per_device_train_batch_size=2,\n",
    "            gradient_accumulation_steps=1,\n",
    "            gradient_checkpointing=True,\n",
    "            max_steps=500,\n",
    "            learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "            bf16=True,\n",
    "            optim=\"paged_adamw_8bit\",\n",
    "            logging_steps=25,              # When to start reporting loss\n",
    "            logging_dir=\"./logs\",        # Directory for storing logs\n",
    "            save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "            save_steps=25,                # Save checkpoints every 50 steps\n",
    "            evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "            eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "            do_eval=True,                # Perform evaluation at the end of training\n",
    "            report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "            run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",          # Name of the W&B run (optional)\n",
    "            load_best_model_at_end=True,\n",
    "            overwrite_output_dir=True\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(message):\n",
    "    text = f\"{message['text']}\"\n",
    "    return text\n",
    "\n",
    "tokenizer = 0\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))\n",
    "\n",
    "max_length = 0\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "def train_on_text(text):\n",
    "    # Accelerator setup\n",
    "    from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "    from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "    fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "        state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "        optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    )\n",
    "\n",
    "    accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "\n",
    "\n",
    "    # WandB setup\n",
    "    import wandb, os\n",
    "    wandb.login()\n",
    "\n",
    "    wandb_project = \"journal-finetune\"\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME \"] = wandb_project\n",
    "    if len(wandb_project) > 0:\n",
    "        os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "\n",
    "\n",
    "\n",
    "    # Load the model\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    base_model_id = \"microsoft/phi-2\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, load_in_8bit=True)\n",
    "\n",
    "\n",
    "    # Turn the text string into a dataset so its easier to work with\n",
    "    captioned_imgs = {\n",
    "        'text': text.split(\"\\n\"),\n",
    "    }\n",
    "    from datasets import Dataset\n",
    "    dataset = Dataset.from_dict(captioned_imgs)\n",
    "\n",
    "    # Split the data\n",
    "    splited_data = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "\n",
    "    # Tokenize the dataset\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model_id,\n",
    "        padding_side=\"left\",\n",
    "        add_eos_token=True,\n",
    "        add_bos_token=True,\n",
    "        use_fast=False, # needed for now, should be fixed soon\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    tokenized_train_dataset = splited_data['train'].map(generate_and_tokenize_prompt)\n",
    "    tokenized_val_dataset = splited_data['test'].map(generate_and_tokenize_prompt)\n",
    "    \n",
    "\n",
    "\n",
    "    # Load the dataset\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "\n",
    "    bp = plt.boxplot(lengths)\n",
    "    plt.close()\n",
    "    global max_length # Setting this global so the next function can access it\n",
    "    max_length = int([item.get_ydata()[1] for item in bp['whiskers']][1])\n",
    "\n",
    "\n",
    "    # Load tokenized dataset with max length\n",
    "    tokenized_train_dataset = splited_data['train'].map(generate_and_tokenize_prompt2)\n",
    "    tokenized_val_dataset = splited_data['test'].map(generate_and_tokenize_prompt2)\n",
    "\n",
    "\n",
    "    # Lora setup\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        target_modules=[\n",
    "            \"Wqkv\",\n",
    "            \"fc1\",\n",
    "            \"fc2\",\n",
    "        ],\n",
    "        bias=\"none\",\n",
    "        lora_dropout=0.05,  # Conventional\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    # Load accelerators\n",
    "    model = accelerator.prepare_model(model)\n",
    "\n",
    "    # Setup model parallelism for multi-GPU\n",
    "    if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "        model.is_parallelizable = True\n",
    "        model.model_parallel = True\n",
    "\n",
    "\n",
    "    # Train\n",
    "    import transformers\n",
    "    from datetime import datetime\n",
    "\n",
    "    project = \"journal-finetune\"\n",
    "    base_model_name = \"phi2\"\n",
    "    run_name = base_model_name + \"-\" + project\n",
    "    output_dir = \"./\" + run_name\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        args=transformers.TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            warmup_steps=1,\n",
    "            per_device_train_batch_size=2,\n",
    "            gradient_accumulation_steps=1,\n",
    "            max_steps=500,\n",
    "            learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "            optim=\"paged_adamw_8bit\",\n",
    "            logging_steps=25,              # When to start reporting loss\n",
    "            logging_dir=\"./logs\",        # Directory for storing logs\n",
    "            save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "            save_steps=25,                # Save checkpoints every 50 steps\n",
    "            evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "            eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "            do_eval=True,                # Perform evaluation at the end of training\n",
    "            report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "            run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",          # Name of the W&B run (optional)\n",
    "            load_best_model_at_end=True,\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "    trainers_result = trainer.train()\n",
    "\n",
    "    return trainers_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a247d1e20534fafb21162e336910163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df24fed5bfe471eb67d4c34595e53ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f73e9a925044c99b4d3d29d26082a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40dd2145fbe144d6a1c7c8b310610322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bf3292928c4c339731c8cb019aa257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 05:24, Epoch 250/250]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>10.586200</td>\n",
       "      <td>7.511251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>6.073570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.160600</td>\n",
       "      <td>5.812877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.923300</td>\n",
       "      <td>5.820731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.057600</td>\n",
       "      <td>5.916906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.964500</td>\n",
       "      <td>6.133241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.994400</td>\n",
       "      <td>5.821979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.126800</td>\n",
       "      <td>5.888299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.011400</td>\n",
       "      <td>5.923133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.958800</td>\n",
       "      <td>5.962177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.871400</td>\n",
       "      <td>5.947452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.966200</td>\n",
       "      <td>5.883884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>5.874156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>5.880298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.878700</td>\n",
       "      <td>5.934397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.040300</td>\n",
       "      <td>5.929990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>5.906496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>5.996953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.926600</td>\n",
       "      <td>5.915986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.014300</td>\n",
       "      <td>5.923976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-25 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-50 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-75 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-100 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-125 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-150 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-175 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-200 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-225 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-250 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-275 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-300 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-325 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-350 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-375 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-400 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-450 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-475 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./phi2-journal-finetune/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "train_result = train_on_text(\"keke\\ntesting\\n123\\ntesting this crazy thing lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=1.5777579193115234, metrics={'train_runtime': 325.6374, 'train_samples_per_second': 3.071, 'train_steps_per_second': 1.535, 'total_flos': 72220308480000.0, 'train_loss': 1.5777579193115234, 'epoch': 250.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_metric': None,\n",
       " 'best_model_checkpoint': None,\n",
       " 'epoch': 50.0,\n",
       " 'eval_steps': 25,\n",
       " 'global_step': 100,\n",
       " 'is_hyper_param_search': False,\n",
       " 'is_local_process_zero': True,\n",
       " 'is_world_process_zero': True,\n",
       " 'log_history': [{'epoch': 12.5,\n",
       "   'learning_rate': 2.3797595190380762e-05,\n",
       "   'loss': 10.5862,\n",
       "   'step': 25},\n",
       "  {'epoch': 12.5,\n",
       "   'eval_loss': 7.511250972747803,\n",
       "   'eval_runtime': 0.3253,\n",
       "   'eval_samples_per_second': 3.074,\n",
       "   'eval_steps_per_second': 3.074,\n",
       "   'step': 25},\n",
       "  {'epoch': 25.0,\n",
       "   'learning_rate': 2.2545090180360722e-05,\n",
       "   'loss': 3.315,\n",
       "   'step': 50},\n",
       "  {'epoch': 25.0,\n",
       "   'eval_loss': 6.073570251464844,\n",
       "   'eval_runtime': 0.2672,\n",
       "   'eval_samples_per_second': 3.743,\n",
       "   'eval_steps_per_second': 3.743,\n",
       "   'step': 50},\n",
       "  {'epoch': 37.5,\n",
       "   'learning_rate': 2.1292585170340683e-05,\n",
       "   'loss': 1.1606,\n",
       "   'step': 75},\n",
       "  {'epoch': 37.5,\n",
       "   'eval_loss': 5.812877178192139,\n",
       "   'eval_runtime': 0.264,\n",
       "   'eval_samples_per_second': 3.788,\n",
       "   'eval_steps_per_second': 3.788,\n",
       "   'step': 75},\n",
       "  {'epoch': 50.0,\n",
       "   'learning_rate': 2.0040080160320643e-05,\n",
       "   'loss': 0.9233,\n",
       "   'step': 100},\n",
       "  {'epoch': 50.0,\n",
       "   'eval_loss': 5.820730686187744,\n",
       "   'eval_runtime': 0.3119,\n",
       "   'eval_samples_per_second': 3.206,\n",
       "   'eval_steps_per_second': 3.206,\n",
       "   'step': 100}],\n",
       " 'logging_steps': 25,\n",
       " 'max_steps': 500,\n",
       " 'num_input_tokens_seen': 0,\n",
       " 'num_train_epochs': 250,\n",
       " 'save_steps': 25,\n",
       " 'total_flos': 14444061696000.0,\n",
       " 'train_batch_size': 2,\n",
       " 'trial_name': None,\n",
       " 'trial_params': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# phi2-journal-finetune/checkpoint-100/trainer_state.json\n",
    "with open(\"phi2-journal-finetune/checkpoint-100/trainer_state.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intputfor = \"kek\\nkek2\\nlmfao\\nlol\"\n",
    "\n",
    "captioned_imgs = {\n",
    "    'text': intputfor.split(\"\\n\"),\n",
    "}\n",
    "from datasets import Dataset\n",
    "out = Dataset.from_dict(captioned_imgs)\n",
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kek', 'kek2', 'lmfao', 'lol']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['note', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1352\n",
       "})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQL796OayRgh"
   },
   "source": [
    "Generally, each `input_ids` should be padded on the left with the `eos_token` (50256) and there should be an `eos_token` 50256 added to the end, and the prompt should start with a `bos_token` (?). However, I'm getting an error with Phi-2's tokenizer. GPU credits for whoever can resolve this!\n",
    "\n",
    "Hopefully should work just fine as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "OKHhvxK83m19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 41, 3643, 40766, 13109, 25, 326, 2576, 287, 11620, 15224, 3073, 588, 616, 409, 986]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6LRa2Zm3m19"
   },
   "source": [
    "Now all the samples should be the same length, `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "I55Yo3yy3m19",
    "outputId": "c87e344d-e0f3-4542-afcc-4e2025926d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]\n",
      "1691\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP3R4enP3m19"
   },
   "source": [
    "### How does the base model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxbl4ACsyRgi"
   },
   "source": [
    "Optionally, you can check how Phi-2 does on one of your data samples. For example, if you have a dataset of users' biometric data to their health scores, you could test the following `eval_prompt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "gOxnx-cAyRgi"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\" Given the following biometric data, score the users' health, from 0-100.\n",
    "\n",
    "### Biometric Data:\n",
    "Temperature=98.2,\n",
    "Sex=F,\n",
    "Age=29,\n",
    "Height=69 inches,\n",
    "Weight=160 lbs,\n",
    "V02_Max=55,\n",
    "HRV=55\n",
    "\n",
    "### Health Score:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRhfq_Fa3m19"
   },
   "source": [
    "The `eval_prompt` I used was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "pa6ux9ni3m19"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \" Bro what \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "NidIuFXMyRgi",
    "outputId": "b1794b11-9a22-4b0a-e871-7df039ab59fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bro what \n",
      "The.\n",
      "A new study has found that the use of a common painkiller during pregnancy may increase the risk for autism in children, according to Reuters Health. The findings were published online on May 1st by JAMA Pediatrics.\n",
      "Researchers from the University of Montreal and McGill University looked at data from more than 100,000 Quebec families with children born between 1998 and 2009. They compared rates of autism spectrum disorder (ASD) among those who had taken acetaminophen while pregnant or breastfeeding their child versus those who did not take it.\n",
      "They found that women who took acetaminophen during any trimester were about 30 percent more likely to have a child diagnosed with ASD than mothers who didn’t take the drug. This increased risk was seen even after taking into account other factors such as age, race/ethnicity, education level, income, smoking status, alcohol consumption, and whether or not the mother used antidepressants or anti-anxiety medications during pregnancy.\n",
      "While this is just one study and further research will be needed before any firm conclusions can be drawn, the authors say they hope these results will encourage doctors and patients alike to consider alternative treatments when possible.\n",
      "What are your thoughts? Do you think there should be more awareness around potential risks associated with\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer so it doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False, # needed for now, should be fixed soon\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCAWeCzZyRgi"
   },
   "source": [
    "Observe how the model does out of the box. This is clearly not my journal, lol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AapDoyfAyRgi"
   },
   "source": [
    "### 5. Set Up LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp2gMi1ZzGET"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. Let's set up our LoRA layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gkIcwsSU01EB"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUYEpEK-yRgj"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to some linear layers of the model. Those layers are `Wqkv`, `fc1`, `fc2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "XshGNsbxyRgj",
    "outputId": "c619b0e8-8516-4d4b-9abe-13eaa3f3b204",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhiForCausalLM(\n",
      "  (model): PhiModel(\n",
      "    (embed_tokens): Embedding(51200, 2560)\n",
      "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x PhiDecoderLayer(\n",
      "        (self_attn): PhiAttention(\n",
      "          (q_proj): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "          (k_proj): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "          (v_proj): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "          (dense): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "          (rotary_emb): PhiRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): PhiMLP(\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (fc1): Linear8bitLt(in_features=2560, out_features=10240, bias=True)\n",
      "          (fc2): Linear8bitLt(in_features=10240, out_features=2560, bias=True)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mTLuQJyRgj"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ybeyl20n3dYH",
    "outputId": "6a16c182-04d9-4812-ae81-502a8fe364d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 26214400 || all params: 2805898240 || trainable%: 0.9342605382581515\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"Wqkv\",\n",
    "        \"fc1\",\n",
    "        \"fc2\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_FHi_VLyRgn"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "IaYMWak4yRgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PhiForCausalLM(\n",
      "      (model): PhiModel(\n",
      "        (embed_tokens): Embedding(51200, 2560)\n",
      "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x PhiDecoderLayer(\n",
      "            (self_attn): PhiAttention(\n",
      "              (q_proj): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "              (k_proj): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "              (dense): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n",
      "              (rotary_emb): PhiRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): PhiMLP(\n",
      "              (activation_fn): NewGELUActivation()\n",
      "              (fc1): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=2560, out_features=10240, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=10240, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (fc2): lora.Linear8bitLt(\n",
      "                (base_layer): Linear8bitLt(in_features=10240, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=10240, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "            )\n",
      "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0MOtwf3zdZp"
   },
   "source": [
    "### 6. Run Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEe0uWYSyRgo"
   },
   "source": [
    "I didn't have a lot of training samples: only about 200 total train/validation. I used 500 training steps, and I was fine with overfitting in this case. I found that the end product worked well. It took about 20 minutes on the 1x A10G 24GB.\n",
    "\n",
    "Overfitting is when the validation loss goes up (bad) while the training loss goes down significantly, meaning the model is learning the training set really well, but is unable to generalize to new datapoints. In most cases, this is not desired, but since I am just playing around with a model to generate outputs like my journal entries, I was fine with a moderate amount of overfitting.\n",
    "\n",
    "With that said, a note on training: you can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting, as described above. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir (`phi2-journal-finetune`) as your final model in step 6 below.\n",
    "\n",
    "If you're just doing something for fun like I did and are OK with overfitting, you can try different checkpoint versions with different degrees of overfitting.\n",
    "\n",
    "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yxSbpKQSLY6B"
   },
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "c_L1131GyRgo"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "jq0nX33BmfaC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jorge/wandb/run-20240206_233832-7sfd69fs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jorgeeduardodsc/journal-finetune/runs/7sfd69fs' target=\"_blank\">phi2-journal-finetune-2024-02-06-23-38</a></strong> to <a href='https://wandb.ai/jorgeeduardodsc/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jorgeeduardodsc/journal-finetune' target=\"_blank\">https://wandb.ai/jorgeeduardodsc/journal-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jorgeeduardodsc/journal-finetune/runs/7sfd69fs' target=\"_blank\">https://wandb.ai/jorgeeduardodsc/journal-finetune/runs/7sfd69fs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 22:05, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.008900</td>\n",
       "      <td>3.715407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.086600</td>\n",
       "      <td>2.918754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.635100</td>\n",
       "      <td>2.789069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.852500</td>\n",
       "      <td>2.758425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.947600</td>\n",
       "      <td>2.720184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.501300</td>\n",
       "      <td>2.679551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.681600</td>\n",
       "      <td>2.677647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.700300</td>\n",
       "      <td>2.652142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.853800</td>\n",
       "      <td>2.643387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.468700</td>\n",
       "      <td>2.645583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.620300</td>\n",
       "      <td>2.619585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.578200</td>\n",
       "      <td>2.614299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.492400</td>\n",
       "      <td>2.609328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.426900</td>\n",
       "      <td>2.603255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.439200</td>\n",
       "      <td>2.590825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.606600</td>\n",
       "      <td>2.584786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.711200</td>\n",
       "      <td>2.573303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.553300</td>\n",
       "      <td>2.572848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.549100</td>\n",
       "      <td>2.567464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.713200</td>\n",
       "      <td>2.570559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.639400</td>\n",
       "      <td>2.567782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.654000</td>\n",
       "      <td>2.558766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.487800</td>\n",
       "      <td>2.553908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.520700</td>\n",
       "      <td>2.552234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.478600</td>\n",
       "      <td>2.545662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.644900</td>\n",
       "      <td>2.547368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.300300</td>\n",
       "      <td>2.544161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.522700</td>\n",
       "      <td>2.537854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.306500</td>\n",
       "      <td>2.539152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.536900</td>\n",
       "      <td>2.535278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.398200</td>\n",
       "      <td>2.531294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.486500</td>\n",
       "      <td>2.537394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.484800</td>\n",
       "      <td>2.532970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.570200</td>\n",
       "      <td>2.531573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.174800</td>\n",
       "      <td>2.531698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.367200</td>\n",
       "      <td>2.533269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.389500</td>\n",
       "      <td>2.533782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.433800</td>\n",
       "      <td>2.530323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.320600</td>\n",
       "      <td>2.532722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.455300</td>\n",
       "      <td>2.532227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=2.6149856567382814, metrics={'train_runtime': 1328.9813, 'train_samples_per_second': 1.505, 'train_steps_per_second': 0.752, 'total_flos': 1925874892800000.0, 'train_loss': 2.6149856567382814, 'epoch': 1.48})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"journal-finetune\"\n",
    "base_model_name = \"phi2\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        max_steps=1000,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "### 7. Drum Roll... Try the Trained Model!\n",
    "\n",
    "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`). \n",
    "\n",
    "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base model from the Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in ./.local/lib/python3.10/site-packages (from openai-whisper) (2.1.2)\n",
      "Requirement already satisfied: numba in ./.local/lib/python3.10/site-packages (from openai-whisper) (0.59.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from openai-whisper) (1.26.3)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in ./.local/lib/python3.10/site-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from openai-whisper) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper) (8.10.0)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in ./.local/lib/python3.10/site-packages (from numba->openai-whisper) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.local/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.local/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (8.9.2.26)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.1.3.1)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (4.9.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->openai-whisper) (3.0.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper) (12.3.101)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801382 sha256=699ef94d73f54d81f9c8b469e0fb145bff020c0bcf9651e680fe1569d056dcba\n",
      "  Stored in directory: /home/jorge/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: tiktoken, openai-whisper\n",
      "Successfully installed openai-whisper-20231117 tiktoken-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='output.wav'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "wav_audio = AudioSegment.from_file(\"WhatsApp Audio 2024-02-08 at 10.54.09_d9abe4f6.waptt.opus\")\n",
    "\n",
    "# Save it\n",
    "wav_audio.export(\"output.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pode passar uma dica para eles, ele precisa um lugar, um rio que tem muita viú, tipo um vídeo específico que tem, você quantos milhões de viú, no Instagram, por exemplo, aí nesse vídeo ele criou uma página dele de Instagram só para que a postante, essas coisas, tem que ter, aí ele posta reposta esses vídeos, aparecendo e sabe quando você quando se faz aquela, quando você se é sobre a posição, acho que é que você fica comentando sobre o vídeo, aí você pode pegar e colocar, eu vi um exemplo do cara, ele colocou um vídeo do um cara que bateu muita visualização, que era sobre o zoom, de uma câmera lá especial, aí ele pegou aí e falou assim tipo um, essa é falar um que isso é que é o zoom do da câmera do iPhone, será que é mesmo? aí aí, aí tipo só dele colocar isso, o povo começa espamático, use o a, fala mal, os caras, por que ele criou, ele pega um vídeo que tem muito alcance, tem que ser um vídeo que já teve muito alcance, se remixa e faz alguma, tem alguma coisa assim, não é, não é, será não estreito, mas pode ser alguma coisa que enxiga a pessoa como é entrar, aí esse número de interação vai ter, vai fazer o povo ir para o topo do fluido dele, quer é o povo estar começando a acessar a página dele, mesmo que não tenha seguido, entrado, daí quando ele colocar esse ebook nessa mesma página que ele criou, que ele vai usar essa página para publicar os ebooks, quando ele coloca esse ebook na página e coloca patrocínio, alguma coisa do tipo, o alcance dele vai ser de dano pesco, aí pela quantidade de, pelo número de alcance acaba aqui fecha, mesmo que a cada mil pessoa se feche uma, se tiver um alcance muito alto, se vai fechar bastante.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"output.wav\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3529541120"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aebf8891bd542d0946dff9597dbad48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# from numba import cuda\n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "base_model_id = \"microsoft/phi-2\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Phi2, same as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False, # needed for now, should be fixed soon\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "eval_tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"phi2-journal-finetune/checkpoint-450\")\n",
    "\n",
    "\n",
    "def inference_on_text(text, max_new_tokens=100, temperature=0.5):\n",
    "    model_input = eval_tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    ft_model.eval()\n",
    "    with torch.no_grad():\n",
    "        return eval_tokenizer.decode(ft_model.generate(\n",
    "            **model_input, \n",
    "            max_new_tokens=max_new_tokens, \n",
    "            repetition_penalty=1.51,\n",
    "            temperature=temperature, \n",
    "            do_sample=True\n",
    "            )[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Translate this to Portuguese: \"Hello my name is John\" \\nAnswer: Olá, meu nome éJohn. The translation from English language into portuguese includes the word order and grammar structure'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_on_text('Translate this to Portuguese: \"Hello my name is John\"', max_new_tokens=30, temperature=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ft_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m ft_model\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m base_model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tokenizer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ft_model' is not defined"
     ]
    }
   ],
   "source": [
    "del ft_model\n",
    "del base_model\n",
    "del tokenizer\n",
    "del eval_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache has been cleared.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# Only use following if not working with multiple processes sharing GPU mem\n",
    "# Ensures that all unneeded IPC handles are released and that GPU memory is being used efficiently\n",
    "torch.cuda.ipc_collect()\n",
    "gc.collect()\n",
    "print(\"GPU cache has been cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello@the-council.org\\nThe Council of Europe is an international organisation that promotes democracy, human rights and the rule law in 47 European countries through its member states as well as by working with other organisations around world to promote these values globally.. The council was founded on 12th December 1949 at a conference held after World War II when it became clear there needed be some form or structure for cooperation between nations who had suffered so much during this period; they wanted peace but also justice which would'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_on_text(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fb8230fb86884aa6be318e2d03a88af2"
     ]
    },
    "id": "SKSnF016yRgp",
    "outputId": "bce5209d-90da-4117-c6ac-cda9f3cb3422"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d7454c93b5445ab5a268b3b07a99b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "base_model_id = \"microsoft/phi-2\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Phi2, same as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False, # needed for now, should be fixed soon\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "eval_tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BxOhAiqyRgp"
   },
   "source": [
    "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GwsiqhWuyRgp"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"phi2-journal-finetune/checkpoint-875\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX39ibolyRgp"
   },
   "source": [
    "and run your inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUehsaVNyRgp"
   },
   "source": [
    "Let's try the same `eval_prompt` and thus `model_input` as above, and see if the new finetuned model performs better. I like playing with the repetition penalty (just little tweaks of .01-.05 at a time). THIS IS SO FUN. I'm obsessed wth this AI version of myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lMkVNEUvyRgp",
    "outputId": "7d49d409-5dbe-4306-c1a4-9d87e3073397"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " yo bro ikr u? im so bored lol i dont even know what to do with my life right now but at least we have each other and our phones for entertainment haha cuz thats all that matters anyways https://www.youtube.com/watchv=_q-Yf9QW0c8&siidx=-1%2C5h3X4Vw6KJ7kzUiFjMmEuOyZpPnHg\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \" yo bro \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.51)[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
